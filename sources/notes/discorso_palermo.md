Buongiorno,
sono Daniele Dragoni, dottorando del dottorato nazionale in Teaching and Learning Sciences. Si tratta di un dottorato di interesse nazionale che ha sede a Macerata. L'università partner a cui appartengo è Roma Tre.
Il contributo che oggi porto è relativo a un'indagine che sto conducendo nell'ambito del tirocinio presso un centro di ricerca: l'ISTC-CNR. L'indagine verte sull'uso dell'intelligenza artificiale nell'educazione e coinvolge anche due dottorandi, due ricercatori del CNR e il mio tutor, il professor Margottini.
Prima di esporre la ricerca e i dati preliminari, vorrei chiedervi se negli ultimi due anni le vostre abitudini digitali sono cambiate. È probabile che sia cambiato il modo in cui fate ricerca o cercate informazioni su internet. Credo che molti di voi utilizzino ormai i nuovi modelli di intelligenza artificiale al posto dei motori di ricerca tradizionali.
Questo cambiamento rende queste intelligenze artificiali dei nuovi mediatori culturali e crea un ulteriore distanza tra noi e la fonte dell'informazione. Una soluzione comoda, veloce, ma molto pericolosa e su cui bisogna riflettere.
L'AI sta quindi cambiando le nostre abitudini digitali e non solo, e lo sta facendo in modo molto radicale. Possiamo dire che questa influenza è trasversale a molti settori, ma nel dominio dell'educazione riveste particolare importanza e comporta da una parte molte opportunità e molti rischi. Tanto che l'Unione Europea, con l'AI Act, ha inserito l'educazione tra i domini ad alto rischio.
Per questo motivo abbiamo ritenuto fondamentale interrogarci su questo cambiamento e capire se le nostre scuole e università, i nostri studenti e i nostri insegnanti sono pronti ad affrontarlo e come lo stanno vivendo.
Abbiamo declinato questa domanda generica e generale in diversi fattori puntuali:
•	Uso
•	Percezioni di competenza
•	Formazione ricevuta
•	Fiducia nell’integrazione e nell’uso responsabile degli studenti
•	Preoccupazioni
•	Percezione del cambiamento sul proprio modo di insegnare e apprendere e quello degli altri e dell’istituzione
•	Pro e contro
•	Buone pratiche
•	Utilizzo dell’IA per la personalizzazione
Metodologia 
Per indagare questi fattori abbiamo utilizzato un approccio mixed method, combinando un'indagine quantitativa e una qualitativa. Da una parte, per ottenere dati numerici robusti e statisticamente significativi; dall'altra, per comprendere in profondità come questa tecnologia viene percepita e quali effetti stia producendo nel contesto educativo, cogliendone le sfumature, le motivazioni sottostanti, le criticità emergenti, le barriere all'adozione, i contesti applicativi e le implicazioni per la pratica didattica.
Come strumento di indagine abbiamo usato il questionario. In realtà ne abbiamo fatti due uno per gli insegnati e un per gli studenti. Le domande dei due questionari sono speculari e confrontabili tra i due gruppi. Inoltre, tra i gruppi degli insegnati abbiamo soprattutto insegnati in formazione. Il che rende questa indagine molto interessante per questo contesto
Una piccola parte dei partecipanti a cui abbiamo somministrato il questionario lo ha fatto online. Mentre la grande maggioranza l’ha fatto durante delle lezioni universitarie. In particolare, abbiamo studenti universitari di corsi di psicologia e insegnati in formazione dei corsi Pef60, TFA e Pef30, questi ultimi in servizio ma che devono conseguire la abilitazione con la nuova normativa.
Di seguito potete vedere i numeri in questo grafico.
I questionari inoltre quando sono  stati somministrati in classe sono state utilizzati per fare delle riflessioni sull’uso dell’AI.
In questa sede per motivi di tempo e anche perché alcune analisi specialmente quelle qualitative sono in svolgimento vi mostrerò alcuni dei primi risultati quantitativi. Vi mostrerò in successione le domande fatte e il risultato.
Risultati
Uso
Molto interessanti sono i dati relativi all’uso e agli strumenti utilizzati soprattutto se si fanno confronti tra studenti e insegnati.
Un primo dato interessante riguarda il divario tra l’utilizzo dell’intelligenza artificiale da parte degli studenti e quello da parte degli insegnanti. Si osserva infatti un sensibile gap sia nell’uso quotidiano sia in quello a fini di apprendimento o didattici. Tale differenza merita di essere interpretata e valutata con attenzione.
L'intelligenza artificiale risulta maggiormente accessibile e immediatamente utile per gli studenti, che possono utilizzarla per ottenere spiegazioni rapide o ricevere supporto nello svolgimento dei compiti. Per gli insegnanti, invece, l'adozione appare meno spontanea e più complessa. Le esigenze professionali richiedono infatti risorse mirate e strutturate, e l'esperienza accumulata permette loro di attingere a materiali tradizionali che, almeno nella fase attuale, risultano più affidabili e pertinenti rispetto alle soluzioni offerte dall'AI.
A questa complessità si aggiungono ulteriori elementi: lo scetticismo verso una tecnologia ancora in evoluzione, una preparazione non sempre sufficiente per un utilizzo pedagogico efficace, e un atteggiamento prudente di attesa volto a comprendere meglio le potenzialità e i limiti reali di questa innovazione in ambito educativo.
Questi gap significativi evidenziano l'esistenza di barriere concrete nell'integrazione dell'AI nel contesto scolastico. Tra le cause principali emergono la possibile mancanza di competenze specifiche, dubbi di natura etica sulla legittimità e appropriatezza del suo impiego in aula, e l'inadeguatezza delle soluzioni attualmente disponibili rispetto alle necessità e alla complessità della pratica quotidiana dell'insegnamento.
A ciò si aggiunge un fattore generazionale rilevante: le fasce più giovani dimostrano una maggiore propensione all'adozione delle nuove tecnologie e un'attitudine più disinvolta alla loro sperimentazione. Si pensi, ad esempio, alla naturalezza con cui gli studenti integrano strumenti digitali nella loro quotidianità, in contrasto con la cautela e lo scetticismo che spesso caratterizzano l'approccio di molti docenti. Un ulteriore elemento critico emerge dall'analisi dei dati: sia gli studenti che gli insegnanti utilizzano un numero limitato di strumenti di intelligenza artificiale, con una netta prevalenza di ChatGPT. Questa concentrazione comporta che l'esperienza d'uso dell'AI si limiti a un'unica piattaforma generalista, senza esplorare strumenti più specifici e progettati specificamente per il contesto educativo, quali ad esempio NotebookLM o altre applicazioni dedicate all'apprendimento.
I dati rivelano inoltre una marcata differenza tra gli utenti occasionali, che impiegano l'intelligenza artificiale per una o due ore settimanali, e i power user che ne fanno un utilizzo intensivo e continuativo. Questa polarizzazione suggerisce che l'integrazione dell'AI nel processo educativo rimane per la maggior parte degli utenti un'esperienza sporadica e superficiale, limitata a consultazioni occasionali piuttosto che a un'incorporazione sistematica nelle pratiche di studio o di insegnamento. Tale modalità d'uso impedisce lo sviluppo di competenze avanzate e la scoperta di applicazioni più sofisticate della tecnologia, contribuendo a mantenere una percezione limitata delle sue reali potenzialità in ambito educativo.
Tuttavia, questo divario non deve essere interpretato esclusivamente in termini negativi. Molte delle attività didattiche si fondano su pratiche consolidate e relazioni interpersonali che non richiedono necessariamente il supporto dell'intelligenza artificiale, e che mantengono la loro efficacia e rilevanza pedagogica indipendentemente dall'introduzione di nuove tecnologie.
Percezione di competenza
A questo punto si collega due fattori chiave che influenzano l’uso di queste tecnologie: la percezione di competenza e la formazioni ricevuta.
Abbiamo chiesto sia agli studenti che agli insegnanti di autovalutare, su una scala da uno a sette, la propria competenza pratica e teorica nell'uso dell'intelligenza artificiale. I risultati evidenziano un divario significativo tra le due dimensioni. La competenza pratica mostra una media di 4,32 con mediana pari a quattro, mentre la competenza teorica si attesta a 3,16 con mediana tre. Si registra dunque un gap di oltre un punto sulla scala Likert, indicativo di una discrepanza sostanziale tra il saper fare e il comprendere i fondamenti della tecnologia.
L'analisi della distribuzione delle risposte degli studenti rende il quadro ancora più evidente. Settanta studenti hanno attribuito un valore pari a cinque alla propria competenza pratica, mentre quarantanove hanno indicato sei, configurando una massa critica di studenti che si percepisce confidentemente competente nell'utilizzo pratico degli strumenti di intelligenza artificiale. Al contrario, per quanto riguarda la competenza teorica, la concentrazione si addensa sui valori bassi della scala: ottantatré risposte corrispondono al valore due e cinquantadue al valore tre. Emerge dunque un approccio prevalentemente empirico, caratterizzato da un apprendimento per tentativi ed errori. Gli studenti acquisiscono padronanza nell'uso diretto degli strumenti senza sviluppare una comprensione formale e strutturata dei principi teorici e dei meccanismi sottostanti alla tecnologia.
Gli insegnanti presentano un pattern differente ma ugualmente delicato. La competenza pratica media si attesta a 3,74, mentre quella teorica a 3,28. Sebbene il divario tra le due dimensioni risulti inferiore rispetto agli studenti, entrambi i valori rimangono al di sotto del punto mediano della scala, segnalando una generale percezione di inadeguatezza. Particolarmente significativo è il dato che vede ottantadue insegnanti su trecentocinquantotto collocarsi sul valore due per la competenza pratica. Una porzione considerevole del corpo docente si sente dunque inadeguata nell'utilizzo pratico degli stessi strumenti che dovrebbe essere in grado di insegnare a utilizzare criticamente e consapevolmente. Questo dato non sorprende se considerato alla luce delle barriere precedentemente analizzate, ma solleva interrogativi importanti sulle modalità attraverso cui preparare adeguatamente gli educatori all'integrazione pedagogica dell'intelligenza artificiale.
Formazione ricevuta
Un dato particolarmente critico emerge dall'analisi della valutazione della formazione ricevuta sull'intelligenza artificiale. Gli studenti assegnano una media di 3,3, mentre gli insegnanti si attestano a 2,93. Entrambi i valori risultano significativamente al di sotto del punto mediano della scala, segnalando una diffusa insoddisfazione rispetto alla preparazione ricevuta su questa tecnologia.
La distribuzione delle risposte è eloquente e preoccupante: il 22% degli studenti ha attribuito il valore minimo, giudicando la formazione "per nulla adeguata", percentuale che sale al 28% tra gli insegnanti. Questa percezione negativa assume contorni ancora più critici se messa in relazione con i dati relativi all'uso effettivo della tecnologia: l'80% degli studenti utilizza l'intelligenza artificiale quotidianamente, eppure la maggioranza di loro ritiene inadeguata la formazione ricevuta in merito.
Si delinea così uno scenario caratterizzato da un apprendimento prevalentemente informale e non guidato, in cui l'acquisizione di competenze avviene in modo autonomo e destrutturato, attraverso la sperimentazione diretta degli strumenti. Questa modalità comporta rischi significativi in termini di sviluppo di un uso acritico e superficiale della tecnologia, privo di quella consapevolezza teorica e di quel pensiero critico indispensabili per un'integrazione efficace e responsabile dell'intelligenza artificiale nei processi di apprendimento e insegnamento. La discrepanza tra utilizzo intensivo e formazione inadeguata costituisce una delle sfide più urgenti da affrontare per una piena e consapevole integrazione dell'AI nel contesto educativo.
Cambiamento
Dall'analisi delle percezioni relative al cambiamento emerge un pattern psicologico significativo. Quando agli insegnanti viene chiesto quanto l'intelligenza artificiale cambierà l'insegnamento in termini generali, la risposta è decisamente positiva: la media si attesta a 5,45 con mediana pari a sei, indicando un riconoscimento diffuso del potenziale trasformativo della tecnologia nel campo educativo.
Tuttavia, quando la domanda assume una connotazione personale – "quanto cambierà il TUO modo di insegnare?" – il valore scende a 4,68 con mediana cinque. Questo gap di quasi 0,8 punti risulta statisticamente significativo e psicologicamente rivelatore. Si configura quello che in letteratura viene definito "bias della terza persona": la tendenza a ritenere che i grandi cambiamenti riguarderanno maggiormente gli altri piuttosto che se stessi.
Tale fenomeno può essere interpretato secondo due prospettive complementari. Da un lato, potrebbe rappresentare un meccanismo di difesa psicologica di fronte a un cambiamento percepito come destabilizzante per le proprie pratiche professionali consolidate. Dall'altro, potrebbe riflettere un'incertezza concreta e pragmatica su come integrare effettivamente l'intelligenza artificiale nella propria quotidianità didattica, evidenziando la distanza tra il riconoscimento teorico del potenziale della tecnologia e la capacità pratica di incorporarla nel proprio repertorio pedagogico.
Gli studenti, dal canto loro, mostrano aspettative più moderate riguardo al cambiamento del proprio approccio allo studio, con una media di 4,91. Pur riconoscendo che l'intelligenza artificiale avrà un impatto sulle loro modalità di apprendimento, non la percepiscono come uno strumento rivoluzionario nella stessa misura in cui gli insegnanti ne prevedono l'impatto sul versante dell'insegnamento. Questa differenza di percezione potrebbe suggerire che gli studenti, già immersi in un uso quotidiano della tecnologia, ne abbiano una visione più pragmatica e meno idealizzata rispetto ai docenti.
Fiducia e preoccupazioni
Uno dei dati più significativi emersi dall'indagine riguarda la fiducia riposta nell'integrazione dell'intelligenza artificiale nel contesto educativo. Gli studenti esprimono un livello di fiducia con media pari a 4,47 e mediana cinque, mentre gli insegnanti si attestano su valori inferiori: media 4,12 e mediana quattro.
Si delinea così un'asimmetria rilevante: coloro che dovranno essere guidati nell'uso della tecnologia si dimostrano più ottimisti rispetto a coloro che dovranno svolgere il ruolo di guida. Questa divergenza può essere interpretata alla luce di diversi fattori. Da un lato, la maggiore familiarità tecnologica delle generazioni più giovani le rende naturalmente più propense ad abbracciare con fiducia le innovazioni digitali. Dall'altro, le preoccupazioni pedagogiche degli insegnanti riflettono una consapevolezza più profonda delle complessità legate all'integrazione dell'intelligenza artificiale nella didattica, aspetti che gli studenti potrebbero non percepire o sottovalutare.
Ancora più significativo risulta il dato relativo alla fiducia che gli insegnanti ripongono negli studenti riguardo all'uso consapevole e critico dell'intelligenza artificiale. Le preoccupazioni dei docenti sull'utilizzo dell'IA da parte degli studenti mostrano una media di 4,71, con quasi il 60% delle risposte concentrate sui valori alti della scala. Emerge chiaramente che gli educatori nutrono dubbi sostanziali sulla capacità critica degli studenti di impiegare questi strumenti in modo riflessivo e appropriato.
La sintesi di questi dati compone un quadro problematico: l'80% degli studenti utilizza l'intelligenza artificiale quotidianamente, mentre gli insegnanti manifestano preoccupazione e sfiducia verso la loro capacità di farlo in modo consapevole. Si configura una situazione paradossale, paragonabile a quella di numerosi conducenti che guidano senza patente, sotto lo sguardo preoccupato di istruttori che non dispongono degli strumenti adeguati per intervenire efficacemente. Questo disallineamento tra uso intensivo e mancanza di competenze critiche guidate rappresenta una delle criticità più urgenti da affrontare per garantire un'integrazione responsabile e pedagogicamente fondata dell'intelligenza artificiale nel percorso educativo.
Le percezioni degli studenti: tra cambiamento, preoccupazione e consapevolezza dei limiti
L'analisi delle domande specifiche rivolte agli studenti rivela un quadro articolato delle loro percezioni sull'intelligenza artificiale nel contesto educativo. Per quanto riguarda l'impatto sul proprio metodo di studio (Q1), gli studenti esprimono aspettative elevate, con una mediana pari a cinque e una distribuzione che si concentra sui valori medio-alti della scala. Riconoscono dunque che l'intelligenza artificiale rappresenterà un elemento significativo di trasformazione nelle loro modalità di apprendimento, pur mantenendo un atteggiamento sostanzialmente equilibrato e non eccessivamente entusiastico.
Un dato particolarmente critico emerge dalla valutazione che gli studenti forniscono della preparazione dei propri insegnanti sull'intelligenza artificiale (Q2). La mediana si attesta sul valore tre, con una concentrazione significativa delle risposte sui valori bassi della scala. Gli studenti percepiscono chiaramente l'inadeguatezza formativa del corpo docente, riconoscendo un gap di competenze che conferma quanto emerso dalle risposte degli insegnanti stessi. Questa consapevolezza è significativa: gli studenti non solo utilizzano intensivamente la tecnologia, ma sono anche in grado di valutare criticamente i limiti di chi dovrebbe guidarli nel suo utilizzo.
Per quanto riguarda le preoccupazioni, emergono due livelli distinti. La preoccupazione per l'uso dell'intelligenza artificiale nella scuola in generale (Q3) si attesta su valori moderati, con mediana intorno a tre, suggerendo un atteggiamento cauto ma non allarmato. Analogamente, la preoccupazione per l'uso dell'IA da parte dei compagni (Q4) si colloca su valori simili, indicando che gli studenti, pur riconoscendo potenziali criticità, non vivono l'integrazione della tecnologia come una minaccia sostanziale. Questa relativa tranquillità contrasta con le preoccupazioni più marcate espresse dagli insegnanti, delineando una differenza generazionale nell'approccio emotivo e valoriale alla tecnologia che merita particolare attenzione nelle strategie di integrazione dell'intelligenza artificiale nel contesto scolastico.

Cosa ci dicono questi dati: verso una nuova pedagogia dell'intelligenza artificiale
I dati emersi dalla nostra indagine mixed method compongono un quadro complesso e per certi versi contraddittorio dell'integrazione dell'intelligenza artificiale nel contesto educativo italiano. Al di là dei singoli risultati, è la lettura sistemica di questi elementi a rivelare le dinamiche profonde e le sfide strutturali che caratterizzano questo momento di transizione tecnologica e pedagogica.
Un'adozione disomogenea e non guidata
Il primo elemento che emerge con forza è la presenza di un'adozione massiccia ma profondamente disomogenea dell'intelligenza artificiale. L'80% degli studenti utilizza questi strumenti quotidianamente, configurando una prassi ormai consolidata e radicata nelle loro routine di studio. Tuttavia, questo utilizzo intensivo si accompagna a una serie di criticità che ne limitano il potenziale educativo e ne amplificano i rischi.
Innanzitutto, l'esperienza d'uso si concentra quasi esclusivamente su ChatGPT, con una sostanziale ignoranza dell'esistenza di strumenti più specifici e pedagogicamente orientati. Questa monocultura tecnologica impedisce agli studenti di sviluppare una comprensione articolata delle diverse applicazioni dell'intelligenza artificiale e delle loro specifiche potenzialità in ambito educativo. In secondo luogo, si registra una polarizzazione netta tra utenti occasionali, che impiegano la tecnologia per una o due ore settimanali, e power user che ne fanno un utilizzo intensivo. Questa frammentazione suggerisce l'assenza di un approccio istituzionale condiviso e strutturato, sostituito da percorsi individuali e autodiretti che riflettono più le inclinazioni personali che una strategia educativa consapevole.
Il paradosso della competenza: saper fare senza comprendere
Uno dei risultati più significativi riguarda il divario tra competenza pratica e competenza teorica, particolarmente marcato negli studenti. La capacità di utilizzare gli strumenti (media 4,32) supera di oltre un punto la comprensione dei principi sottostanti (media 3,16). Questo gap configura un modello di apprendimento basato sul trial and error, in cui l'acquisizione di abilità operative avviene in modo empirico e destrutturato, senza passare attraverso una comprensione formale dei meccanismi, delle logiche e dei limiti della tecnologia.
Tale approccio, se da un lato consente una rapida familiarizzazione con gli strumenti, dall'altro preclude lo sviluppo di quelle competenze critiche e metacognitive indispensabili per un uso consapevole e responsabile dell'intelligenza artificiale. Gli studenti sanno interrogare un sistema di IA generativa, ma non comprendono come questo elabori le risposte, quali bias possa contenere, quali limiti epistemologici presenti, e come validare criticamente l'output ricevuto. Si tratta di un'alfabetizzazione tecnologica superficiale che rischia di produrre utenti acritici piuttosto che cittadini digitali competenti.
L'inadeguatezza formativa: un vuoto istituzionale
Il dato forse più allarmante riguarda la valutazione della formazione ricevuta sull'intelligenza artificiale. Sia gli studenti (media 3,3) che gli insegnanti (media 2,93) esprimono un giudizio significativamente negativo, con oltre un quarto degli insegnanti che la considera "per nulla adeguata". Questo giudizio assume contorni drammatici se considerato in relazione all'uso quotidiano della tecnologia: si configura una situazione in cui la pratica precede e sostituisce la formazione, anziché esserne guidata.
Il sistema educativo si trova di fronte a un vuoto istituzionale evidente. Mentre l'intelligenza artificiale si diffonde rapidamente tra gli studenti attraverso canali informali e peer-to-peer, le istituzioni scolastiche non riescono a fornire quella cornice pedagogica, quel supporto critico e quella guida metodologica che dovrebbero costituire il loro valore aggiunto. L'apprendimento dell'IA diventa così un processo selvaggio, caratterizzato dall'assenza di mediazione educativa e dalla prevalenza di logiche individualistiche e strumentali.
Il bias della terza persona e la resistenza al cambiamento
Gli insegnanti manifestano un interessante fenomeno psicologico: mentre riconoscono che l'intelligenza artificiale cambierà significativamente l'insegnamento in generale (media 5,45), sono molto più cauti nel prevederne l'impatto sulla propria pratica didattica personale (media 4,68). Questo "bias della terza persona" può essere interpretato come un meccanismo di difesa di fronte a un cambiamento percepito come destabilizzante, oppure come espressione di un'incertezza concreta su come tradurre il riconoscimento teorico del potenziale dell'IA in pratiche didattiche effettive.
Tale fenomeno si accompagna a livelli di competenza percepita generalmente bassi (competenza pratica media 3,74) e a una massa significativa di docenti che si colloca sui valori più bassi della scala. Emerge un corpo insegnante che si sente inadeguato rispetto agli strumenti che dovrebbe essere in grado di insegnare a utilizzare criticamente, intrappolato tra il riconoscimento della rilevanza della tecnologia e l'incapacità di integrarla efficacemente nella propria pratica professionale.
Il paradosso della fiducia: chi guida non si fida di chi viene guidato
Un ulteriore elemento critico riguarda la fiducia. Gli studenti si dimostrano più fiduciosi nell'integrazione dell'IA nell'istruzione (media 4,47) rispetto agli insegnanti (media 4,12), configurando un'asimmetria in cui chi dovrebbe essere guidato è più ottimista di chi dovrebbe guidare. Ma il dato più preoccupante riguarda la fiducia che gli insegnanti ripongono nella capacità critica degli studenti: le preoccupazioni si attestano su valori elevati (media 4,71), con quasi il 60% delle risposte concentrate sui valori alti della scala.
Si delinea così un paradosso educativo: l'80% degli studenti utilizza quotidianamente l'intelligenza artificiale, mentre gli insegnanti non si fidano della loro capacità di farlo in modo consapevole e critico, e al contempo non dispongono degli strumenti formativi e delle competenze necessarie per intervenire efficacemente. È come se numerosi conducenti guidassero senza patente sotto lo sguardo preoccupato di istruttori che non hanno i mezzi per insegnare loro a guidare correttamente. Significativamente, gli studenti stessi sono consapevoli di questa inadeguatezza, come dimostra la loro valutazione negativa della preparazione degli insegnanti sull'IA (mediana 3).
Implicazioni e direzioni future
Questi dati, nel loro insieme, delineano un'urgenza educativa che non può essere ulteriormente ignorata o rinviata. L'integrazione dell'intelligenza artificiale nel contesto scolastico sta avvenendo de facto, ma in modo caotico, non guidato e pedagogicamente inadeguato. È necessario un intervento sistemico e strutturato che affronti contemporaneamente diverse dimensioni:
Formazione docenti: È indispensabile investire in percorsi formativi seri e continuativi per gli insegnanti, che non si limitino a insegnare l'uso operativo degli strumenti, ma sviluppino una comprensione critica dei fondamenti dell'intelligenza artificiale, delle sue implicazioni pedagogiche ed etiche, e delle modalità attraverso cui integrarla efficacemente nella didattica.
Curricoli strutturati per gli studenti: È necessario superare l'apprendimento informale e autodidattico introducendo percorsi curriculari che combinino competenza pratica e comprensione teorica, sviluppando quella literacy critica dell'IA che i dati mostrano come drammaticamente assente.
Diversificazione degli strumenti: Occorre promuovere la conoscenza e l'utilizzo di strumenti specificamente progettati per il contesto educativo, superando la dipendenza esclusiva da piattaforme generaliste come ChatGPT.
Ricerca pedagogica: È fondamentale sviluppare ricerca empirica sulle modalità più efficaci di integrazione dell'IA nella didattica, sui suoi effetti sull'apprendimento, e sulle strategie per prevenire un uso acritico e superficiale.
Ripensamento delle pratiche didattiche: Gli insegnanti devono essere supportati nel ripensare le proprie pratiche alla luce delle possibilità offerte dall'IA, superando sia l'atteggiamento difensivo che l'entusiasmo acritico, per sviluppare un approccio pedagogicamente fondato e criticamente consapevole.
I dati ci dicono che siamo a un bivio. Possiamo lasciare che l'intelligenza artificiale si integri nel contesto educativo in modo spontaneo e disordinato, con tutti i rischi che questo comporta in termini di uso acritico, superficiale e pedagogicamente inefficace. Oppure possiamo decidere di assumere un ruolo attivo e consapevole, costruendo quella "pedagogia dell'intelligenza artificiale" che ancora manca, ma che appare sempre più urgente e necessaria per garantire che questa tecnologia diventi davvero uno strumento di arricchimento dell'esperienza educativa e non un fattore di impoverimento del pensiero critico e dell'autonomia intellettuale degli studenti.




 


