Title 1: Bridging the Gap: Trust, Competence, and Concern in the Integration of AI among Teachers and Students
Title 2: Balancing Trust and Uncertainty: Human Factors in the Adoption of AI in Education
1	Autori

(Daniele Dragoni, Rino Falcone, Elisa Colì, Isabella Poggi, Daniele Caligiore)

2	Guida al draft
Ogni capitolo è preceduto da un elenco puntato delle attività da svolgere nell'articolo; il testo evidenziato in rosso indica le parti ancora da implementare.


1	Introduction
●	Considerazione su Impact of new digital tools in education (REF), fiducia, competenza paura, come hanno reagito docenti e studenti (4 righe)
●	Attenzione, adesso qualcosa di rivoluzionario, IA che può fare X, Y, … (2 righe)
●	Ma soprattutto IA generativa
●	Perché IAG rivoluzionaria rispetto a tecnologie (per punti)
●	Cosa e’ IA generativa
●	Che impatto sta avendo (REF), stato dell’arte, articoli
●	Noi in questo articolo cosa abbiamo fatto
●	Menzionare i risultati


Digital technologies play a central role in contemporary educational settings. Their deployment can produce both beneficial and adverse effects on learning processes. On one hand, they expand access to a wide array of resources, enable the personalization of instructional pathways and support interactive pedagogical methods; On the other hand, if used as a shortcut and without critical engagement, they may foster an uncritical reliance on technological tools, thereby weakening learners’ independent cognitive capacities.
Within this framework, two user profiles should be taken into consideration. For individuals with cognitive impairments, technological aids function as effective compensatory mechanisms, enabling performance comparable to that of their non-impaired peers. Conversely, among adult and older learners, the introduction of novel technologies frequently encounters elevated levels of difficulty, yielding resistance and anxiety that often lack empirical justification.
From a broader perspective, the adoption and mastery of new technologies are substantially influenced by emotional and social factors. Learners’ self-efficacy beliefs regarding their digital competence, fears of potential negative consequences if technology is mismanaged, and the degree to which peers employ the same tools all play a pivotal role. Similarly, the willingness of teachers to integrate technological innovations may be constrained by concerns over students’ improper use of devices or by their own emotional reservations toward unfamiliar digital platforms.
In the present day, a new technology is emerging, which is generative intelligence artificial. The main characteristic of this technology is its ability to combine existing elements in a new way, which Murani defines as creativity in Fantasia. This allows it to create texts, voices, images, and videos that seem to be made by a human. Furthermore, it has a great ability to recognize patterns, making it very useful for creating code.
This technology improves everyday thanks to two fundamental factors: the evolution of hardware and the progress of the surrounding ecosystem. On the hardware side, advances such as more powerful GPUs, optimized memory architectures, and dedicated processing units contribute to better performance and scalability. On the ecosystem side, improvements include the development of new algorithms, fine-tuning methods, and supporting technologies such as Retrieval-Augmented Generation (RAG), vector stores, orchestration tools, and evaluation frameworks. These elements, among others, help enhance the overall efficiency and effectiveness of the technology.
This article examines the key factors influencing the adoption of new technologies in educational contexts, with particular attention to users' perceived digital competence, fears of misuse, and broader concerns. Additionally, it investigates how students and teachers engage with these technologies in practice and discusses evolving norms regarding appropriate and inappropriate uses of AI.
2	Materials and Methods
●	questionario
●	soggetti
●	etica
●	analisi statistica
●	utilizzo di ML (per sviluppare idee, per migliorare il questionario, strumento per creare tools per analisi statistica, ecc.)

A mixed‐methods action‐research design was implemented to capture both numerical trends and rich, contextual insights into AI adoption in education. The study combined traditional survey techniques with an experimental “vibe-research” approach, whereby an interactive dashboard facilitated a dynamic interplay between generative AI and researcher decisions, allowing real-time adjustments to question presentation and analytic focus.
The primary data collection instrument was an online questionnaire structured around four domains. First, demographic and background variables (age, gender, educational level, disciplinary area, professional status) enabled segmentation of respondents. Second, a series of 7-point Likert items assessed perceived digital competence, confidence in AI integration, and levels of concern regarding potential misuse. Third, dichotomous (yes/no) and time-use questions quantified patterns of daily and educational AI engagement, including hours per week dedicated to AI-supported activities. Fourth, open-ended prompts elicited motivations for use or non-use, preferred tools, typical prompts, perceived benefits and drawbacks, and recommendations for improvement. Mirror-formulated items for students and teachers ensured direct comparability across cohorts. Prior to deployment, the questionnaire underwent pilot testing with a small convenience sample to refine wording, verify response consistency, and estimate completion time.
Participants were drawn from three user segments—students at various school levels, in-service teachers from multiple disciplines, and pre-service teachers in training programs—recruited through educational networks and online invitations. Data collection spanned several weeks during the academic term, with responses gathered anonymously under strict GDPR compliance. No financial incentives were offered, and participation was entirely voluntary, mitigating potential response biases related to coercion or reward.
Quantitative data were analyzed using descriptive statistics, independent-samples t-tests, one-way ANOVAs, and multiple regression models to detect group differences and identify key predictors of AI adoption. Correlation matrices illuminated associations among perceived competence, fear, and actual usage. Qualitative responses were processed through text-mining techniques—including frequency counts, thematic coding, and topic modeling—to uncover recurrent patterns, divergent viewpoints, and emergent themes. All analyses and visualizations were implemented within the bespoke dashboard environment, which also served as a methodological laboratory to observe how researcher prompts and AI outputs co-evolve.
Ethical oversight encompassed informed consent, anonymization of all data, and secure storage protocols. This comprehensive, hybrid methodology enabled a nuanced understanding of both the drivers and the lived experiences of AI integration in educational settings, while simultaneously interrogating the boundaries between human and machine contributions to research.
3	Results
-	selezionare risultati dalla dashboard da raccontare nel paper
-	tempo di utilizzo
-	età utilizzatori

The results section presents the main findings of the study, structured around several key thematic areas. It starts with the demographic profile of participants, then moves on to an analysis of how artificial intelligence (AI) is utilized in teaching and learning environments. Following this, the report explores participants’ perceptions of their own competencies, their levels of trust and concern regarding AI, the time dedicated to AI-related activities, and the specific tools employed. The section concludes with an analysis of participants’ opinions on which tools are suitable—or unsuitable—for educational purposes.

2.1	Participant Demographics
Age distribution
Gender composition
Group size and characteristics (students, future teachers, current teachers

University students in PEF teacher training programs, TFA support courses, and high school students taught by participating teachers.

The study is based on a convenience sample consisting of three groups: current teachers, future teachers, and students. Current teachers form the largest group (n = 308), followed by students (n = 247), and future teachers (n = 100). The average age differs significantly among the groups, with current teachers being the oldest (M = 46.3, SD = 10.2) and students the youngest (M = 21.1, SD = 6.7), revealing a 25.2-year age gap. Regarding gender distribution, students have the highest proportion of female participants (81.4%). Additionally, the current teacher group shows the widest age range, from 20 to 72 years.

N. Participants	Group	Mean Age	Median Age	Std. Deviation	Age Range	Prevalent Gender	% Prevalent Gender
269	Students	21.1	22.0	6.7	14–58	F	81.4%
308	Current Teachers	46.3	47.0	10.2	20–72	F	80.8%
100	Future Teachers	36.6	36.0	8.6	22–56	F	73.7%


2.2	AI Use in Teaching and Learning
Contexts of use (e.g., studying, lesson planning, assessment)

2.3	Perceptions and Attitudes Toward AI
Self-assessed AI-related competencies
Levels of trust in AI
Concerns and reservations about AI in education

2.4	Time Spent on AI-Related Activities
Weekly hours dedicated to using AI for study or teaching
Variations across groups

2.5	Tools Used
Most commonly adopted AI tools
Preferences and frequency of use

2.6	Perceived Appropriateness of AI Tools
Tools considered appropriate for educational use
Tools and practices considered unsuitable or discouraged

4	Discussion
5	
6	Conclusion
7	
8	References
