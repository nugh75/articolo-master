{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e5933c7",
   "metadata": {},
   "source": [
    "# Analisi esplorativa dei dati (EDA)\n",
    "\n",
    "Questo notebook esegue un'analisi esplorativa rapida sui file dati presenti nella cartella `data/raw/surveys/`.\n",
    "\n",
    "- Rileva automaticamente file CSV/TSV/XLS/XLSX/JSON\n",
    "- Carica il dataset selezionato\n",
    "- Mostra struttura, valori mancanti e statistiche\n",
    "- Crea alcuni grafici di base e salva output in `analysis/exports/latest/`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c963368",
   "metadata": {},
   "source": [
    "## Cella 2: Installazione dipendenze\n",
    "\n",
    "Questa cella verifica e installa automaticamente le librerie Python necessarie per l'analisi (pandas, numpy, matplotlib, seaborn, openpyxl). Se una libreria manca, viene installata automaticamente tramite pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1507af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se necessario, installa dipendenze (esegui una volta)\n",
    "import sys, subprocess\n",
    "def ensure(pkg):\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "        return True\n",
    "    except Exception:\n",
    "        print(f'Installing {pkg} ...')\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg])\n",
    "        return True\n",
    "\n",
    "for p in ['pandas', 'numpy', 'matplotlib', 'seaborn', 'openpyxl', 'sciencePlots']:\n",
    "    ensure(p)\n",
    "print('Dipendenze pronte.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04408a4d",
   "metadata": {},
   "source": [
    "## Cella 3: Import e configurazione librerie\n",
    "\n",
    "Importa le librerie principali (pandas, numpy, matplotlib, seaborn) e configura le opzioni di visualizzazione per mostrare più righe e colonne. Imposta anche il tema grafico 'whitegrid' di seaborn e stampa le versioni delle librerie utilizzate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b34206e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import e configurazione\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "sns.set_theme(style='whitegrid')\n",
    "print('Versioni:', {\n",
    "    'pandas': pd.__version__,\n",
    "    'numpy': np.__version__\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fa6429",
   "metadata": {},
   "source": [
    "## Cella 4: Definizione percorsi\n",
    "\n",
    "Definisce i percorsi delle cartelle principali del progetto: la cartella dati di input (`data/raw/surveys/`) e la cartella di output per i risultati esplorativi (`analysis/exports/latest/`). Crea automaticamente la cartella di output se non esiste e verifica l'esistenza della cartella dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419be581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percorsi: individua la root del repository e carica i path da config/paths.json\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    for candidate in [start, *start.parents]:\n",
    "        if (candidate / '.git').exists():\n",
    "            return candidate\n",
    "    raise RuntimeError('Impossibile trovare la root del repository')\n",
    "\n",
    "REPO_ROOT = find_repo_root(Path.cwd())\n",
    "with (REPO_ROOT / 'config' / 'paths.json').open() as fp:\n",
    "    PATHS = json.load(fp)\n",
    "\n",
    "DATA_DIR = (REPO_ROOT / PATHS['data']['raw_surveys_dir']).resolve()\n",
    "INTERIM_DIR = (REPO_ROOT / PATHS['data']['interim_dir']).resolve()\n",
    "OUTPUT_DIR = (REPO_ROOT / PATHS['analysis']['exports_latest_dir']).resolve()\n",
    "\n",
    "INTERIM_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('DATA_DIR:', DATA_DIR)\n",
    "print('INTERIM_DIR:', INTERIM_DIR)\n",
    "print('OUTPUT_DIR:', OUTPUT_DIR)\n",
    "assert DATA_DIR.exists(), f'Cartella dati non trovata: {DATA_DIR}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7683e025",
   "metadata": {},
   "source": [
    "## Cella 5: Lista file disponibili\n",
    "\n",
    "Cerca e elenca tutti i file di dati disponibili nella cartella `data/raw/surveys/`. Supporta formati CSV, TSV, Excel (xlsx, xls) e JSON. Mostra un elenco numerato di tutti i file trovati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469cc27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elenco file disponibili\n",
    "from itertools import chain\n",
    "patterns = ['*.csv', '*.tsv', '*.xlsx', '*.xls', '*.json']\n",
    "files = list(chain.from_iterable(DATA_DIR.glob(p) for p in patterns))\n",
    "files = sorted(files)\n",
    "for i, f in enumerate(files, 1):\n",
    "    print(f'{i:2d}.', f.name)\n",
    "if not files:\n",
    "    print('Nessun file trovato in', DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd042b5",
   "metadata": {},
   "source": [
    "## Cella 6: Identificazione file insegnanti e studenti\n",
    "\n",
    "Identifica automaticamente i due file Excel principali (insegnanti e studenti) usando pattern di riconoscimento nei nomi dei file (es. \"insegn\", \"student\", ecc.). Se i pattern non corrispondono, usa i primi due file Excel trovati in ordine alfabetico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8b2ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleziona i due file Excel (insegnanti e studenti)\n",
    "from pathlib import Path\n",
    "import re\n",
    "from itertools import chain\n",
    "\n",
    "# Rileva i file Excel direttamente dalla cartella dati (evita dipendenze dall'ordine di esecuzione di altre celle)\n",
    "excel_files = sorted(chain.from_iterable(DATA_DIR.glob(p) for p in ('*.xlsx', '*.xls')))\n",
    "if not excel_files:\n",
    "    raise FileNotFoundError(f'Nessun file Excel trovato in {DATA_DIR}')\n",
    "\n",
    "# Heuristics per riconoscere i file\n",
    "insegn_patterns = [r'insegn', r'docent', r'teacher']\n",
    "studenti_patterns = [r'student', r'alunn', r'alliev']\n",
    "\n",
    "def match_any(path: Path, patterns):\n",
    "    name = path.name.lower()\n",
    "    return any(re.search(p, name) for p in patterns)\n",
    "\n",
    "file_insegnanti = next((p for p in excel_files if match_any(p, insegn_patterns)), None)\n",
    "file_studenti = next((p for p in excel_files if match_any(p, studenti_patterns)), None)\n",
    "\n",
    "# Fallback: se non riconosciamo i nomi, prendiamo i primi due file\n",
    "if file_insegnanti is None or file_studenti is None:\n",
    "    if len(excel_files) >= 2:\n",
    "        # Ordina per nome per stabilità\n",
    "        ef_sorted = sorted(excel_files)\n",
    "        file_insegnanti = file_insegnanti or ef_sorted[0]\n",
    "        file_studenti = file_studenti or ef_sorted[1]\n",
    "    else:\n",
    "        raise RuntimeError('Meno di due file Excel trovati, impossibile proseguire con insegnanti e studenti.')\n",
    "\n",
    "print('File insegnanti:', file_insegnanti.name)\n",
    "print('File studenti  :', file_studenti.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbb6ed1",
   "metadata": {},
   "source": [
    "## Cella 7: Caricamento dati da Excel\n",
    "\n",
    "Carica i file Excel di insegnanti e studenti. Utilizza la prima riga come intestazioni (domande del questionario), gestisce nomi di colonna duplicati, rimuove righe e colonne completamente vuote, e unifica le strutture dati aggiungendo una colonna \"Gruppo\" per distinguere insegnanti e studenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd26db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica i file usando la prima riga come domande (intestazioni)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "SHEET_NAME = 0  # modifica se serve un foglio diverso\n",
    "\n",
    "# Utility per deduplicare i nomi colonna preservando l'ordine\n",
    "from collections import Counter\n",
    "\n",
    "def dedupe(names):\n",
    "    seen = {}\n",
    "    out = []\n",
    "    for n in names:\n",
    "        key = ('' if n is None or (isinstance(n, float) and np.isnan(n)) else str(n).strip())\n",
    "        key = key if key else 'Senza_nome'\n",
    "        if key not in seen:\n",
    "            seen[key] = 0\n",
    "            out.append(key)\n",
    "        else:\n",
    "            seen[key] += 1\n",
    "            out.append(f\"{key}__{seen[key]}\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def load_survey_excel(path: Path) -> tuple[pd.DataFrame, list]:\n",
    "    df_raw = pd.read_excel(path, sheet_name=SHEET_NAME, header=None)\n",
    "    # Prima riga con le domande\n",
    "    questions = df_raw.iloc[0].tolist()\n",
    "    questions = [str(x).strip() if not (isinstance(x, float) and np.isnan(x)) else '' for x in questions]\n",
    "    questions = [q if q else 'Senza_nome' for q in questions]\n",
    "    questions = dedupe(questions)\n",
    "\n",
    "    # Applica le intestazioni e rimuovi la prima riga\n",
    "    df = df_raw.iloc[1:].copy()\n",
    "    df.columns = questions\n",
    "\n",
    "    # Drop colonne completamente vuote e righe completamente vuote\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    df = df.dropna(axis=0, how='all')\n",
    "    # Reset indice per sicurezza\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df, questions\n",
    "\n",
    "# Caricamento\n",
    "_df_ins, q_insegnanti = load_survey_excel(file_insegnanti)\n",
    "_df_stu, q_studenti = load_survey_excel(file_studenti)\n",
    "\n",
    "# Uniforma le colonne facendo l'unione, riempiendo con NaN dove mancano\n",
    "all_cols = list(dict.fromkeys(list(_df_ins.columns) + list(_df_stu.columns)))  # preserve order\n",
    "_df_ins = _df_ins.reindex(columns=all_cols)\n",
    "_df_stu = _df_stu.reindex(columns=all_cols)\n",
    "\n",
    "# Aggiungi colonna Gruppo\n",
    "_df_ins['Gruppo'] = 'insegnanti'\n",
    "_df_stu['Gruppo'] = 'studenti'\n",
    "\n",
    "# Concatena\n",
    "DF = pd.concat([_df_ins, _df_stu], ignore_index=True)\n",
    "print('Shape insegnanti:', _df_ins.shape)\n",
    "print('Shape studenti  :', _df_stu.shape)\n",
    "print('Shape totale    :', DF.shape)\n",
    "\n",
    "# Verifica differenze di domande fra i due file\n",
    "set_ins, set_stu = set(q_insegnanti), set(q_studenti)\n",
    "solo_insegnanti = [c for c in set_ins - set_stu]\n",
    "solo_studenti = [c for c in set_stu - set_ins]\n",
    "if solo_insegnanti:\n",
    "    print('\\nDomande presenti solo in insegnanti (conteggio:', len(solo_insegnanti), '):')\n",
    "    for x in sorted(solo_insegnanti):\n",
    "        print(' -', x)\n",
    "if solo_studenti:\n",
    "    print('\\nDomande presenti solo in studenti (conteggio:', len(solo_studenti), '):')\n",
    "    for x in sorted(solo_studenti):\n",
    "        print(' -', x)\n",
    "\n",
    "# Salva il dataframe combinato\n",
    "out_csv = OUTPUT_DIR / 'combined_insegnanti_studenti.csv'\n",
    "DF.to_csv(out_csv, index=False)\n",
    "print('\\nSalvato CSV combinato in:', out_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a977a73a",
   "metadata": {},
   "source": [
    "## Cella 8: Concatenazione e verifica differenze\n",
    "\n",
    "Concatena i dataframe di insegnanti e studenti in un unico dataframe (DF). Verifica e stampa le domande presenti solo in uno dei due gruppi. Salva il dataframe combinato in formato CSV per analisi successive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3089a7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrai e stampa la lista completa delle domande (non troncata) e salvala su file\n",
    "# Le domande sono le colonne (esclusa la colonna 'Gruppo')\n",
    "questions_all = [c for c in DF.columns if c != 'Gruppo']\n",
    "\n",
    "print('Numero totale di domande:', len(questions_all))\n",
    "for idx, q in enumerate(questions_all, 1):\n",
    "    print(f\"{idx:3d}. {q}\")\n",
    "\n",
    "# Salva su CSV\n",
    "q_out = OUTPUT_DIR / 'domande_prima_riga_insegnanti_studenti.csv'\n",
    "(\n",
    "    pd.DataFrame({'n': range(1, len(questions_all)+1), 'domanda': questions_all})\n",
    "    .to_csv(q_out, index=False)\n",
    ")\n",
    "print('\\nSalvata lista domande in:', q_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2617de",
   "metadata": {},
   "source": [
    "## Cella 9: Estrazione lista domande\n",
    "\n",
    "Estrae e stampa la lista completa di tutte le domande del questionario (nomi delle colonne esclusa \"Gruppo\"). Salva la lista numerata in un file CSV per riferimento e documentazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412cbd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Costruisce DF_plot con 'GruppoDettaglio' per le 4 categorie richieste\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "assert 'DF' in globals(), 'DF non trovato: esegui prima le celle di caricamento dati.'\n",
    "\n",
    "ORDER = [\n",
    "    'studenti - secondaria',\n",
    "    'studenti - universitari',\n",
    "    'insegnanti - non in servizio',\n",
    "    'insegnanti - in servizio',\n",
    "]\n",
    "\n",
    "# Individua colonna stato insegnamento (per \"attualmente insegni o hai intenzione di insegnare\")\n",
    "STATUS_COL = None\n",
    "for c in DF.columns:\n",
    "    s = str(c).lower()\n",
    "    if all(tok in s for tok in ('insegn',)) and any(tok in s for tok in ('attualmente','adesso','ora','intenz','insegnare','stai')):\n",
    "        STATUS_COL = c\n",
    "        break\n",
    "\n",
    "# Token per classificazione\n",
    "TOK_STU_UNIV = re.compile(r\"univers|ateneo|laure|trienn|magistral\", re.I)\n",
    "TOK_STU_PRIM = re.compile(r\"primaria|primarie\", re.I)\n",
    "TOK_STU_SECO = re.compile(r\"secondaria|superior|liceo|istituto\", re.I)\n",
    "\n",
    "# Stato insegnamento: mappe comuni (case-insensitive)\n",
    "TOK_TCH_STATUS_NON = re.compile(r\"ancora\\s+non\\s+insegno|non\\s+insegno|no,?\\s+ma\\s+ho\\s+intenz|no\\s+\\(intenzione\\)|pre\\s*-?serv|tirocin|tfa|sfp|laureand|studente|abilitaz\", re.I)\n",
    "TOK_TCH_STATUS_IN  = re.compile(r\"s[ìi],?\\s*attualmente\\s*insegno|attualmente\\s*insegno|ora\\s*insegno|in\\s+servizio\", re.I)\n",
    "\n",
    "# Utility: testo unificato per riga (valori non null)\n",
    "def row_text(r: pd.Series) -> str:\n",
    "    parts = []\n",
    "    for v in r.values:\n",
    "        if pd.isna(v):\n",
    "            continue\n",
    "        s = str(v).strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        if re.fullmatch(r\"\\d+(\\.\\d+)?\", s):\n",
    "            continue\n",
    "        parts.append(s)\n",
    "    return (\" \".join(parts)).lower()\n",
    "\n",
    "# Classificatore riga -> GruppoDettaglio\n",
    "def classify_row(r: pd.Series) -> str:\n",
    "    g = str(r.get('Gruppo', '')).strip().lower()\n",
    "\n",
    "    if g == 'studenti':\n",
    "        text = row_text(r)\n",
    "        if TOK_STU_UNIV.search(text):\n",
    "            return 'studenti - universitari'\n",
    "        if TOK_STU_PRIM.search(text):\n",
    "            return 'studenti - primaria'\n",
    "        if TOK_STU_SECO.search(text):\n",
    "            return 'studenti - secondaria'\n",
    "        return 'studenti - secondaria'\n",
    "\n",
    "    if g == 'insegnanti':\n",
    "        # Se disponibile, usa la colonna stato insegnamento (più affidabile)\n",
    "        if STATUS_COL is not None:\n",
    "            val = str(r.get(STATUS_COL, '')).strip().lower()\n",
    "            if TOK_TCH_STATUS_NON.search(val):\n",
    "                return 'insegnanti - non in servizio'\n",
    "            if TOK_TCH_STATUS_IN.search(val):\n",
    "                return 'insegnanti - in servizio'\n",
    "        # Fallback: pattern generali nel testo della riga\n",
    "        text = row_text(r)\n",
    "        if TOK_TCH_STATUS_NON.search(text):\n",
    "            return 'insegnanti - non in servizio'\n",
    "        if TOK_TCH_STATUS_IN.search(text):\n",
    "            return 'insegnanti - in servizio'\n",
    "        return 'insegnanti - in servizio'\n",
    "\n",
    "    return g or 'sconosciuto'\n",
    "\n",
    "DF_plot = DF.copy()\n",
    "DF_plot['GruppoDettaglio'] = DF_plot.apply(classify_row, axis=1)\n",
    "\n",
    "# Categoria ordinata (includiamo eventuali classi extra senza ordinarle)\n",
    "DF_plot['GruppoDettaglio'] = pd.Categorical(\n",
    "    DF_plot['GruppoDettaglio'],\n",
    "    categories=ORDER + [c for c in DF_plot['GruppoDettaglio'].unique() if c not in ORDER],\n",
    "    ordered=True,\n",
    ")\n",
    "\n",
    "# Report rapido di controllo\n",
    "print('Colonna stato insegnamento:', STATUS_COL)\n",
    "print('Distribuzione by Gruppo:')\n",
    "print(DF_plot['Gruppo'].value_counts(dropna=False))\n",
    "print('\\nDistribuzione by GruppoDettaglio:')\n",
    "print(DF_plot['GruppoDettaglio'].value_counts(dropna=False))\n",
    "\n",
    "# Salva di servizio\n",
    "(OUTPUT_DIR / 'classificazione').mkdir(parents=True, exist_ok=True)\n",
    "DF_plot[['Gruppo','GruppoDettaglio']].value_counts().to_csv(OUTPUT_DIR / 'classificazione' / 'conteggi_gruppi.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e7bae6",
   "metadata": {},
   "source": [
    "## Cella 10: Classificazione in 4 gruppi dettagliati\n",
    "\n",
    "Classifica i partecipanti in 4 categorie dettagliate:\n",
    "- studenti - secondaria\n",
    "- studenti - universitari  \n",
    "- insegnanti - non in servizio\n",
    "- insegnanti - in servizio\n",
    "\n",
    "Utilizza pattern di ricerca testuale per identificare il livello scolastico degli studenti e lo stato lavorativo degli insegnanti. Crea la colonna \"GruppoDettaglio\" nel dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fb4377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica classificazione: distribuzione risposte stato insegnamento e crosstab con GruppoDettaglio\n",
    "assert 'DF_plot' in globals(), 'DF_plot non trovato: esegui la cella di classificazione.'\n",
    "\n",
    "if STATUS_COL is None:\n",
    "    print('Nessuna colonna di stato insegnamento trovata.')\n",
    "else:\n",
    "    vc = (\n",
    "        DF.loc[DF['Gruppo'].eq('insegnanti'), STATUS_COL]\n",
    "          .astype(str)\n",
    "          .str.strip()\n",
    "          .value_counts(dropna=False)\n",
    "    )\n",
    "    print('Valori distinti (insegnanti) per', STATUS_COL, ':')\n",
    "    print(vc)\n",
    "\n",
    "    # Crosstab fra stato testuale e categoria assegnata\n",
    "    tab = pd.crosstab(\n",
    "        DF_plot.loc[DF_plot['Gruppo'].eq('insegnanti'), 'GruppoDettaglio'],\n",
    "        DF.loc[DF['Gruppo'].eq('insegnanti'), STATUS_COL].astype(str).str.strip(),\n",
    "        dropna=False\n",
    "    )\n",
    "    display(tab)\n",
    "\n",
    "    out = OUTPUT_DIR / 'classificazione' / 'crosstab_gruppo_vs_stato_insegnamento.csv'\n",
    "    tab.to_csv(out)\n",
    "    print('Crosstab salvata in:', out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b644379",
   "metadata": {},
   "source": [
    "## Configurazioni condivise per grafici bilingue e ordine gruppi\n",
    "\n",
    "Definisce costanti globali utilizzate in tutto il notebook per garantire coerenza tra i grafici in italiano e inglese:\n",
    "\n",
    "- **Palette colori** (`PALETTE_4GROUPS`): Assegna colori specifici a ciascun gruppo (rosso=studenti secondaria, verde=universitari, blu=insegnanti in servizio, giallo=non in servizio)\n",
    "- **Ordine gruppi** (`ORDER`, `ORDER_4`): Sequenza standard per visualizzazioni e analisi\n",
    "- **Etichette bilingue** (`GROUP_LABELS`): Mappatura italiano↔inglese dei nomi dei gruppi\n",
    "- **Etichette assi** (`LANG_AXES`): Titoli degli assi in italiano e inglese per grafici\n",
    "\n",
    "Queste configurazioni vengono richiamate nelle celle successive per garantire uniformità visiva e semantica in tutti i grafici generati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c089c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurazioni condivise per grafici bilingue e ordine gruppi\n",
    "ORDER_4 = [\n",
    "    'studenti - secondaria',\n",
    "    'studenti - universitari',\n",
    "    'insegnanti - non in servizio',\n",
    "    'insegnanti - in servizio',\n",
    "]\n",
    "\n",
    "GROUP_LABELS = {\n",
    "    'it': {\n",
    "        'studenti - secondaria': 'Studenti - secondaria',\n",
    "        'studenti - universitari': 'Studenti - universitari',\n",
    "        'insegnanti - non in servizio': 'Insegnanti - non in servizio',\n",
    "        'insegnanti - in servizio': 'Insegnanti - in servizio',\n",
    "    },\n",
    "    'en': {\n",
    "        'studenti - secondaria': 'Students - secondary',\n",
    "        'studenti - universitari': 'Students - university',\n",
    "        'insegnanti - non in servizio': 'Teachers - pre-service',\n",
    "        'insegnanti - in servizio': 'Teachers - in-service',\n",
    "    }\n",
    "}\n",
    "\n",
    "LANG_AXES = {\n",
    "    'it': {'xlabel': 'Gruppo', 'ylabel': 'Valore'},\n",
    "    'en': {'xlabel': 'Group', 'ylabel': 'Value'},\n",
    "}\n",
    "\n",
    "PALETTE_4GROUPS = {\n",
    "    'studenti - secondaria': '#e41a1c',\n",
    "    'studenti - universitari': '#4daf4a',\n",
    "    'insegnanti - non in servizio': '#ffd31a',\n",
    "    'insegnanti - in servizio': '#377eb8',\n",
    "}\n",
    "\n",
    "def map_group_label(value, lang='it'):\n",
    "    return GROUP_LABELS.get(lang, {}).get(value, str(value))\n",
    "\n",
    "def map_group_series(series, lang='it'):\n",
    "    mapping = GROUP_LABELS.get(lang, {})\n",
    "    return series.map(lambda v: mapping.get(v, str(v)))\n",
    "\n",
    "def _iqr_mask(series):\n",
    "    q1 = series.quantile(0.25)\n",
    "    q3 = series.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    if pd.isna(iqr) or iqr == 0:\n",
    "        return series.between(q1, q3)\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    return series.between(lower, upper)\n",
    "\n",
    "def bilingual_violin_box(\n",
    "    df,\n",
    "    value_col,\n",
    "    group_col='GruppoDettaglio',\n",
    "    order=None,\n",
    "    palette=None,\n",
    "    slug=None,\n",
    "    title_it='',\n",
    "    title_en='',\n",
    "    ylabel_it=None,\n",
    "    ylabel_en=None,\n",
    "    xlabel_it=None,\n",
    "    xlabel_en=None,\n",
    "    trim_outliers=False,\n",
    "    save_csv=False,\n",
    "    summary_suffix='_summary.csv',\n",
    "    data_suffix='_data.csv',\n",
    "    show_strip=True,\n",
    "):\n",
    "    \"\"\"Crea violin e box plot bilingue (IT/EN) e salva gli output richiesti.\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    order = order or ORDER_4\n",
    "    palette = palette or PALETTE_4GROUPS\n",
    "\n",
    "    data = df[[group_col, value_col]].dropna().copy()\n",
    "    data = data[data[group_col].isin(order)]\n",
    "    if data.empty:\n",
    "        print(f\"⚠️ Nessun dato disponibile per {slug or value_col}\")\n",
    "        return data, None\n",
    "\n",
    "    data[group_col] = pd.Categorical(data[group_col], categories=order, ordered=True)\n",
    "\n",
    "    if trim_outliers:\n",
    "        filtered = []\n",
    "        for grp in order:\n",
    "            subset = data[data[group_col] == grp]\n",
    "            if subset.empty:\n",
    "                continue\n",
    "            mask = _iqr_mask(subset[value_col])\n",
    "            filtered.append(subset[mask])\n",
    "        if filtered:\n",
    "            data = pd.concat(filtered, ignore_index=True)\n",
    "\n",
    "    stats = (\n",
    "        data.groupby(group_col, observed=False)[value_col]\n",
    "            .agg(\n",
    "                conteggio='count',\n",
    "                media='mean',\n",
    "                mediana='median',\n",
    "                sd='std',\n",
    "                q1=lambda s: s.quantile(0.25),\n",
    "                q3=lambda s: s.quantile(0.75),\n",
    "            )\n",
    "            .round(2)\n",
    "    )\n",
    "\n",
    "    print(f\"\\nStatistiche per {slug or value_col}:\")\n",
    "    print(stats)\n",
    "\n",
    "    def _save_csv(payload, suffix):\n",
    "        if slug and save_csv:\n",
    "            out_path = OUTPUT_DIR / f\"{slug}{suffix}\"\n",
    "            payload.to_csv(out_path, index=False)\n",
    "            print('  ↳ Salvato', out_path)\n",
    "\n",
    "    if save_csv:\n",
    "        _save_csv(data[[group_col, value_col]].copy(), data_suffix)\n",
    "        _save_csv(stats.reset_index(), summary_suffix)\n",
    "\n",
    "    for lang in ('it', 'en'):\n",
    "        lang_title = title_it if lang == 'it' else (title_en or title_it)\n",
    "        ylabel = ylabel_it if lang == 'it' else (ylabel_en or ylabel_it or LANG_AXES[lang]['ylabel'])\n",
    "        xlabel = xlabel_it if lang == 'it' else (xlabel_en or LANG_AXES[lang]['xlabel'])\n",
    "        display_df = data.copy()\n",
    "        display_df['__group_display'] = map_group_series(display_df[group_col], lang)\n",
    "        order_lang = [map_group_label(g, lang) for g in order if g in data[group_col].cat.categories]\n",
    "        palette_lang = {map_group_label(k, lang): v for k, v in palette.items() if k in order}\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 5.5))\n",
    "        sns.violinplot(\n",
    "            data=display_df,\n",
    "            x='__group_display',\n",
    "            y=value_col,\n",
    "            order=order_lang,\n",
    "            palette=palette_lang,\n",
    "            hue='__group_display',\n",
    "            legend=False,\n",
    "            inner='quartile',\n",
    "            cut=0,\n",
    "            density_norm='width',\n",
    "            ax=ax,\n",
    "        )\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_ylabel(ylabel)\n",
    "        if lang_title:\n",
    "            ax.set_title(lang_title)\n",
    "        ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "        ax.set_axisbelow(True)\n",
    "        for tick in ax.get_xticklabels():\n",
    "            tick.set_rotation(10)\n",
    "            tick.set_ha('right')\n",
    "        sns.despine(ax=ax)\n",
    "        plt.tight_layout()\n",
    "        if slug:\n",
    "            fig.savefig(OUTPUT_DIR / f\"{slug}_{lang}_violin.png\", dpi=150)\n",
    "            fig.savefig(OUTPUT_DIR / f\"{slug}_{lang}_violin.svg\", dpi=150)\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "        fig_box, ax_box = plt.subplots(figsize=(10, 5.5))\n",
    "        sns.boxplot(\n",
    "            data=display_df,\n",
    "            x='__group_display',\n",
    "            y=value_col,\n",
    "            order=order_lang,\n",
    "            palette=palette_lang,\n",
    "            hue='__group_display',\n",
    "            legend=False,\n",
    "            showfliers=not trim_outliers,\n",
    "            ax=ax_box,\n",
    "        )\n",
    "        if show_strip:\n",
    "            sns.stripplot(\n",
    "                data=display_df,\n",
    "                x='__group_display',\n",
    "                y=value_col,\n",
    "                order=order_lang,\n",
    "                hue='__group_display',\n",
    "                palette=palette_lang,\n",
    "                dodge=False,\n",
    "                size=3,\n",
    "                alpha=0.7,\n",
    "                linewidth=0,\n",
    "                ax=ax_box,\n",
    "            )\n",
    "        if ax_box.get_legend():\n",
    "            ax_box.get_legend().remove()\n",
    "        ax_box.set_xlabel(xlabel)\n",
    "        ax_box.set_ylabel(ylabel)\n",
    "        title_box = f\"{lang_title} — box\" if lang_title else 'Box plot'\n",
    "        ax_box.set_title(title_box)\n",
    "        ax_box.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "        ax_box.set_axisbelow(True)\n",
    "        for tick in ax_box.get_xticklabels():\n",
    "            tick.set_rotation(10)\n",
    "            tick.set_ha('right')\n",
    "        sns.despine(ax=ax_box)\n",
    "        plt.tight_layout()\n",
    "        if slug:\n",
    "            fig_box.savefig(OUTPUT_DIR / f\"{slug}_{lang}_box.png\", dpi=150)\n",
    "            fig_box.savefig(OUTPUT_DIR / f\"{slug}_{lang}_box.svg\", dpi=150)\n",
    "        plt.show()\n",
    "        plt.close(fig_box)\n",
    "\n",
    "    return data, stats\n",
    "\n",
    "\n",
    "\n",
    "def ensure_df_age(force=False, verbose=True):\n",
    "    \"\"\"Garantisce che i dataframe sull'età siano disponibili.\"\"\"\n",
    "    import re\n",
    "    import pandas as pd\n",
    "\n",
    "    global df_age, df_age_trimmed, age_stats_full, age_stats_trimmed\n",
    "\n",
    "    already_available = (\n",
    "        'df_age' in globals() and 'df_age_trimmed' in globals()\n",
    "        and df_age is not None and df_age_trimmed is not None\n",
    "    )\n",
    "    if already_available and not force:\n",
    "        if verbose:\n",
    "            print('df_age già disponibile (usa force=True per rigenerare).')\n",
    "        return df_age, df_age_trimmed, age_stats_full, age_stats_trimmed\n",
    "\n",
    "    assert 'DF' in globals(), 'DF non trovato: esegui la cella di caricamento dati.'\n",
    "    assert 'DF_plot' in globals(), 'DF_plot non trovato: esegui le celle precedenti.'\n",
    "\n",
    "    col_eta = None\n",
    "    for tokens in (('quanti', 'anni'), ('eta',), ('età',)):\n",
    "        for col in DF.columns:\n",
    "            label = str(col).lower()\n",
    "            if all(tok in label for tok in tokens):\n",
    "                col_eta = col\n",
    "                break\n",
    "        if col_eta:\n",
    "            break\n",
    "    if col_eta is None:\n",
    "        raise RuntimeError('Colonna età non trovata nel dataset')\n",
    "\n",
    "    col_insegn_ordine = None\n",
    "    for col in DF.columns:\n",
    "        txt = str(col).lower()\n",
    "        if all(token in txt for token in ('ordine', 'scuola')):\n",
    "            col_insegn_ordine = col\n",
    "            break\n",
    "\n",
    "    num_re = re.compile(r'(\\d{1,3})')\n",
    "\n",
    "    def to_age(value):\n",
    "        if pd.isna(value):\n",
    "            return pd.NA\n",
    "        if isinstance(value, (int, float)):\n",
    "            num = float(value)\n",
    "        else:\n",
    "            match = num_re.search(str(value))\n",
    "            if not match:\n",
    "                return pd.NA\n",
    "            num = float(match.group(1))\n",
    "        return num if 5 <= num <= 100 else pd.NA\n",
    "\n",
    "    age_base = DF_plot.copy()\n",
    "    age_base['Eta'] = DF[col_eta].apply(to_age)\n",
    "\n",
    "    mask_primary = age_base['GruppoDettaglio'].astype(str).str.contains('studenti - primaria', case=False, na=False)\n",
    "    mask_univ = pd.Series(False, index=age_base.index)\n",
    "    if col_insegn_ordine is not None:\n",
    "        teacher_mask = age_base['Gruppo'].astype(str).str.contains('insegnanti', case=False, na=False)\n",
    "        school_text = DF[col_insegn_ordine].astype(str).str.lower()\n",
    "        mask_univ = teacher_mask & school_text.str.contains('univers|ateneo|univ', regex=True, na=False)\n",
    "\n",
    "    filtered = age_base.loc[~mask_primary & ~mask_univ].copy()\n",
    "    filtered = filtered[filtered['GruppoDettaglio'].isin(ORDER_4)]\n",
    "    filtered = filtered[filtered['Eta'].notna()]\n",
    "    filtered['GruppoDettaglio'] = pd.Categorical(filtered['GruppoDettaglio'], categories=ORDER_4, ordered=True)\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Esempi validati: {len(filtered)} osservazioni')\n",
    "\n",
    "    df_full = filtered[['GruppoDettaglio', 'Eta']].copy()\n",
    "\n",
    "    def compute_stats(frame):\n",
    "        if frame.empty:\n",
    "            return pd.DataFrame(columns=['GruppoDettaglio', 'conteggio', 'media', 'mediana', 'sd', 'q1', 'q3'])\n",
    "        return (\n",
    "            frame.groupby('GruppoDettaglio', observed=False)['Eta']\n",
    "                 .agg(\n",
    "                     conteggio='count',\n",
    "                     media='mean',\n",
    "                     mediana='median',\n",
    "                     sd='std',\n",
    "                     q1=lambda s: s.quantile(0.25),\n",
    "                     q3=lambda s: s.quantile(0.75),\n",
    "                 )\n",
    "                 .round(2)\n",
    "        )\n",
    "\n",
    "    trimmed_parts = []\n",
    "    for grp in ORDER_4:\n",
    "        subset = df_full[df_full['GruppoDettaglio'] == grp]\n",
    "        if subset.empty:\n",
    "            continue\n",
    "        eta_vals = subset['Eta']\n",
    "        q1 = eta_vals.quantile(0.25)\n",
    "        q3 = eta_vals.quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        if pd.isna(iqr) or iqr == 0:\n",
    "            trimmed_parts.append(subset)\n",
    "            continue\n",
    "        lower = q1 - 1.5 * iqr\n",
    "        upper = q3 + 1.5 * iqr\n",
    "        trimmed_parts.append(subset[(subset['Eta'] >= lower) & (subset['Eta'] <= upper)])\n",
    "\n",
    "    df_trim = pd.concat(trimmed_parts, ignore_index=True) if trimmed_parts else df_full.copy()\n",
    "    stats_full = compute_stats(df_full)\n",
    "    stats_trim = compute_stats(df_trim)\n",
    "\n",
    "    df_age = df_full.copy()\n",
    "    df_age_trimmed = df_trim.copy()\n",
    "    age_stats_full = stats_full.copy()\n",
    "    age_stats_trimmed = stats_trim.copy()\n",
    "\n",
    "    if verbose:\n",
    "        print('I dataframe df_age e df_age_trimmed sono pronti per le celle successive.')\n",
    "\n",
    "    return df_age, df_age_trimmed, age_stats_full, age_stats_trimmed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eddce8",
   "metadata": {},
   "source": [
    "## Cella 11: Verifica classificazione\n",
    "\n",
    "Verifica la classificazione creata nella cella precedente. Mostra la distribuzione delle risposte alla domanda sullo stato dell'insegnamento e crea una crosstab tra Gruppo e GruppoDettaglio per controllare la coerenza della classificazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed40520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versioni publication-ready per i grafici sull'età\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import unicodedata\n",
    "\n",
    "# Helper per garantire df_age disponibile\n",
    "\n",
    "def _normalize(s: str) -> str:\n",
    "    return ''.join(c for c in unicodedata.normalize('NFKD', s) if not unicodedata.combining(c)).lower().replace(' ', '')\n",
    "\n",
    "def ensure_df_age(verbose: bool = False, force: bool = False):\n",
    "    global df_age\n",
    "    if not force and 'df_age' in globals() and isinstance(df_age, pd.DataFrame) and {'GruppoDettaglio', 'Eta'}.issubset(df_age.columns):\n",
    "        if verbose:\n",
    "            print('[ensure_df_age] df_age già presente.')\n",
    "        return df_age\n",
    "    if 'DF_plot' not in globals() or not isinstance(DF_plot, pd.DataFrame):\n",
    "        raise RuntimeError('DF_plot non disponibile: esegui prima le celle di classificazione (cella con DF_plot).')\n",
    "    if 'DF' not in globals() or not isinstance(DF, pd.DataFrame):\n",
    "        raise RuntimeError('DF non disponibile: esegui le celle di caricamento dati.')\n",
    "\n",
    "    # Identifica colonna età: scegli quella con molti valori tra 10 e 100\n",
    "    age_candidates = []\n",
    "    for c in DF.columns:\n",
    "        s = pd.to_numeric(DF[c], errors='coerce')\n",
    "        valid = s.between(10, 100).sum()\n",
    "        if valid >= 50:  # soglia\n",
    "            age_candidates.append((c, valid))\n",
    "    age_candidates.sort(key=lambda x: -x[1])\n",
    "    if not age_candidates:\n",
    "        raise RuntimeError('Nessuna colonna con valori plausibili di età trovata.')\n",
    "    age_col = age_candidates[0][0]\n",
    "\n",
    "    # Usa DF_plot che ha GruppoDettaglio già classificato\n",
    "    if 'GruppoDettaglio' not in DF_plot.columns:\n",
    "        raise RuntimeError('Colonna GruppoDettaglio non trovata in DF_plot.')\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[ensure_df_age] Colonna età selezionata: {age_col}\")\n",
    "        print(f\"[ensure_df_age] Uso DF_plot con GruppoDettaglio già classificato\")\n",
    "\n",
    "    tmp = DF_plot[['GruppoDettaglio']].copy()\n",
    "    tmp['Eta'] = pd.to_numeric(DF[age_col], errors='coerce')\n",
    "    df_age = tmp.dropna(subset=['Eta', 'GruppoDettaglio'])\n",
    "    if verbose:\n",
    "        print(f\"[ensure_df_age] Righe valide: {len(df_age)}\")\n",
    "        print(df_age['GruppoDettaglio'].value_counts())\n",
    "    return df_age\n",
    "\n",
    "# Stile\n",
    "try:\n",
    "    plt.style.reload_library()\n",
    "    plt.style.use(['science', 'no-latex', 'grid'])\n",
    "except Exception:\n",
    "    plt.style.use('default')\n",
    "    mpl.rcParams.update({'axes.grid': True, 'grid.alpha': 0.3, 'grid.linestyle': '--'})\n",
    "\n",
    "mpl.rcParams.update({'text.usetex': False,'font.family': 'DejaVu Sans','font.size': 8,'savefig.dpi': 300})\n",
    "\n",
    "# df_age\n",
    "ensure_df_age(verbose=True)\n",
    "\n",
    "# Filtra solo i 4 gruppi principali\n",
    "df_age_4groups = df_age[df_age['GruppoDettaglio'].isin(ORDER_4)].copy()\n",
    "\n",
    "# Limita ai valori plausibili per i grafici\n",
    "AGE_MIN, AGE_MAX = 10, 80\n",
    "df_age_plot = df_age_4groups[(df_age_4groups['Eta'] >= AGE_MIN) & (df_age_4groups['Eta'] <= AGE_MAX)].copy()\n",
    "\n",
    "# Usa l'ordine e la palette dei 4 gruppi\n",
    "order = ORDER_4\n",
    "palette = PALETTE_4GROUPS\n",
    "\n",
    "# Calcola outlier con metodo IQR (senza limiti di età per identificare tutti gli outlier)\n",
    "stats_publication = (df_age_4groups.groupby('GruppoDettaglio', observed=False)['Eta'].agg(q1=lambda s: s.quantile(0.25), q3=lambda s: s.quantile(0.75)))\n",
    "stats_publication['iqr'] = stats_publication['q3'] - stats_publication['q1']\n",
    "stats_publication['lower'] = stats_publication['q1'] - 1.5 * stats_publication['iqr']\n",
    "stats_publication['upper'] = stats_publication['q3'] + 1.5 * stats_publication['iqr']\n",
    "merged = df_age_4groups.merge(stats_publication, on='GruppoDettaglio', how='left')\n",
    "\n",
    "inliers = merged[(merged['Eta'] >= merged['lower']) & (merged['Eta'] <= merged['upper'])]\n",
    "outliers = merged[(merged['Eta'] < merged['lower']) | (merged['Eta'] > merged['upper'])]\n",
    "\n",
    "# Boxplot orizzontale con outlier\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "sns.boxplot(data=inliers, x='Eta', y='GruppoDettaglio', order=order, palette=palette, \n",
    "            hue='GruppoDettaglio', legend=False, ax=ax, showfliers=False)\n",
    "for grp in order:\n",
    "    grp_out = outliers[outliers['GruppoDettaglio'] == grp]['Eta']\n",
    "    if not grp_out.empty:\n",
    "        y_pos = order.index(grp)\n",
    "        ax.scatter(grp_out, [y_pos]*len(grp_out), color=palette[grp], s=20, alpha=0.7, \n",
    "                   edgecolor='black', linewidth=0.5, marker='o', zorder=3)\n",
    "ax.set_xlabel('Età')\n",
    "ax.set_ylabel('')\n",
    "ax.xaxis.set_major_locator(MultipleLocator(10))\n",
    "ax.set_xlim(AGE_MIN, AGE_MAX)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR/'age_boxplot_publication_h.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Limita ai valori plausibili per l'istogramma\n",
    "df_age_plot = df_age_4groups[(df_age_4groups['Eta'] >= AGE_MIN) & (df_age_4groups['Eta'] <= AGE_MAX)].copy()\n",
    "\n",
    "# Istogramma\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "bins = range(AGE_MIN, AGE_MAX + 1, 5)\n",
    "ax.hist(df_age_plot['Eta'], bins=bins, color='steelblue', edgecolor='black', linewidth=0.4, alpha=0.75)\n",
    "ax.set_xlabel('Età')\n",
    "ax.set_ylabel('Frequenza')\n",
    "ax.xaxis.set_major_locator(MultipleLocator(10))\n",
    "ax.set_xlim(AGE_MIN, AGE_MAX)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR/'age_histogram_publication.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('[age_plots] Salvati grafici pub-ready.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a46841c",
   "metadata": {},
   "source": [
    "# 0. Profilo del campione\n",
    "\n",
    "Panoramica demografica delle quattro categorie principali e delle categorie escluse, necessaria per leggere le differenze d'uso nelle sezioni successive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1880c9da",
   "metadata": {},
   "source": [
    "## 0.1 Distribuzione dell'età nei quattro cluster\n",
    "\n",
    "Applichiamo i filtri (categorie escluse comprese) e produciamo, nella stessa cella, violin plot e box plot in italiano e in inglese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c139ee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Età – dataset filtrato e grafici bilingui\n",
    "print('=== Controllo categorie ===')\n",
    "excluded_counts = (\n",
    "    DF_plot[~DF_plot['GruppoDettaglio'].isin(ORDER_4)]['GruppoDettaglio']\n",
    "    .value_counts(dropna=False)\n",
    ")\n",
    "if excluded_counts.empty:\n",
    "    print('Nessuna categoria extra oltre alle quattro principali')\n",
    "else:\n",
    "    print('Categorie escluse monitorate:')\n",
    "    print(excluded_counts)\n",
    "\n",
    "ensure_df_age(force=True, verbose=True)\n",
    "\n",
    "# FILTRO CRITICO: Rimuovi valori di età assurdi (errori di input)\n",
    "# Mantieni solo valori ragionevoli tra 10 e 100 anni\n",
    "df_age_clean = df_age[(df_age['Eta'] >= 10) & (df_age['Eta'] <= 100)].copy()\n",
    "\n",
    "# Filtra solo i 4 gruppi principali\n",
    "df_age_clean = df_age_clean[df_age_clean['GruppoDettaglio'].isin(ORDER_4)].copy()\n",
    "\n",
    "print(f\"Dati puliti: {len(df_age_clean)} righe valide (da {len(df_age)} originali)\")\n",
    "print(f\"Righe rimosse per età anomala: {len(df_age) - len(df_age_clean)}\")\n",
    "\n",
    "# Grafici bilingui principali\n",
    "df_age_full, age_stats = bilingual_violin_box(\n",
    "    df_age_clean[['GruppoDettaglio', 'Eta']].copy(),\n",
    "    value_col='Eta',\n",
    "    slug='eta_full',\n",
    "    title_it='Distribuzione età per gruppo (campione completo)',\n",
    "    title_en='Age distribution by group (full sample)',\n",
    "    ylabel_it='Età (anni)',\n",
    "    ylabel_en='Age (years)',\n",
    "    save_csv=True,\n",
    ")\n",
    "\n",
    "df_age_trimmed, age_stats_trimmed = bilingual_violin_box(\n",
    "    df_age_clean[['GruppoDettaglio', 'Eta']].copy(),\n",
    "    value_col='Eta',\n",
    "    slug='eta_trimmed',\n",
    "    title_it='Distribuzione età per gruppo (senza outlier)',\n",
    "    title_en='Age distribution by group (trimmed)',\n",
    "    ylabel_it='Età (anni)',\n",
    "    ylabel_en='Age (years)',\n",
    "    trim_outliers=True,\n",
    ")\n",
    "\n",
    "# Rende disponibili i dataframe alle celle successive\n",
    "df_age = df_age_full.copy()\n",
    "df_age_trimmed = df_age_trimmed.copy()\n",
    "age_stats_full = age_stats.copy()\n",
    "age_stats_trimmed = age_stats_trimmed.copy()\n",
    "print('I dataframe df_age e df_age_trimmed sono pronti per le celle successive.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf9c8a6",
   "metadata": {},
   "source": [
    "## 0.2 Distribuzione di genere\n",
    "\n",
    "Conteggi e grafici bilingui (violin e box non applicabili; usiamo barre per categorie nominali)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa60fd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conteggi GENERE per Gruppo (pulito: solo questa cella per il genere)\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Utility: normalizza stringhe\n",
    "_def_na = {None, np.nan}\n",
    "\n",
    "def _norm(s):\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    try:\n",
    "        s = str(s).strip()\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "    return s\n",
    "\n",
    "def _find_col(tokens, cols):\n",
    "    \"\"\"Trova una colonna contenente TUTTI i token (case-insensitive).\"\"\"\n",
    "    toks = [t.lower() for t in tokens]\n",
    "    for c in cols:\n",
    "        lc = c.lower()\n",
    "        if all(t in lc for t in toks):\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "# Ricostruisco un base filtrato coerente con le analisi età\n",
    "base_g = DF_plot.copy()\n",
    "all_cols = list(DF.columns)\n",
    "\n",
    "# Colonna genere (preferisce quella con 'genere', altrimenti 'sesso')\n",
    "col_genere = _find_col([\"genere\"], all_cols) or _find_col([\"sesso\"], all_cols)\n",
    "if col_genere is None:\n",
    "    raise RuntimeError(\"Colonna del genere non trovata (atteso 'genere' o 'sesso').\")\n",
    "\n",
    "# Porto la colonna nel base (allineamento per indice)\n",
    "if col_genere not in base_g.columns:\n",
    "    base_g[col_genere] = DF[col_genere]\n",
    "\n",
    "# Colonna ordine di scuola per escludere docenti universitari (se disponibile)\n",
    "col_insegn_ordine = _find_col([\"ordine\", \"scuola\"], all_cols)\n",
    "if col_insegn_ordine and col_insegn_ordine not in base_g.columns:\n",
    "    base_g[col_insegn_ordine] = DF[col_insegn_ordine]\n",
    "\n",
    "# Filtri: rimuovo studenti primaria e docenti universitari\n",
    "mask_primaria = base_g[\"GruppoDettaglio\"].str.contains(\"studenti - primaria\", case=False, na=False)\n",
    "mask_univ = False\n",
    "if col_insegn_ordine:\n",
    "    mask_univ = (\n",
    "        base_g[\"Gruppo\"].str.contains(\"insegnanti\", case=False, na=False)\n",
    "        & base_g[col_insegn_ordine].astype(str).str.contains(\"univers|ateneo|univ\", case=False, na=False, regex=True)\n",
    "    )\n",
    "base_gf = base_g.loc[~mask_primaria & ~mask_univ].copy()\n",
    "\n",
    "# Normalizzazione GENERE in tre categorie\n",
    "GEN_ORDER = [\"Maschio\", \"Femmina\", \"Non risponde\"]\n",
    "\n",
    "def _norm_genere(v):\n",
    "    s = _norm(v).lower()\n",
    "    if s == \"\" or \"non risp\" in s or \"preferisc\" in s:\n",
    "        return \"Non risponde\"\n",
    "    if s in {\"m\", \"maschio\"} or \"masch\" in s or \"uomo\" in s:\n",
    "        return \"Maschio\"\n",
    "    if s in {\"f\", \"femmina\"} or \"femm\" in s or \"donna\" in s:\n",
    "        return \"Femmina\"\n",
    "    # qualunque altra voce la riconduco a Non risponde per la tabella richiesta\n",
    "    return \"Non risponde\"\n",
    "\n",
    "base_gf[\"GenereCat\"] = base_gf[col_genere].map(_norm_genere)\n",
    "\n",
    "cont_genere_main = (\n",
    "    pd.crosstab(base_gf[\"GruppoDettaglio\"], base_gf[\"GenereCat\"]).reindex(columns=GEN_ORDER, fill_value=0)\n",
    ")\n",
    "\n",
    "# Esporta CSV\n",
    "out_dir = Path(\"output\")/\"exploratory\"/\"demographics\"/\"gender\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "(p_gen_main := out_dir/\"gender_counts_by_group.csv\")\n",
    "cont_genere_main.to_csv(p_gen_main)\n",
    "\n",
    "print(\"Colonna GENERE:\", col_genere)\n",
    "print(\"✓ CSV salvato:\", p_gen_main)\n",
    "print(\"\\nConteggi GENERE per Gruppo:\")\n",
    "print(cont_genere_main)\n",
    "\n",
    "# Controllo somme per riga rispetto al totale per gruppo\n",
    "row_sum = cont_genere_main.sum(axis=1)\n",
    "check_df = pd.concat({\"totale\": base_gf.groupby(\"GruppoDettaglio\").size(), \"somma_tab\": row_sum}, axis=1)\n",
    "print(\"\\nVerifica somma per gruppo (totale vs somma_tab):\")\n",
    "print(check_df)\n",
    "\n",
    "# ============================================================================\n",
    "# GENERAZIONE GRAFICI BILINGUE (EN + IT)\n",
    "# ============================================================================\n",
    "\n",
    "# Traduzioni\n",
    "labels_it_en = {\n",
    "    'studenti - secondaria': 'students - secondary',\n",
    "    'studenti - universitari': 'students - university',\n",
    "    'insegnanti - non in servizio': 'teachers - pre-service',\n",
    "    'insegnanti - in servizio': 'teachers - in-service',\n",
    "}\n",
    "\n",
    "# Colori per genere\n",
    "color_m = '#4A90E2'  # Blu per maschi\n",
    "color_f = '#E94B3C'  # Rosso per femmine\n",
    "\n",
    "# Prepara i dati\n",
    "gender_plot = cont_genere_main[[\"Maschio\", \"Femmina\"]].copy()\n",
    "gender_order = list(ORDER_4)  # Ordine standard dei 4 gruppi\n",
    "\n",
    "# Calcola percentuali\n",
    "totals = gender_plot.sum(axis=1)\n",
    "gender_perc = gender_plot.div(totals, axis=0) * 100\n",
    "\n",
    "# ============================================================================\n",
    "# GRAFICO INGLESE (sempre per primo)\n",
    "# ============================================================================\n",
    "\n",
    "fig_en, ax_en = plt.subplots(figsize=(12, 6))\n",
    "x = np.arange(len(gender_order))\n",
    "width = 0.35\n",
    "\n",
    "# Converti i gruppi in inglese\n",
    "gender_order_en = [labels_it_en[g] for g in gender_order]\n",
    "\n",
    "# Barre\n",
    "bars1 = ax_en.bar(x - width/2, gender_plot.loc[gender_order, 'Maschio'], width, \n",
    "                   label='Male', color=color_m, alpha=0.8)\n",
    "bars2 = ax_en.bar(x + width/2, gender_plot.loc[gender_order, 'Femmina'], width, \n",
    "                   label='Female', color=color_f, alpha=0.8)\n",
    "\n",
    "# Aggiungi etichette con numeri assoluti e percentuali\n",
    "for i, grp in enumerate(gender_order):\n",
    "    # Maschi\n",
    "    count_m = gender_plot.loc[grp, 'Maschio']\n",
    "    perc_m = gender_perc.loc[grp, 'Maschio']\n",
    "    if count_m > 0:\n",
    "        ax_en.text(i - width/2, count_m + 2, f'{count_m}\\n({perc_m:.1f}%)', \n",
    "                   ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # Femmine\n",
    "    count_f = gender_plot.loc[grp, 'Femmina']\n",
    "    perc_f = gender_perc.loc[grp, 'Femmina']\n",
    "    if count_f > 0:\n",
    "        ax_en.text(i + width/2, count_f + 2, f'{count_f}\\n({perc_f:.1f}%)', \n",
    "                   ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "ax_en.set_xlabel('Group', fontsize=12)\n",
    "ax_en.set_ylabel('Count', fontsize=12)\n",
    "ax_en.set_title('Gender Distribution by Group', fontsize=14, fontweight='bold')\n",
    "ax_en.set_xticks(x)\n",
    "ax_en.set_xticklabels(gender_order_en, rotation=15, ha='right')\n",
    "ax_en.legend()\n",
    "ax_en.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Salva grafici EN\n",
    "p_gender_en_png = out_dir / \"gender_distribution_4groups_en.png\"\n",
    "p_gender_en_svg = out_dir / \"gender_distribution_4groups_en.svg\"\n",
    "fig_en.savefig(p_gender_en_png, dpi=300, bbox_inches='tight')\n",
    "fig_en.savefig(p_gender_en_svg, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'\\n✓ Grafici INGLESE salvati in:')\n",
    "print(f'  PNG: {p_gender_en_png}')\n",
    "print(f'  SVG: {p_gender_en_svg}')\n",
    "\n",
    "# ============================================================================\n",
    "# GRAFICO ITALIANO\n",
    "# ============================================================================\n",
    "\n",
    "fig_it, ax_it = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Barre\n",
    "bars1_it = ax_it.bar(x - width/2, gender_plot.loc[gender_order, 'Maschio'], width, \n",
    "                      label='Maschio', color=color_m, alpha=0.8)\n",
    "bars2_it = ax_it.bar(x + width/2, gender_plot.loc[gender_order, 'Femmina'], width, \n",
    "                      label='Femmina', color=color_f, alpha=0.8)\n",
    "\n",
    "# Aggiungi etichette con numeri assoluti e percentuali\n",
    "for i, grp in enumerate(gender_order):\n",
    "    # Maschi\n",
    "    count_m = gender_plot.loc[grp, 'Maschio']\n",
    "    perc_m = gender_perc.loc[grp, 'Maschio']\n",
    "    if count_m > 0:\n",
    "        ax_it.text(i - width/2, count_m + 2, f'{count_m}\\n({perc_m:.1f}%)', \n",
    "                   ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # Femmine\n",
    "    count_f = gender_plot.loc[grp, 'Femmina']\n",
    "    perc_f = gender_perc.loc[grp, 'Femmina']\n",
    "    if count_f > 0:\n",
    "        ax_it.text(i + width/2, count_f + 2, f'{count_f}\\n({perc_f:.1f}%)', \n",
    "                   ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "ax_it.set_xlabel('Gruppo', fontsize=12)\n",
    "ax_it.set_ylabel('Conteggio', fontsize=12)\n",
    "ax_it.set_title('Distribuzione per genere per gruppo', fontsize=14, fontweight='bold')\n",
    "ax_it.set_xticks(x)\n",
    "ax_it.set_xticklabels(gender_order, rotation=15, ha='right')\n",
    "ax_it.legend()\n",
    "ax_it.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Salva grafici IT\n",
    "p_gender_it_png = out_dir / \"gender_distribution_4groups_it.png\"\n",
    "p_gender_it_svg = out_dir / \"gender_distribution_4groups_it.svg\"\n",
    "fig_it.savefig(p_gender_it_png, dpi=300, bbox_inches='tight')\n",
    "fig_it.savefig(p_gender_it_svg, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'\\n✓ Grafici ITALIANO salvati in:')\n",
    "print(f'  PNG: {p_gender_it_png}')\n",
    "print(f'  SVG: {p_gender_it_svg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c47b16",
   "metadata": {},
   "source": [
    "## 0.3 Area disciplinare (STEM vs Umanistiche)\n",
    "\n",
    "Conteggi e grafici bilingui dedicati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927a5e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuzione area disciplinare – grafici bilingui\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "if col_stud_percorso is None or col_doc_materia is None:\n",
    "    print('Colonne area disciplinare mancanti. Esegui la cella precedente.')\n",
    "else:\n",
    "    area_plot = area_counts[area_counts['Area_norm'].isin(['STEM', 'Umanistiche'])].copy()\n",
    "    area_order = ['STEM', 'Umanistiche']\n",
    "    area_plot['Area_norm'] = pd.Categorical(area_plot['Area_norm'], area_order, ordered=True)\n",
    "\n",
    "    for lang in ('it', 'en'):\n",
    "        fig, ax = plt.subplots(figsize=(14, 6))\n",
    "        x = np.arange(len(ORDER_4))\n",
    "        width = 0.35\n",
    "        colors = {'STEM': '#1f77b4', 'Umanistiche': '#ff7f0e'}\n",
    "        label_stem = 'Discipline STEM' if lang == 'it' else 'STEM fields'\n",
    "        label_hum = 'Discipline umanistiche' if lang == 'it' else 'Humanities'\n",
    "        xlabel = 'Gruppo' if lang == 'it' else 'Group'\n",
    "        ylabel = 'Frequenza' if lang == 'it' else 'Count'\n",
    "        title = 'Area disciplinare nei 4 gruppi' if lang == 'it' else 'Disciplinary area across groups'\n",
    "\n",
    "        for i, grp in enumerate(ORDER_4):\n",
    "            sub = area_plot[area_plot['GruppoDettaglio'] == grp]\n",
    "            for j, area in enumerate(area_order):\n",
    "                data = sub[sub['Area_norm'] == area]\n",
    "                if data.empty:\n",
    "                    continue\n",
    "                count = int(data['conteggio'].iloc[0])\n",
    "                perc = float(data['perc'].iloc[0])\n",
    "                offset = -width/2 if area == 'STEM' else width/2\n",
    "                ax.bar(i + offset, count, width, color=colors[area], label=(label_stem if area == 'STEM' else label_hum) if i == 0 else None)\n",
    "                ax.text(i + offset, count + max(1, count*0.01), f\"{count}\\n({int(round(perc))}%)\", ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels([map_group_label(g, lang) for g in ORDER_4])\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_ylabel(ylabel)\n",
    "        ax.set_title(title)\n",
    "        legend_elements = [\n",
    "            mpatches.Patch(facecolor=colors['STEM'], label=label_stem),\n",
    "            mpatches.Patch(facecolor=colors['Umanistiche'], label=label_hum)\n",
    "        ]\n",
    "        ax.legend(handles=legend_elements, ncols=2)\n",
    "        ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        fp_png = OUT_EXPL / f'area_distribution_4groups_{lang}.png'\n",
    "        fp_svg = OUT_EXPL / f'area_distribution_4groups_{lang}.svg'\n",
    "        fig.savefig(fp_png, dpi=300)\n",
    "        fig.savefig(fp_svg, dpi=300)\n",
    "        plt.show()\n",
    "        print(f'Salvati grafici area {lang.upper()}:', fp_png, 'e', fp_svg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9687c4d1",
   "metadata": {},
   "source": [
    "# 1. Usage patterns\n",
    "\n",
    "Frequenza, intensità e varietà con cui gli strumenti di IA vengono utilizzati nei diversi profili educativi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ca5fd5",
   "metadata": {},
   "source": [
    "## 1.1 Adozione quotidiana (Sì/No)\n",
    "\n",
    "Distribuzione binaria dell'uso dell'IA nella vita quotidiana per ciascun gruppo (grafici IT/EN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3201b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso quotidiano dell'IA (sì/no) — istogrammi per 4 categorie (IT/EN)\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Stile coerente con il resto del notebook\n",
    "try:\n",
    "    import scienceplots  # noqa: F401\n",
    "except Exception:\n",
    "    try:\n",
    "        ensure('SciencePlots')\n",
    "        import scienceplots  # noqa: F401\n",
    "    except Exception:\n",
    "        pass\n",
    "plt.style.use(['science', 'no-latex', 'grid'])\n",
    "mpl.rcParams.update({\n",
    "    'text.usetex': False,\n",
    "    'mathtext.fontset': 'dejavusans',\n",
    "    'font.family': 'DejaVu Sans',\n",
    "    'figure.dpi': 150,\n",
    "    'savefig.dpi': 300,\n",
    "    'font.size': 12,\n",
    "    'axes.labelsize': 12,\n",
    "    'axes.titlesize': 13,\n",
    "    'xtick.labelsize': 11,\n",
    "    'ytick.labelsize': 11,\n",
    "})\n",
    "\n",
    "# Helper per ricerca colonne\n",
    "\n",
    "def find_col_any(cols, token_options):\n",
    "    for c in cols:\n",
    "        text = str(c).lower()\n",
    "        for tokens in token_options:\n",
    "            if all(tok in text for tok in tokens):\n",
    "                return c\n",
    "    return None\n",
    "\n",
    "# Normalizza sì/no\n",
    "_yes_re = re.compile(r'^(si|sì|yes|y|true|1)$', re.IGNORECASE)\n",
    "_no_re  = re.compile(r'^(no|n|false|0)$', re.IGNORECASE)\n",
    "\n",
    "def to_yes_no(v):\n",
    "    if pd.isna(v):\n",
    "        return np.nan\n",
    "    s = str(v).strip().lower()\n",
    "    s = s.replace('ì', 'i')  # gestisci accento per matching semplice\n",
    "    if _yes_re.match(s):\n",
    "        return True\n",
    "    if _no_re.match(s):\n",
    "        return False\n",
    "    return np.nan\n",
    "\n",
    "# Base di lavoro e ordine/palette gruppi\n",
    "base = DF_plot.copy()\n",
    "order = [\n",
    "    'studenti - secondaria',\n",
    "    'studenti - universitari',\n",
    "    'insegnanti - non in servizio',\n",
    "    'insegnanti - in servizio',\n",
    "]\n",
    "palette = {\n",
    "    'studenti - secondaria': 'red',\n",
    "    'studenti - universitari': 'forestgreen',\n",
    "    'insegnanti - in servizio': 'royalblue',\n",
    "    'insegnanti - non in servizio': 'gold',\n",
    "}\n",
    "\n",
    "# Individua colonna per la domanda “Nella tua vita quotidiana utilizzi l'intelligenza artificiale?”\n",
    "# Potrebbero esserci due colonne (questionari diversi). Cerchiamo per token.\n",
    "all_cols = list(DF.columns)\n",
    "col_daily_stu = find_col_any(all_cols, [[\"nella\", \"vita\", \"quotidian\", \"intelligenza\", \"artificial\"],\n",
    "                                        [\"vita\", \"quotidian\", \"utilizzi\", \"intelligenza\"]])\n",
    "col_daily_doc = col_daily_stu  # spesso il testo è identico; se necessario, differenziarlo qui\n",
    "if col_daily_stu is None:\n",
    "    # fallback: cerca inglese o varianti\n",
    "    col_daily_stu = find_col_any(all_cols, [[\"daily\", \"life\", \"use\", \"ai\"], [\"use\", \"artificial\", \"intelligence\", \"daily\"]])\n",
    "if col_daily_stu is None:\n",
    "    raise RuntimeError(\"Impossibile trovare la colonna della domanda: 'Nella tua vita quotidiana utilizzi l'intelligenza artificiale?' \")\n",
    "\n",
    "# Assicura colonne nella base\n",
    "for c in {col_daily_stu, col_daily_doc}:\n",
    "    if c and c not in base.columns:\n",
    "        base[c] = DF[c]\n",
    "\n",
    "# Filtri coerenti con il resto (escludi primaria e docenti universitari)\n",
    "col_insegn_ordine = find_col_any(\n",
    "    DF.columns,\n",
    "    [[\"ordine\", \"scuola\", \"insegni\"], [\"ordine\", \"scuola\", \"vorrest\"], [\"ordine\", \"scuola\"]]\n",
    ")\n",
    "mask_primaria = base['GruppoDettaglio'].astype(str).str.contains('studenti - primaria', case=False, na=False)\n",
    "mask_univ = False\n",
    "if col_insegn_ordine is not None:\n",
    "    m_teacher = base['Gruppo'].astype(str).str.contains('insegnanti', case=False, na=False)\n",
    "    tvals = base.loc[m_teacher, col_insegn_ordine].astype(str).str.lower()\n",
    "    m_univ = tvals.str.contains(r\"univers|ateneo|univ\", regex=True, na=False)\n",
    "    mask_univ = pd.Series(False, index=base.index)\n",
    "    mask_univ.loc[tvals[m_univ].index] = True\n",
    "filt = (~mask_primaria) & (~mask_univ) if isinstance(mask_univ, pd.Series) else (~mask_primaria)\n",
    "df_bin = base.loc[filt].copy()\n",
    "\n",
    "# Colonna binaria sì/no per riga, distinguendo se serve studenti vs insegnanti\n",
    "is_student = df_bin['Gruppo'].astype(str).str.contains('studenti', case=False, na=False)\n",
    "df_bin['DailyAI'] = np.where(\n",
    "    is_student,\n",
    "    df_bin[col_daily_stu].apply(to_yes_no),\n",
    "    df_bin[col_daily_doc].apply(to_yes_no) if col_daily_doc else np.nan,\n",
    ")\n",
    "\n",
    "# Tieni solo le 4 categorie ordinate\n",
    "df_bin = df_bin[df_bin['GruppoDettaglio'].isin(order)].copy()\n",
    "df_bin['GruppoDettaglio'] = pd.Categorical(df_bin['GruppoDettaglio'], categories=order, ordered=True)\n",
    "\n",
    "# Tabella conteggi per gruppo (True/False)\n",
    "counts = (\n",
    "    df_bin.groupby(['GruppoDettaglio', 'DailyAI'], observed=False)\n",
    "          .size()\n",
    "          .rename('conteggio')\n",
    "          .reset_index()\n",
    ")\n",
    "# Completa livelli mancanti (True/False) per ogni gruppo\n",
    "all_idx = pd.MultiIndex.from_product([order, [False, True]], names=['GruppoDettaglio','DailyAI'])\n",
    "counts = counts.set_index(['GruppoDettaglio','DailyAI']).reindex(all_idx, fill_value=0).reset_index()\n",
    "\n",
    "# Calcola percentuali per gruppo\n",
    "counts['totale_gruppo'] = counts.groupby('GruppoDettaglio')['conteggio'].transform('sum')\n",
    "counts['perc'] = np.where(counts['totale_gruppo']>0, counts['conteggio'] / counts['totale_gruppo'], np.nan)\n",
    "\n",
    "# Salvataggi CSV\n",
    "OUT = (Path.cwd()/'../analysis/exports/latest').resolve()\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "counts_csv = OUT / 'daily_ai_use_yesno_counts.csv'\n",
    "counts.to_csv(counts_csv, index=False)\n",
    "print('Conteggi salvati in:', counts_csv)\n",
    "\n",
    "# Funzione per disegnare una griglia 2x2 (lasciata per riferimento)\n",
    "\n",
    "def plot_grid(counts_df, lang='it'):\n",
    "    labels = {'it': {'title': \"Uso quotidiano dell'IA (sì/no) — per categoria\",\n",
    "                     'xlabel': 'Risposta', 'ylabel': 'Frequenza', 'yes': 'Sì', 'no': 'No'},\n",
    "              'en': {'title': 'Daily AI use (yes/no) — by category',\n",
    "                     'xlabel': 'Response', 'ylabel': 'Count', 'yes': 'Yes', 'no': 'No'}}\n",
    "    lab = labels.get(lang, labels['it'])\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(9, 6), sharex=True)\n",
    "    axes = axes.flatten()\n",
    "    for i, grp in enumerate(order):\n",
    "        ax = axes[i]\n",
    "        sub = counts_df[counts_df['GruppoDettaglio'] == grp].copy()\n",
    "        # Ordina sempre Sì prima di No\n",
    "        sub = sub.sort_values('DailyAI', ascending=False)  # True (Sì), False (No)\n",
    "        x = [lab['yes'], lab['no']]\n",
    "        y = [int(sub.loc[sub['DailyAI'] == True, 'conteggio'].values[0]),\n",
    "             int(sub.loc[sub['DailyAI'] == False, 'conteggio'].values[0])]\n",
    "        color = palette['insegnanti - in servizio'] if 'insegnanti' in grp else palette['studenti - secondaria']\n",
    "        if 'universitari' in grp:\n",
    "            color = palette['studenti - universitari']\n",
    "        if 'non in servizio' in grp:\n",
    "            color = palette['insegnanti - non in servizio']\n",
    "        ax.bar(x, y, color=color, alpha=0.9)\n",
    "        ax.set_title(grp)\n",
    "        ax.set_xlabel(lab['xlabel'])\n",
    "        ax.set_ylabel(lab['ylabel'])\n",
    "        # Aggiungi le percentuali nelle etichette\n",
    "        for resp in [True, False]:\n",
    "            val = int(sub.loc[sub['DailyAI']==resp, 'conteggio'].values[0])\n",
    "            pct = float(sub.loc[sub['DailyAI']==resp, 'perc'].values[0]) * 100 if sub.loc[sub['DailyAI']==resp, 'totale_gruppo'].values[0]>0 else np.nan\n",
    "            lbl = f\"{val} ({pct:.0f}%)\" if pct==pct else f\"{val}\"\n",
    "            xi = lab['yes'] if resp else lab['no']\n",
    "            ax.text(xi, val, lbl, ha='center', va='bottom', fontsize=10)\n",
    "        ax.set_ylim(0, max(y)*1.25 + 1)\n",
    "    fig.suptitle(lab['title'])\n",
    "    plt.tight_layout(rect=[0, 0.02, 1, 0.96])\n",
    "    return fig\n",
    "\n",
    "# Nuovo: unico grafico con 4 gruppi e barre Sì/No (Sì sempre prima) + percentuali\n",
    "from matplotlib.colors import to_rgb\n",
    "\n",
    "def lighten(color, amount=0.5):\n",
    "    r, g, b = to_rgb(color)\n",
    "    return (1 - amount) + amount * r, (1 - amount) + amount * g, (1 - amount) + amount * b\n",
    "\n",
    "def plot_combined(counts_df, lang='it'):\n",
    "    labels = {'it': {'title': \"Uso quotidiano dell'IA (sì/no) — 4 gruppi\",\n",
    "                     'xlabel': 'Gruppo', 'ylabel': 'Frequenza', 'yes': 'Sì', 'no': 'No',\n",
    "                     'groups': order},\n",
    "              'en': {'title': 'Daily AI use (yes/no) — 4 groups',\n",
    "                     'xlabel': 'Group', 'ylabel': 'Count', 'yes': 'Yes', 'no': 'No',\n",
    "                     'groups': ['students - secondary','students - university','teachers - not in service','teachers - in service']}}\n",
    "    lab = labels.get(lang, labels['it'])\n",
    "\n",
    "    # Preparazione dati: garantisci Sì (True) poi No (False)\n",
    "    df = counts_df.copy().sort_values(['GruppoDettaglio','DailyAI'], ascending=[True, False])\n",
    "    # Posizioni\n",
    "    x = np.arange(len(order))\n",
    "    width = 0.38\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(11, 6))\n",
    "    # Disegna per ciascun gruppo le due barre: Sì (a sinistra), No (a destra)\n",
    "    bars = []\n",
    "    for i, grp in enumerate(order):\n",
    "        sub = df[df['GruppoDettaglio']==grp]\n",
    "        yes = int(sub.loc[sub['DailyAI']==True, 'conteggio'].iloc[0])\n",
    "        no  = int(sub.loc[sub['DailyAI']==False, 'conteggio'].iloc[0])\n",
    "        yes_p = float(sub.loc[sub['DailyAI']==True, 'perc'].iloc[0]) * 100 if int(sub['totale_gruppo'].iloc[0])>0 else np.nan\n",
    "        no_p  = float(sub.loc[sub['DailyAI']==False, 'perc'].iloc[0]) * 100 if int(sub['totale_gruppo'].iloc[0])>0 else np.nan\n",
    "        base_col = palette['insegnanti - in servizio'] if 'insegnanti' in grp else palette['studenti - secondaria']\n",
    "        if 'universitari' in grp:\n",
    "            base_col = palette['studenti - universitari']\n",
    "        if 'non in servizio' in grp:\n",
    "            base_col = palette['insegnanti - non in servizio']\n",
    "        col_yes = base_col\n",
    "        col_no  = lighten(base_col, 0.7)\n",
    "        b1 = ax.bar(x[i]-width/2, yes, width, color=col_yes)\n",
    "        b2 = ax.bar(x[i]+width/2, no,  width, color=col_no)\n",
    "        # Etichette con percentuali\n",
    "        ax.text(x[i]-width/2, yes, f\"{yes} ({yes_p:.0f}%)\" if yes_p==yes_p else f\"{yes}\", ha='center', va='bottom', fontsize=10)\n",
    "        ax.text(x[i]+width/2, no,  f\"{no} ({no_p:.0f}%)\"   if no_p==no_p else f\"{no}\",  ha='center', va='bottom', fontsize=10)\n",
    "        bars.extend([b1,b2])\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(lab['groups'], rotation=0)\n",
    "    ax.set_xlabel(lab['xlabel'])\n",
    "    ax.set_ylabel(lab['ylabel'])\n",
    "    ax.set_title(lab['title'])\n",
    "    # Leggenda con patch personalizzate (colori neutri)\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='darkgray', label=lab['yes']),\n",
    "        Patch(facecolor='lightgray', label=lab['no'])\n",
    "    ]\n",
    "    leg = ax.legend(handles=legend_elements, ncols=2, frameon=False)\n",
    "    ax.margins(x=0.02)\n",
    "    ax.set_ylim(0, max(counts_df['conteggio'])*1.15 + 5)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Disegna e salva figure IT/EN (griglia e grafico unico)\n",
    "fig_it = plot_grid(counts, lang='it')\n",
    "p_it_png = OUT / 'hist_daily_ai_use_it.png'\n",
    "p_it_svg = OUT / 'hist_daily_ai_use_it.svg'\n",
    "fig_it.savefig(p_it_png)\n",
    "fig_it.savefig(p_it_svg)\n",
    "plt.show()\n",
    "plt.close(fig_it)\n",
    "\n",
    "fig_en = plot_grid(counts, lang='en')\n",
    "p_en_png = OUT / 'hist_daily_ai_use_en.png'\n",
    "p_en_svg = OUT / 'hist_daily_ai_use_en.svg'\n",
    "fig_en.savefig(p_en_png)\n",
    "fig_en.savefig(p_en_svg)\n",
    "plt.show()\n",
    "plt.close(fig_en)\n",
    "\n",
    "# Nuovi grafici unici\n",
    "g_it = plot_combined(counts, lang='it')\n",
    "out_it_png = OUT / 'hist_daily_ai_use_combined_it.png'\n",
    "out_it_svg = OUT / 'hist_daily_ai_use_combined_it.svg'\n",
    "g_it.savefig(out_it_png)\n",
    "g_it.savefig(out_it_svg)\n",
    "plt.show()\n",
    "plt.close(g_it)\n",
    "\n",
    "g_en = plot_combined(counts, lang='en')\n",
    "out_en_png = OUT / 'hist_daily_ai_use_combined_en.png'\n",
    "out_en_svg = OUT / 'hist_daily_ai_use_combined_en.svg'\n",
    "g_en.savefig(out_en_png)\n",
    "g_en.savefig(out_en_svg)\n",
    "plt.show()\n",
    "plt.close(g_en)\n",
    "\n",
    "print('Salvati:', p_it_png, p_it_svg, p_en_png, p_en_svg, out_it_png, out_it_svg, out_en_png, out_en_svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc20c56c",
   "metadata": {},
   "source": [
    "## 1.2 Intensità settimanale di utilizzo\n",
    "\n",
    "Ore dedicate all'IA nella vita quotidiana per ciascun gruppo (violin + box bilingui)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f37e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ore settimanali di uso IA — grafici bilingui con violino/box\n",
    "import re\n",
    "from IPython.display import display\n",
    "\n",
    "col_hours = None\n",
    "for col in DF.columns:\n",
    "    label = str(col).lower()\n",
    "    if all(token in label for token in ('ore', 'settimana')) and 'ia' in label:\n",
    "        col_hours = col\n",
    "        break\n",
    "if col_hours is None:\n",
    "    raise RuntimeError('Colonna ore settimanali per uso IA non trovata')\n",
    "\n",
    "col_insegn_ordine = None\n",
    "for col in DF.columns:\n",
    "    txt = str(col).lower()\n",
    "    if all(token in txt for token in ('ordine', 'scuola')):\n",
    "        col_insegn_ordine = col\n",
    "        break\n",
    "\n",
    "base_hours = DF_plot.copy()\n",
    "if col_hours not in base_hours.columns:\n",
    "    base_hours[col_hours] = DF[col_hours]\n",
    "if col_insegn_ordine and col_insegn_ordine not in base_hours.columns:\n",
    "    base_hours[col_insegn_ordine] = DF[col_insegn_ordine]\n",
    "\n",
    "mask_primary = base_hours['GruppoDettaglio'].astype(str).str.contains('studenti - primaria', case=False, na=False)\n",
    "mask_univ = pd.Series(False, index=base_hours.index)\n",
    "if col_insegn_ordine is not None:\n",
    "    teacher_mask = base_hours['Gruppo'].astype(str).str.contains('insegnanti', case=False, na=False)\n",
    "    school_text = base_hours[col_insegn_ordine].astype(str).str.lower()\n",
    "    mask_univ = teacher_mask & school_text.str.contains('univers|ateneo|univ', regex=True, na=False)\n",
    "\n",
    "num_re = re.compile(r\"(\\d+[\\.,]?\\d*)\")\n",
    "\n",
    "def to_hours(value):\n",
    "    if pd.isna(value):\n",
    "        return pd.NA\n",
    "    if isinstance(value, (int, float)):\n",
    "        val = float(value)\n",
    "    else:\n",
    "        match = num_re.search(str(value))\n",
    "        if not match:\n",
    "            return pd.NA\n",
    "        val = float(match.group(1).replace(',', '.'))\n",
    "    return val if 0 <= val <= 168 else pd.NA\n",
    "\n",
    "is_student = base_hours['Gruppo'].astype(str).str.contains('studenti', case=False, na=False)\n",
    "base_hours['OreSettimanali'] = base_hours[col_hours].apply(to_hours)\n",
    "\n",
    "hours_df = base_hours.loc[~mask_primary & ~mask_univ].copy()\n",
    "hours_df = hours_df[hours_df['GruppoDettaglio'].isin(ORDER_4) & hours_df['OreSettimanali'].notna()]\n",
    "hours_df['GruppoDettaglio'] = pd.Categorical(hours_df['GruppoDettaglio'], categories=ORDER_4, ordered=True)\n",
    "print(f'Osservazioni valide per ore settimanali: {len(hours_df)}')\n",
    "\n",
    "hours_full, hours_stats = bilingual_violin_box(\n",
    "    hours_df[['GruppoDettaglio', 'OreSettimanali']],\n",
    "    value_col='OreSettimanali',\n",
    "    slug='ore_settimanali_ia',\n",
    "    title_it='Uso IA nella vita quotidiana — ore settimanali',\n",
    "    title_en='Daily-life AI usage — weekly hours',\n",
    "    ylabel_it='Ore settimanali (uso IA)',\n",
    "    ylabel_en='Weekly hours (AI use)',\n",
    "    save_csv=True,\n",
    ")\n",
    "\n",
    "hours_trimmed, hours_stats_trimmed = bilingual_violin_box(\n",
    "    hours_df[['GruppoDettaglio', 'OreSettimanali']],\n",
    "    value_col='OreSettimanali',\n",
    "    slug='ore_settimanali_ia_trimmed',\n",
    "    title_it='Uso quotidiano IA — ore settimanali (senza outlier)',\n",
    "    title_en='Daily-life AI usage — weekly hours (trimmed)',\n",
    "    ylabel_it='Ore settimanali (uso IA)',\n",
    "    ylabel_en='Weekly hours (AI use)',\n",
    "    trim_outliers=True,\n",
    ")\n",
    "\n",
    "print(hours_stats)\n",
    "display(hours_stats)\n",
    "\n",
    "df_use = hours_full.copy()\n",
    "df_use_trimmed = hours_trimmed.copy()\n",
    "print('\\nI dataframe df_use e df_use_trimmed sono aggiornati per le analisi successive.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c8e8ed",
   "metadata": {},
   "source": [
    "## 1.3 Uso per studio vs didattica\n",
    "\n",
    "Confronto delle attivazioni (Sì/No) tra studenti e insegnanti nei rispettivi contesti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15f394d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso dell'IA nello studio (studenti) vs nella didattica (insegnanti) — sì/no con percentuali (IT/EN)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "OUT_EXPL = (Path.cwd()/\"../analysis/exports/latest\").resolve()\n",
    "ASSETS = (Path.cwd()/\"../assets/figures\").resolve()\n",
    "OUT_EXPL.mkdir(parents=True, exist_ok=True)\n",
    "ASSETS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Trova colonne delle due domande principali\n",
    "\n",
    "def find_col(df, tokens_all, tokens_any=None):\n",
    "    cols = list(df.columns)\n",
    "    toks_all = [t.lower() for t in tokens_all]\n",
    "    for c in cols:\n",
    "        s = str(c).lower()\n",
    "        if all(t in s for t in toks_all):\n",
    "            if not tokens_any:\n",
    "                return c\n",
    "            if any(t in s for t in [x.lower() for x in tokens_any]):\n",
    "                return c\n",
    "    # fallback: any of toks_all\n",
    "    for c in cols:\n",
    "        s = str(c).lower()\n",
    "        if any(t in s for t in toks_all):\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "COL_STUDY = find_col(DF_plot, [\"utilizzi\", \"intelligenza\", \"studio\"])  # \"Utilizzi l'intelligenza artificiale nello studio?\"\n",
    "COL_TEACH = find_col(DF_plot, [\"utilizzi\", \"intelligenza\", \"didattica\"]) # \"Utilizzi l'intelligenza artificiale nella didattica?\"\n",
    "print(\"Colonne rilevate:\", COL_STUDY, \"|\", COL_TEACH)\n",
    "\n",
    "YES_IT, NO_IT = \"Sì\", \"No\"\n",
    "YES_EN, NO_EN = \"Yes\", \"No\"\n",
    "\n",
    "def norm_yesno(v):\n",
    "    if pd.isna(v):\n",
    "        return np.nan\n",
    "    s = str(v).strip().lower()\n",
    "    s = s.replace(\"ì\",\"i\")\n",
    "    if s in {\"si\",\"yes\",\"y\",\"true\",\"1\"}:\n",
    "        return YES_IT\n",
    "    if s in {\"no\",\"n\",\"false\",\"0\"}:\n",
    "        return NO_IT\n",
    "    return np.nan\n",
    "\n",
    "ORDER_4 = [\n",
    "    \"studenti - secondaria\",\n",
    "    \"studenti - universitari\",\n",
    "    \"insegnanti - non in servizio\",\n",
    "    \"insegnanti - in servizio\",\n",
    "]\n",
    "\n",
    "base = DF_plot.copy()\n",
    "mask_stu = base[\"GruppoDettaglio\"].isin(ORDER_4[:2])\n",
    "mask_tch = base[\"GruppoDettaglio\"].isin(ORDER_4[2:])\n",
    "\n",
    "base.loc[mask_stu, \"UsoAI_studio_didattica\"] = base.loc[mask_stu, COL_STUDY].map(norm_yesno) if COL_STUDY in base.columns else np.nan\n",
    "base.loc[mask_tch, \"UsoAI_studio_didattica\"] = base.loc[mask_tch, COL_TEACH].map(norm_yesno) if COL_TEACH in base.columns else np.nan\n",
    "\n",
    "use = base[base[\"UsoAI_studio_didattica\"].isin([YES_IT, NO_IT]) & base[\"GruppoDettaglio\"].isin(ORDER_4)].copy()\n",
    "use[\"GruppoDettaglio\"] = pd.Categorical(use[\"GruppoDettaglio\"], ORDER_4, ordered=True)\n",
    "\n",
    "counts = (use.groupby([\"GruppoDettaglio\",\"UsoAI_studio_didattica\"]).size().reset_index(name=\"conteggio\"))\n",
    "# completa buchi\n",
    "idx = pd.MultiIndex.from_product([ORDER_4,[YES_IT, NO_IT]], names=[\"GruppoDettaglio\",\"UsoAI_studio_didattica\"])\n",
    "\n",
    "counts = (\n",
    "    counts\n",
    "    .set_index([\"GruppoDettaglio\",\"UsoAI_studio_didattica\"])\n",
    "    .reindex(idx, fill_value=0)\n",
    "    .rename_axis([\"GruppoDettaglio\",\"UsoAI_studio_didattica\"])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "if \"UsoAI_studio_didattica\" not in counts.columns and \"level_1\" in counts.columns:\n",
    "    counts = counts.rename(columns={\"level_1\": \"UsoAI_studio_didattica\"})\n",
    "if \"GruppoDettaglio\" not in counts.columns and \"level_0\" in counts.columns:\n",
    "    counts = counts.rename(columns={\"level_0\": \"GruppoDettaglio\"})\n",
    "counts[\"totale_gruppo\"] = counts.groupby(\"GruppoDettaglio\")[\"conteggio\"].transform(\"sum\")\n",
    "counts[\"perc\"] = (counts[\"conteggio\"]/counts[\"totale_gruppo\"]*100).round(1)\n",
    "\n",
    "counts_csv_it = OUT_EXPL/\"ai_use_study_teaching_yesno_counts_it.csv\"\n",
    "counts.to_csv(counts_csv_it, index=False)\n",
    "print(\"Conteggi IT salvati:\", counts_csv_it)\n",
    "\n",
    "palette = {\n",
    "    \"studenti - secondaria\": \"#e41a1c\",\n",
    "    \"studenti - universitari\": \"#4daf4a\",\n",
    "    \"insegnanti - non in servizio\": \"#ffd31a\",\n",
    "    \"insegnanti - in servizio\": \"#3b6ce1\",\n",
    "}\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def lighten(c, a=0.7):\n",
    "    r,g,b = mcolors.to_rgb(c)\n",
    "    return (1 - a) + a*r, (1 - a) + a*g, (1 - a) + a*b\n",
    "\n",
    "# Combined 4-groups IT\n",
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "x = np.arange(len(ORDER_4)); width = 0.36\n",
    "for i, grp in enumerate(ORDER_4):\n",
    "    sub = counts[counts[\"GruppoDettaglio\"]==grp]\n",
    "    c = palette[grp]\n",
    "    yes = int(sub.loc[sub[\"UsoAI_studio_didattica\"]==YES_IT, \"conteggio\"].iloc[0])\n",
    "    no  = int(sub.loc[sub[\"UsoAI_studio_didattica\"]==NO_IT, \"conteggio\"].iloc[0])\n",
    "    yp  = float(sub.loc[sub[\"UsoAI_studio_didattica\"]==YES_IT, \"perc\"].iloc[0])\n",
    "    np_ = float(sub.loc[sub[\"UsoAI_studio_didattica\"]==NO_IT, \"perc\"].iloc[0])\n",
    "    ax.bar(i-width/2, yes, width, color=c)\n",
    "    ax.bar(i+width/2, no,  width, color=lighten(c,0.7))\n",
    "    ax.text(i-width/2, yes+max(1,yes*0.01), f\"{yes} ({int(round(yp))}%)\", ha='center', va='bottom', fontsize=11)\n",
    "    ax.text(i+width/2, no+max(1,no*0.01),   f\"{no} ({int(round(np_))}%)\", ha='center', va='bottom', fontsize=11)\n",
    "ax.set_xticks(x); ax.set_xticklabels(ORDER_4)\n",
    "ax.set_title(\"Uso dell'IA nello studio/didattica (sì/no) — 4 gruppi\")\n",
    "ax.set_xlabel(\"Gruppo\"); ax.set_ylabel(\"Frequenza\")\n",
    "# Leggenda con patch personalizzate\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='darkgray', label='Sì'),\n",
    "    Patch(facecolor='lightgray', label='No')\n",
    "]\n",
    "ax.legend(handles=legend_elements, ncols=2)\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--'); plt.tight_layout()\n",
    "fp_it_png = OUT_EXPL/\"ai_use_study_teaching_4groups_it.png\"; fp_it_svg = OUT_EXPL/\"ai_use_study_teaching_4groups_it.svg\"\n",
    "fig.savefig(fp_it_png, dpi=300); fig.savefig(fp_it_svg, dpi=300)\n",
    "plt.show()\n",
    "print(\"Salvati:\", fp_it_png, fp_it_svg)\n",
    "\n",
    "# EN copy (labels only)\n",
    "map_it_en = {\n",
    "    \"studenti - secondaria\": \"students - secondary\",\n",
    "    \"studenti - universitari\": \"students - university\",\n",
    "    \"insegnanti - non in servizio\": \"teachers - not in service\",\n",
    "    \"insegnanti - in servizio\": \"teachers - in service\",\n",
    "}\n",
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "x = np.arange(len(ORDER_4)); width = 0.36\n",
    "for i, grp in enumerate(ORDER_4):\n",
    "    sub = counts[counts[\"GruppoDettaglio\"]==grp]\n",
    "    c = palette[grp]\n",
    "    yes = int(sub.loc[sub[\"UsoAI_studio_didattica\"]==YES_IT, \"conteggio\"].iloc[0])\n",
    "    no  = int(sub.loc[sub[\"UsoAI_studio_didattica\"]==NO_IT, \"conteggio\"].iloc[0])\n",
    "    yp  = float(sub.loc[sub[\"UsoAI_studio_didattica\"]==YES_IT, \"perc\"].iloc[0])\n",
    "    np_ = float(sub.loc[sub[\"UsoAI_studio_didattica\"]==NO_IT, \"perc\"].iloc[0])\n",
    "    ax.bar(i-width/2, yes, width, color=c)\n",
    "    ax.bar(i+width/2, no,  width, color=lighten(c,0.7))\n",
    "    ax.text(i-width/2, yes+max(1,yes*0.01), f\"{yes} ({int(round(yp))}%)\", ha='center', va='bottom', fontsize=11)\n",
    "    ax.text(i+width/2, no+max(1,no*0.01),   f\"{no} ({int(round(np_))}%)\", ha='center', va='bottom', fontsize=11)\n",
    "ax.set_xticks(x); ax.set_xticklabels([map_it_en[g] for g in ORDER_4])\n",
    "ax.set_title(\"AI use in study/teaching (yes/no) — 4 groups\")\n",
    "ax.set_xlabel(\"Group\"); ax.set_ylabel(\"Count\")\n",
    "# Leggenda con patch personalizzate\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='darkgray', label='Yes'),\n",
    "    Patch(facecolor='lightgray', label='No')\n",
    "]\n",
    "ax.legend(handles=legend_elements, ncols=2)\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--'); plt.tight_layout()\n",
    "fp_en_png = OUT_EXPL/\"ai_use_study_teaching_4groups_en.png\"; fp_en_svg = OUT_EXPL/\"ai_use_study_teaching_4groups_en.svg\"\n",
    "fig.savefig(fp_en_png, dpi=300); fig.savefig(fp_en_svg, dpi=300)\n",
    "plt.show()\n",
    "print(\"Saved:\", fp_en_png, fp_en_svg)\n",
    "\n",
    "# Copia in assets i due principali\n",
    "import shutil\n",
    "try:\n",
    "    shutil.copyfile(fp_en_png, ASSETS/\"ai_use_study_teaching_4groups_en.png\")\n",
    "    print(\"Copiati in assets.\")\n",
    "except Exception as e:\n",
    "    print(\"Avviso copia assets:\", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd203e1e",
   "metadata": {},
   "source": [
    "## 1.4 Sintesi combinata dei quattro gruppi\n",
    "\n",
    "Vista unica con barre Sì/No per i quattro cluster (IT/EN) e salvataggi CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23a3f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variante a due pannelli: a sinistra gli studenti (uso nello studio), a destra gli insegnanti (uso nella didattica)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "ORDER_STU = [\"studenti - secondaria\", \"studenti - universitari\"]\n",
    "ORDER_TCH = [\"insegnanti - non in servizio\", \"insegnanti - in servizio\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6), sharey=True)\n",
    "width = 0.36\n",
    "\n",
    "for ax, groups, title in [\n",
    "    (axes[0], ORDER_STU, \"Studenti — uso nello studio\"),\n",
    "    (axes[1], ORDER_TCH, \"Insegnanti — uso nella didattica\"),\n",
    "]:\n",
    "    x = np.arange(len(groups))\n",
    "    for i, grp in enumerate(groups):\n",
    "        sub = counts[counts[\"GruppoDettaglio\"]==grp]\n",
    "        c = palette[grp]\n",
    "        yes = int(sub.loc[sub[\"UsoAI_studio_didattica\"]==YES_IT, \"conteggio\"].iloc[0])\n",
    "        no  = int(sub.loc[sub[\"UsoAI_studio_didattica\"]==NO_IT, \"conteggio\"].iloc[0])\n",
    "        yp  = float(sub.loc[sub[\"UsoAI_studio_didattica\"]==YES_IT, \"perc\"].iloc[0])\n",
    "        np_ = float(sub.loc[sub[\"UsoAI_studio_didattica\"]==NO_IT, \"perc\"].iloc[0])\n",
    "        ax.bar(i-width/2, yes, width, color=c)\n",
    "        ax.bar(i+width/2, no,  width, color=lighten(c,0.7))\n",
    "        ax.text(i-width/2, yes+max(1,yes*0.01), f\"{yes} ({int(round(yp))}%)\", ha='center', va='bottom', fontsize=11)\n",
    "        ax.text(i+width/2, no+max(1,no*0.01),   f\"{no} ({int(round(np_))}%)\", ha='center', va='bottom', fontsize=11)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(groups)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Gruppo\")\n",
    "    ax.set_ylabel(\"Frequenza\")\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    # Leggenda con patch personalizzate\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='darkgray', label='Sì'),\n",
    "        Patch(facecolor='lightgray', label='No')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, ncols=2)\n",
    "\n",
    "plt.suptitle(\"Uso dell'IA nello studio/didattica (sì/no) — studenti vs insegnanti\")\n",
    "plt.tight_layout(rect=[0,0.03,1,0.98])\n",
    "\n",
    "fp_pan_it_png = OUT_EXPL/\"ai_use_study_teaching_panels_it.png\"\n",
    "fp_pan_it_svg = OUT_EXPL/\"ai_use_study_teaching_panels_it.svg\"\n",
    "fig.savefig(fp_pan_it_png, dpi=300); fig.savefig(fp_pan_it_svg, dpi=300)\n",
    "plt.show()\n",
    "print(\"Salvati (pannelli IT):\", fp_pan_it_png, fp_pan_it_svg)\n",
    "\n",
    "# EN labels\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6), sharey=True)\n",
    "for ax, groups, title in [\n",
    "    (axes[0], ORDER_STU, \"Students — study use\"),\n",
    "    (axes[1], ORDER_TCH, \"Teachers — teaching use\"),\n",
    "]:\n",
    "    x = np.arange(len(groups))\n",
    "    for i, grp in enumerate(groups):\n",
    "        sub = counts[counts[\"GruppoDettaglio\"]==grp]\n",
    "        c = palette[grp]\n",
    "        yes = int(sub.loc[sub[\"UsoAI_studio_didattica\"]==YES_IT, \"conteggio\"].iloc[0])\n",
    "        no  = int(sub.loc[sub[\"UsoAI_studio_didattica\"]==NO_IT, \"conteggio\"].iloc[0])\n",
    "        yp  = float(sub.loc[sub[\"UsoAI_studio_didattica\"]==YES_IT, \"perc\"].iloc[0])\n",
    "        np_ = float(sub.loc[sub[\"UsoAI_studio_didattica\"]==NO_IT, \"perc\"].iloc[0])\n",
    "        ax.bar(i-width/2, yes, width, color=c)\n",
    "        ax.bar(i+width/2, no,  width, color=lighten(c,0.7))\n",
    "        ax.text(i-width/2, yes+max(1,yes*0.01), f\"{yes} ({int(round(yp))}%)\", ha='center', va='bottom', fontsize=11)\n",
    "        ax.text(i+width/2, no+max(1,no*0.01),   f\"{no} ({int(round(np_))}%)\", ha='center', va='bottom', fontsize=11)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([map_it_en[g] for g in groups])\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Group\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    # Leggenda con patch personalizzate\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='darkgray', label='Yes'),\n",
    "        Patch(facecolor='lightgray', label='No')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, ncols=2)\n",
    "\n",
    "plt.suptitle(\"AI use in study/teaching (yes/no) — students vs teachers\")\n",
    "plt.tight_layout(rect=[0,0.03,1,0.98])\n",
    "\n",
    "fp_pan_en_png = OUT_EXPL/\"ai_use_study_teaching_panels_en.png\"\n",
    "fp_pan_en_svg = OUT_EXPL/\"ai_use_study_teaching_panels_en.svg\"\n",
    "fig.savefig(fp_pan_en_png, dpi=300); fig.savefig(fp_pan_en_svg, dpi=300)\n",
    "plt.show()\n",
    "print(\"Saved (panels EN):\", fp_pan_en_png, fp_pan_en_svg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65ecf95",
   "metadata": {},
   "source": [
    "## 1.6 Significatività statistica dei pattern di uso\n",
    "\n",
    "Verifichiamo se le differenze osservate tra gruppi sono statisticamente rilevanti (proporzioni e ore)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c145d6bb",
   "metadata": {},
   "source": [
    "### 1.6.a Test Chi-quadrato (uso quotidiano Sì/No)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296d7c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PREPARAZIONE DATI PER TEST STATISTICI ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "OUT_EXPL = (Path.cwd()/\"../analysis/exports/latest\").resolve()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PREPARAZIONE DATI PER TEST STATISTICI\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. PREPARAZIONE tab_gen (Genere × Uso IA)\n",
    "print(\"\\n1. Creazione tab_gen (Genere × Uso IA)...\")\n",
    "\n",
    "# Usa col_daily_stu se disponibile\n",
    "if 'col_daily_stu' in globals() and col_daily_stu is not None:\n",
    "    col_use = col_daily_stu\n",
    "else:\n",
    "    col_use = next((c for c in DF.columns if 'utilizzi quotidianamente' in c.lower()), None)\n",
    "\n",
    "if col_use and 'base_gf' in globals():\n",
    "    yes_set = set(['si','sì','yes','y','1','true'])\n",
    "    \n",
    "    tab_gen = DF_plot[['GruppoDettaglio']].copy()\n",
    "    tab_gen['GenereCat'] = base_gf['GenereCat'] if 'GenereCat' in base_gf.columns else 'Non risponde'\n",
    "    tab_gen['uses_ai'] = DF[col_use].apply(lambda v: str(v).strip().lower() in yes_set if pd.notna(v) else False)\n",
    "    \n",
    "    # Aggregazione: per ogni (Gruppo, Genere) conta totale e utenti\n",
    "    agg = (\n",
    "        tab_gen[tab_gen['GruppoDettaglio'].isin(ORDER_4)]\n",
    "        .groupby(['GruppoDettaglio', 'GenereCat'], observed=True)\n",
    "        .agg(total=('uses_ai', 'size'), users=('uses_ai', 'sum'))\n",
    "        .reset_index()\n",
    "    )\n",
    "    agg['perc_users_of_gender'] = (agg['users'] / agg['total'] * 100).round(1)\n",
    "    tab_gen = agg\n",
    "    print(f\"   ✓ tab_gen creato: {len(tab_gen)} righe\")\n",
    "else:\n",
    "    print(\"   ⚠️  Impossibile creare tab_gen (mancano col_use o base_gf)\")\n",
    "    tab_gen = None\n",
    "\n",
    "# 2. PREPARAZIONE df_check (per test chi-quadrato differenze gruppi)\n",
    "print(\"\\n2. Creazione df_check (Uso IA per gruppo)...\")\n",
    "\n",
    "if col_use and 'base_gf' in globals():\n",
    "    yes_set = set(['si','sì','yes','y','1','true'])\n",
    "    \n",
    "    df_check = DF_plot[['GruppoDettaglio']].copy()\n",
    "    if 'GenereCat' in base_gf.columns:\n",
    "        df_check['GenereCat'] = base_gf['GenereCat']\n",
    "    df_check['uses_ai'] = DF[col_use].apply(lambda v: str(v).strip().lower() in yes_set if pd.notna(v) else False)\n",
    "    df_check = df_check[df_check['GruppoDettaglio'].isin(ORDER_4)]\n",
    "    print(f\"   ✓ df_check creato: {len(df_check)} righe\")\n",
    "else:\n",
    "    print(\"   ⚠️  Impossibile creare df_check\")\n",
    "    df_check = None\n",
    "\n",
    "# 3. PREPARAZIONE df_use (Ore settimanali per gruppo)\n",
    "print(\"\\n3. Creazione df_use (Ore settimanali)...\")\n",
    "\n",
    "# Cerca colonna ore settimanali - pattern più flessibile\n",
    "col_hours = None\n",
    "for c in DF.columns:\n",
    "    c_lower = c.lower()\n",
    "    if 'ore' in c_lower and 'settiman' in c_lower and 'attività quotidiane' in c_lower:\n",
    "        col_hours = c\n",
    "        print(f\"   Trovata colonna ore: {c[:70]}...\")\n",
    "        break\n",
    "\n",
    "if col_hours:\n",
    "    # Funzione per convertire in ore (gestisce testo e numeri)\n",
    "    def to_hours(val):\n",
    "        if pd.isna(val):\n",
    "            return np.nan\n",
    "        val_str = str(val).strip().lower()\n",
    "        if val_str in ['non lo so', 'non rispondo', '']:\n",
    "            return np.nan\n",
    "        try:\n",
    "            return float(val_str)\n",
    "        except:\n",
    "            return np.nan\n",
    "    \n",
    "    df_use = DF_plot[['GruppoDettaglio']].copy()\n",
    "    df_use['OreSettimanali'] = DF[col_hours].apply(to_hours)\n",
    "    df_use = df_use[df_use['GruppoDettaglio'].isin(ORDER_4)]\n",
    "    df_use = df_use.dropna(subset=['OreSettimanali'])\n",
    "    print(f\"   ✓ df_use creato: {len(df_use)} righe valide\")\n",
    "else:\n",
    "    print(\"   ⚠️  Impossibile creare df_use (colonna ore settimanali non trovata)\")\n",
    "    df_use = None\n",
    "\n",
    "# 4. PREPARAZIONE tab_area (Area disciplinare × Uso IA)\n",
    "print(\"\\n4. Creazione tab_area (Area × Uso IA)...\")\n",
    "\n",
    "# Cerca colonna area disciplinare in DF\n",
    "col_area = None\n",
    "for c in DF.columns:\n",
    "    c_lower = c.lower()\n",
    "    if ('settore' in c_lower and 'scientific' in c_lower) or ('classe' in c_lower and 'concorso' in c_lower):\n",
    "        col_area = c\n",
    "        print(f\"   Trovata colonna area: {c[:60]}...\")\n",
    "        break\n",
    "\n",
    "if col_area and col_use:\n",
    "    yes_set = set(['si','sì','yes','y','1','true'])\n",
    "    \n",
    "    # Normalizza le aree in STEM / Umanistiche\n",
    "    def norm_area(val):\n",
    "        if pd.isna(val):\n",
    "            return 'Non risponde'\n",
    "        s = str(val).strip().lower()\n",
    "        # STEM\n",
    "        if any(x in s for x in ['stem', 'scienz', 'matemat', 'fisic', 'chim', 'biolog', 'ingegner', 'tecnolog', 'informatic']):\n",
    "            return 'STEM'\n",
    "        # Umanistiche\n",
    "        if any(x in s for x in ['uman', 'letter', 'lingu', 'artist', 'music', 'filosofi', 'stori', 'giuridic', 'giurispr', 'sociol', 'psicolog', 'pedagog', 'scienze dell\\'educazione']):\n",
    "            return 'Umanistiche'\n",
    "        return 'Altro'\n",
    "    \n",
    "    # Prepara dataframe\n",
    "    df_a = DF_plot[['GruppoDettaglio']].copy()\n",
    "    df_a['Area_norm'] = DF[col_area].apply(norm_area)\n",
    "    df_a['uses_ai'] = DF[col_use].apply(lambda v: str(v).strip().lower() in yes_set if pd.notna(v) else False)\n",
    "    \n",
    "    # Filtra per i 4 gruppi principali e solo STEM/Umanistiche\n",
    "    df_a = df_a[df_a['GruppoDettaglio'].isin(ORDER_4)]\n",
    "    df_a = df_a[df_a['Area_norm'].isin(['STEM', 'Umanistiche'])]\n",
    "    \n",
    "    # Crea tabella di contingenza: Gruppo × Area_norm\n",
    "    tab_area = (\n",
    "        df_a.groupby(['GruppoDettaglio','Area_norm'], observed=False)\n",
    "        .agg(total=('uses_ai','size'), users=('uses_ai','sum'))\n",
    "        .reset_index()\n",
    "    )\n",
    "    tab_area['perc_users_of_area'] = (tab_area['users'] / tab_area['total'] * 100).round(1)\n",
    "    print(f\"   ✓ tab_area creato: {len(tab_area)} righe\")\n",
    "else:\n",
    "    if not col_area:\n",
    "        print(\"   ⚠️  Colonna area disciplinare non trovata in DF\")\n",
    "    elif not col_use:\n",
    "        print(\"   ⚠️  col_use non disponibile\")\n",
    "    tab_area = None\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PREPARAZIONE COMPLETATA\")\n",
    "print(\"=\"*80)\n",
    "print(f\"  tab_gen:   {'✓' if tab_gen is not None else '✗'}\")\n",
    "print(f\"  tab_area:  {'✓' if tab_area is not None else '✗'}\")\n",
    "print(f\"  df_check:  {'✓' if df_check is not None else '✗'}\")\n",
    "print(f\"  df_use:    {'✓' if df_use is not None else '✗'}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6570f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TEST CHI-QUADRATO: GENERE × USO IA ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency, fisher_exact\n",
    "from pathlib import Path\n",
    "\n",
    "OUT_EXPL = (Path.cwd()/\"../analysis/exports/latest\").resolve()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TEST CHI-QUADRATO: Genere × Uso dell'IA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Verifica che tab_gen esista (dalla cella precedente)\n",
    "if 'tab_gen' not in globals():\n",
    "    print(\"ATTENZIONE: tab_gen non trovato. Esegui prima la cella 41 (incrocio genere × uso).\")\n",
    "else:\n",
    "    # Test chi-quadrato per ogni gruppo separatamente\n",
    "    results_gender = []\n",
    "    \n",
    "    for grp in ORDER_4:\n",
    "        print(f\"\\n{'─'*60}\")\n",
    "        print(f\"Gruppo: {grp}\")\n",
    "        print(f\"{'─'*60}\")\n",
    "        \n",
    "        # Filtra dati per questo gruppo (solo Maschio/Femmina)\n",
    "        sub = tab_gen[(tab_gen['GruppoDettaglio']==grp) & \n",
    "                      (tab_gen['GenereCat'].isin(['Maschio','Femmina']))].copy()\n",
    "        \n",
    "        if len(sub) < 2:\n",
    "            print(\"  ⚠️  Dati insufficienti per il test\")\n",
    "            continue\n",
    "        \n",
    "        # Crea tabella di contingenza: righe=genere, colonne=[non_users, users]\n",
    "        contingency = []\n",
    "        for gender in ['Maschio', 'Femmina']:\n",
    "            row_data = sub[sub['GenereCat']==gender]\n",
    "            if not row_data.empty:\n",
    "                total = int(row_data['total'].iloc[0])\n",
    "                users = int(row_data['users'].iloc[0])\n",
    "                non_users = total - users\n",
    "                contingency.append([non_users, users])\n",
    "                print(f\"  {gender:8s}: {users:3d}/{total:3d} usano IA ({row_data['perc_users_of_gender'].iloc[0]:.1f}%)\")\n",
    "        \n",
    "        if len(contingency) == 2:\n",
    "            contingency = np.array(contingency)\n",
    "            \n",
    "            # Test chi-quadrato\n",
    "            try:\n",
    "                chi2, p_value, dof, expected = chi2_contingency(contingency)\n",
    "                \n",
    "                # Se valori attesi < 5, usa Fisher's exact test\n",
    "                if (expected < 5).any():\n",
    "                    print(\"\\n  ℹ️  Valori attesi < 5, uso Fisher's exact test\")\n",
    "                    oddsratio, p_value_fisher = fisher_exact(contingency)\n",
    "                    print(f\"  Fisher's exact test p-value: {p_value_fisher:.4f}\")\n",
    "                    sig = \"✓ Significativo\" if p_value_fisher < 0.05 else \"✗ Non significativo\"\n",
    "                    print(f\"  {sig} (α=0.05)\")\n",
    "                    results_gender.append({\n",
    "                        'Gruppo': grp,\n",
    "                        'Test': 'Fisher',\n",
    "                        'p-value': p_value_fisher,\n",
    "                        'Significativo (α=0.05)': p_value_fisher < 0.05\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"\\n  χ² = {chi2:.3f}, df = {dof}, p-value = {p_value:.4f}\")\n",
    "                    sig = \"✓ Significativo\" if p_value < 0.05 else \"✗ Non significativo\"\n",
    "                    print(f\"  {sig} (α=0.05)\")\n",
    "                    results_gender.append({\n",
    "                        'Gruppo': grp,\n",
    "                        'Test': 'Chi-quadrato',\n",
    "                        'Chi2': chi2,\n",
    "                        'df': dof,\n",
    "                        'p-value': p_value,\n",
    "                        'Significativo (α=0.05)': p_value < 0.05\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f\"  ⚠️  Errore nel test: {e}\")\n",
    "    \n",
    "    # Salva risultati\n",
    "    if results_gender:\n",
    "        df_results_gender = pd.DataFrame(results_gender)\n",
    "        csv_gender_sig = OUT_EXPL / 'significance_gender_use.csv'\n",
    "        df_results_gender.to_csv(csv_gender_sig, index=False)\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"RIEPILOGO TEST GENERE × USO\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(df_results_gender.to_string(index=False))\n",
    "        print(f\"\\nSalvato: {csv_gender_sig}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6185610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TEST CHI-QUADRATO: AREA DISCIPLINARE × USO IA ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency, fisher_exact\n",
    "from pathlib import Path\n",
    "\n",
    "OUT_EXPL = (Path.cwd()/\"../analysis/exports/latest\").resolve()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TEST CHI-QUADRATO: Area disciplinare × Uso dell'IA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Verifica che tab_area esista\n",
    "if 'tab_area' not in globals() or tab_area is None:\n",
    "    print(\"\\n⚠️  ATTENZIONE: tab_area non disponibile.\")\n",
    "    print(\"   Per eseguire questo test, è necessario prima eseguire la cella 52\")\n",
    "    print(\"   che calcola Area_norm e crea la tabella di contingenza tab_area.\\n\")\n",
    "    print(\"=\" * 80)\n",
    "elif len(tab_area) == 0:\n",
    "    print(\"\\n⚠️  ATTENZIONE: tab_area è vuoto. Verifica i dati.\\n\")\n",
    "    print(\"=\" * 80)\n",
    "else:\n",
    "    # Test chi-quadrato per ogni gruppo separatamente\n",
    "    results_area = []\n",
    "    \n",
    "    for grp in ORDER_4:\n",
    "        print(f\"\\n{'─'*60}\")\n",
    "        print(f\"Gruppo: {grp}\")\n",
    "        print(f\"{'─'*60}\")\n",
    "        \n",
    "        # Filtra dati per questo gruppo (solo STEM/Umanistiche)\n",
    "        sub = tab_area[(tab_area['GruppoDettaglio']==grp) & \n",
    "                       (tab_area['Area_norm'].isin(['STEM','Umanistiche']))].copy()\n",
    "        \n",
    "        if len(sub) < 2:\n",
    "            print(\"  ⚠️  Dati insufficienti per il test\")\n",
    "            continue\n",
    "        \n",
    "        # Crea tabella di contingenza: righe=area, colonne=[non_users, users]\n",
    "        contingency = []\n",
    "        for area in ['STEM', 'Umanistiche']:\n",
    "            row_data = sub[sub['Area_norm']==area]\n",
    "            if not row_data.empty:\n",
    "                total = int(row_data['total'].iloc[0])\n",
    "                users = int(row_data['users'].iloc[0])\n",
    "                non_users = total - users\n",
    "                contingency.append([non_users, users])\n",
    "                print(f\"  {area:12s}: {users:3d}/{total:3d} usano IA ({row_data['perc_users_of_area'].iloc[0]:.1f}%)\")\n",
    "        \n",
    "        if len(contingency) == 2:\n",
    "            contingency = np.array(contingency)\n",
    "            \n",
    "            # Test chi-quadrato\n",
    "            try:\n",
    "                chi2, p_value, dof, expected = chi2_contingency(contingency)\n",
    "                \n",
    "                # Se valori attesi < 5, usa Fisher's exact test\n",
    "                if (expected < 5).any():\n",
    "                    print(\"\\n  ℹ️  Valori attesi < 5, uso Fisher's exact test\")\n",
    "                    oddsratio, p_value_fisher = fisher_exact(contingency)\n",
    "                    print(f\"  Fisher's exact test p-value: {p_value_fisher:.4f}\")\n",
    "                    sig = \"✓ Significativo\" if p_value_fisher < 0.05 else \"✗ Non significativo\"\n",
    "                    print(f\"  {sig} (α=0.05)\")\n",
    "                    results_area.append({\n",
    "                        'Gruppo': grp,\n",
    "                        'Test': 'Fisher',\n",
    "                        'p-value': p_value_fisher,\n",
    "                        'Significativo (α=0.05)': p_value_fisher < 0.05\n",
    "                    })\n",
    "                else:\n",
    "                    print(f\"\\n  χ² = {chi2:.3f}, df = {dof}, p-value = {p_value:.4f}\")\n",
    "                    sig = \"✓ Significativo\" if p_value < 0.05 else \"✗ Non significativo\"\n",
    "                    print(f\"  {sig} (α=0.05)\")\n",
    "                    results_area.append({\n",
    "                        'Gruppo': grp,\n",
    "                        'Test': 'Chi-quadrato',\n",
    "                        'Chi2': chi2,\n",
    "                        'df': dof,\n",
    "                        'p-value': p_value,\n",
    "                        'Significativo (α=0.05)': p_value < 0.05\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f\"  ⚠️  Errore nel test: {e}\")\n",
    "    \n",
    "    # Salva risultati\n",
    "    if results_area:\n",
    "        df_results_area = pd.DataFrame(results_area)\n",
    "        csv_area_sig = OUT_EXPL / 'significance_area_use.csv'\n",
    "        df_results_area.to_csv(csv_area_sig, index=False)\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"RIEPILOGO TEST AREA × USO\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(df_results_area.to_string(index=False))\n",
    "        print(f\"\\nSalvato: {csv_area_sig}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26c6ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TEST CHI-QUADRATO: DIFFERENZE TRA I 4 GRUPPI ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "from pathlib import Path\n",
    "\n",
    "OUT_EXPL = (Path.cwd()/\"../analysis/exports/latest\").resolve()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TEST CHI-QUADRATO: Differenze nell'uso dell'IA tra i 4 gruppi\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Verifica che df_check esista (dalla cella 41)\n",
    "if 'df_check' not in globals():\n",
    "    print(\"ATTENZIONE: df_check non trovato. Esegui prima la cella 41 (incrocio genere × uso).\")\n",
    "else:\n",
    "    # Crea tabella di contingenza: righe=gruppo, colonne=[non_users, users]\n",
    "    contingency_groups = []\n",
    "    group_labels = []\n",
    "    \n",
    "    print(\"\\nDistribuzione uso IA per gruppo:\")\n",
    "    print(f\"{'─'*60}\")\n",
    "    \n",
    "    for grp in ORDER_4:\n",
    "        grp_data = df_check[df_check['GruppoDettaglio']==grp]\n",
    "        total = len(grp_data)\n",
    "        users = grp_data['uses_ai'].sum()\n",
    "        non_users = total - users\n",
    "        perc = (users / total * 100) if total > 0 else 0\n",
    "        \n",
    "        contingency_groups.append([non_users, users])\n",
    "        group_labels.append(grp)\n",
    "        \n",
    "        print(f\"{grp:35s}: {users:3d}/{total:3d} ({perc:.1f}%)\")\n",
    "    \n",
    "    contingency_groups = np.array(contingency_groups)\n",
    "    \n",
    "    # Test chi-quadrato\n",
    "    try:\n",
    "        chi2, p_value, dof, expected = chi2_contingency(contingency_groups)\n",
    "        \n",
    "        print(f\"\\n{'─'*60}\")\n",
    "        print(\"Test chi-quadrato:\")\n",
    "        print(f\"  χ² = {chi2:.3f}\")\n",
    "        print(f\"  df = {dof}\")\n",
    "        print(f\"  p-value = {p_value:.6f}\")\n",
    "        \n",
    "        if p_value < 0.001:\n",
    "            print(f\"  ✓✓✓ ALTAMENTE significativo (p < 0.001)\")\n",
    "        elif p_value < 0.01:\n",
    "            print(f\"  ✓✓ Molto significativo (p < 0.01)\")\n",
    "        elif p_value < 0.05:\n",
    "            print(f\"  ✓ Significativo (p < 0.05)\")\n",
    "        else:\n",
    "            print(f\"  ✗ Non significativo (p ≥ 0.05)\")\n",
    "        \n",
    "        # Verifica assunzioni del test\n",
    "        print(f\"\\n{'─'*60}\")\n",
    "        print(\"Verifica assunzioni:\")\n",
    "        min_expected = expected.min()\n",
    "        print(f\"  Minimo valore atteso: {min_expected:.2f}\")\n",
    "        if min_expected < 5:\n",
    "            print(\"  ⚠️  ATTENZIONE: alcuni valori attesi < 5, i risultati potrebbero non essere affidabili\")\n",
    "        else:\n",
    "            print(\"  ✓ Tutti i valori attesi ≥ 5, assunzioni soddisfatte\")\n",
    "        \n",
    "        # Salva risultati\n",
    "        result_groups = {\n",
    "            'Test': 'Chi-quadrato tra 4 gruppi',\n",
    "            'Chi2': chi2,\n",
    "            'df': dof,\n",
    "            'p-value': p_value,\n",
    "            'Significativo (α=0.05)': p_value < 0.05,\n",
    "            'Significativo (α=0.01)': p_value < 0.01,\n",
    "            'Significativo (α=0.001)': p_value < 0.001,\n",
    "            'Min_expected': min_expected,\n",
    "            'Assunzioni_OK': min_expected >= 5\n",
    "        }\n",
    "        \n",
    "        df_result_groups = pd.DataFrame([result_groups])\n",
    "        csv_groups_sig = OUT_EXPL / 'significance_4groups_use.csv'\n",
    "        df_result_groups.to_csv(csv_groups_sig, index=False)\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\"CONCLUSIONE:\")\n",
    "        if p_value < 0.05:\n",
    "            print(\"Le differenze nell'uso dell'IA tra i 4 gruppi SONO statisticamente significative.\")\n",
    "            print(\"Questo indica che l'appartenenza al gruppo è associata all'uso dell'IA.\")\n",
    "        else:\n",
    "            print(\"Le differenze nell'uso dell'IA tra i 4 gruppi NON sono statisticamente significative.\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        print(f\"\\nSalvato: {csv_groups_sig}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Errore nel test: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc02330d",
   "metadata": {},
   "source": [
    "### 1.6.b Sintesi test Chi-quadrato"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9751b914",
   "metadata": {},
   "source": [
    "### 1.6.c ANOVA sulle ore settimanali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bf9194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ANOVA: ORE SETTIMANALI USO IA TRA I 4 GRUPPI ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "\n",
    "OUT_EXPL = (Path.cwd()/\"../analysis/exports/latest\").resolve()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ANOVA: Ore settimanali di uso dell'IA tra i 4 gruppi\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Verifica che df_use esista (dalla cella ore settimanali)\n",
    "if 'df_use' not in globals():\n",
    "    print(\"ATTENZIONE: df_use non trovato. Esegui prima le celle sull'analisi ore settimanali.\")\n",
    "else:\n",
    "    # Prepara dati per ANOVA\n",
    "    groups_data = []\n",
    "    group_names = []\n",
    "    \n",
    "    print(\"\\nStatistiche descrittive per gruppo:\")\n",
    "    print(f\"{'─'*80}\")\n",
    "    print(f\"{'Gruppo':<35s} {'N':>6s} {'Media':>8s} {'Mediana':>8s} {'SD':>8s} {'Min':>6s} {'Max':>6s}\")\n",
    "    print(f\"{'─'*80}\")\n",
    "    \n",
    "    for grp in ORDER_4:\n",
    "        grp_data = df_use[df_use['GruppoDettaglio']==grp]['OreSettimanali'].dropna()\n",
    "        if len(grp_data) > 0:\n",
    "            groups_data.append(grp_data.values)\n",
    "            group_names.append(grp)\n",
    "            \n",
    "            print(f\"{grp:<35s} {len(grp_data):>6d} {grp_data.mean():>8.2f} {grp_data.median():>8.2f} \"\n",
    "                  f\"{grp_data.std():>8.2f} {grp_data.min():>6.1f} {grp_data.max():>6.1f}\")\n",
    "    \n",
    "    # Esegui ANOVA one-way\n",
    "    if len(groups_data) >= 2:\n",
    "        print(f\"\\n{'─'*80}\")\n",
    "        print(\"ANOVA One-Way:\")\n",
    "        print(f\"{'─'*80}\")\n",
    "        \n",
    "        f_stat, p_value = stats.f_oneway(*groups_data)\n",
    "        \n",
    "        print(f\"  F-statistic = {f_stat:.4f}\")\n",
    "        print(f\"  p-value = {p_value:.6f}\")\n",
    "        \n",
    "        if p_value < 0.001:\n",
    "            print(f\"  ✓✓✓ ALTAMENTE significativo (p < 0.001)\")\n",
    "        elif p_value < 0.01:\n",
    "            print(f\"  ✓✓ Molto significativo (p < 0.01)\")\n",
    "        elif p_value < 0.05:\n",
    "            print(f\"  ✓ Significativo (p < 0.05)\")\n",
    "        else:\n",
    "            print(f\"  ✗ Non significativo (p ≥ 0.05)\")\n",
    "        \n",
    "        # Verifica assunzioni\n",
    "        print(f\"\\n{'─'*80}\")\n",
    "        print(\"Verifica assunzioni ANOVA:\")\n",
    "        print(f\"{'─'*80}\")\n",
    "        \n",
    "        # Test di Levene per omogeneità delle varianze\n",
    "        levene_stat, levene_p = stats.levene(*groups_data)\n",
    "        print(f\"  Test di Levene (omogeneità varianze):\")\n",
    "        print(f\"    Statistica = {levene_stat:.4f}, p-value = {levene_p:.4f}\")\n",
    "        if levene_p >= 0.05:\n",
    "            print(f\"    ✓ Varianze omogenee (assunzione soddisfatta)\")\n",
    "        else:\n",
    "            print(f\"    ⚠️  Varianze NON omogenee (considera Welch's ANOVA)\")\n",
    "        \n",
    "        # Test di normalità (Shapiro-Wilk) per ogni gruppo\n",
    "        print(f\"\\n  Test di normalità (Shapiro-Wilk) per gruppo:\")\n",
    "        all_normal = True\n",
    "        for i, (grp_name, data) in enumerate(zip(group_names, groups_data)):\n",
    "            if len(data) >= 3:\n",
    "                shapiro_stat, shapiro_p = stats.shapiro(data)\n",
    "                normal = shapiro_p >= 0.05\n",
    "                all_normal = all_normal and normal\n",
    "                status = \"✓\" if normal else \"⚠️\"\n",
    "                print(f\"    {status} {grp_name:<35s}: p = {shapiro_p:.4f}\")\n",
    "        \n",
    "        if not all_normal:\n",
    "            print(f\"\\n  ⚠️  Alcuni gruppi non sono normali → considera Kruskal-Wallis (non parametrico)\")\n",
    "        \n",
    "        # Salva risultati\n",
    "        anova_result = {\n",
    "            'Test': 'ANOVA One-Way',\n",
    "            'F-statistic': f_stat,\n",
    "            'p-value': p_value,\n",
    "            'Significativo (α=0.05)': p_value < 0.05,\n",
    "            'Significativo (α=0.01)': p_value < 0.01,\n",
    "            'Significativo (α=0.001)': p_value < 0.001,\n",
    "            'Levene_statistic': levene_stat,\n",
    "            'Levene_p-value': levene_p,\n",
    "            'Varianze_omogenee': levene_p >= 0.05\n",
    "        }\n",
    "        \n",
    "        df_anova = pd.DataFrame([anova_result])\n",
    "        csv_anova = OUT_EXPL / 'anova_hours_4groups.csv'\n",
    "        df_anova.to_csv(csv_anova, index=False)\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        if p_value < 0.05:\n",
    "            print(\"CONCLUSIONE: Le medie delle ore settimanali di uso IA differiscono\")\n",
    "            print(\"significativamente tra i 4 gruppi.\")\n",
    "            print(\"→ Prosegui con test post-hoc per identificare quali coppie differiscono.\")\n",
    "        else:\n",
    "            print(\"CONCLUSIONE: Non ci sono differenze significative nelle medie delle ore\")\n",
    "            print(\"settimanali di uso IA tra i 4 gruppi.\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        print(f\"\\nSalvato: {csv_anova}\")\n",
    "    else:\n",
    "        print(\"⚠️  Dati insufficienti per ANOVA (servono almeno 2 gruppi)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6da6a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TEST POST-HOC: Tukey HSD per confronti multipli ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "from itertools import combinations\n",
    "\n",
    "OUT_EXPL = (Path.cwd()/\"../analysis/exports/latest\").resolve()\n",
    "\n",
    "# Verifica che l'ANOVA sia stata eseguita e sia significativa\n",
    "if 'p_value' not in globals():\n",
    "    print(\"⚠️  Esegui prima la cella ANOVA sopra.\")\n",
    "elif p_value >= 0.05:\n",
    "    print(\"ℹ️  ANOVA non significativo (p ≥ 0.05), test post-hoc non necessari.\")\n",
    "    print(\"   Non ci sono differenze significative tra i gruppi.\")\n",
    "else:\n",
    "    print(\"=\"*80)\n",
    "    print(\"TEST POST-HOC: Confronti a coppie (Tukey HSD)\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nPoiché l'ANOVA è significativo, identifichiamo quali coppie differiscono.\\n\")\n",
    "    \n",
    "    # Implementazione manuale Tukey HSD (scipy non ha statsmodels di default)\n",
    "    # Alternativa: usa test t con correzione Bonferroni\n",
    "    \n",
    "    # Prepara tutti i dati con etichette gruppo\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "    for grp in ORDER_4:\n",
    "        grp_data = df_use[df_use['GruppoDettaglio']==grp]['OreSettimanali'].dropna()\n",
    "        all_data.extend(grp_data.values)\n",
    "        all_labels.extend([grp] * len(grp_data))\n",
    "    \n",
    "    df_for_posthoc = pd.DataFrame({'Gruppo': all_labels, 'Ore': all_data})\n",
    "    \n",
    "    # Confronti a coppie con test t (correzione Bonferroni)\n",
    "    n_comparisons = len(list(combinations(ORDER_4, 2)))\n",
    "    alpha_bonferroni = 0.05 / n_comparisons\n",
    "    \n",
    "    print(f\"Numero di confronti: {n_comparisons}\")\n",
    "    print(f\"Soglia Bonferroni: α = {alpha_bonferroni:.4f} (0.05/{n_comparisons})\")\n",
    "    print(f\"\\n{'─'*90}\")\n",
    "    print(f\"{'Gruppo 1':<35s} {'Gruppo 2':<35s} {'Diff Media':>10s} {'p-value':>10s} {'Sig?':>5s}\")\n",
    "    print(f\"{'─'*90}\")\n",
    "    \n",
    "    posthoc_results = []\n",
    "    \n",
    "    for grp1, grp2 in combinations(ORDER_4, 2):\n",
    "        data1 = df_use[df_use['GruppoDettaglio']==grp1]['OreSettimanali'].dropna()\n",
    "        data2 = df_use[df_use['GruppoDettaglio']==grp2]['OreSettimanali'].dropna()\n",
    "        \n",
    "        if len(data1) > 0 and len(data2) > 0:\n",
    "            # Test t indipendente\n",
    "            t_stat, p_val = stats.ttest_ind(data1, data2)\n",
    "            diff_mean = data1.mean() - data2.mean()\n",
    "            \n",
    "            # Significativo con Bonferroni?\n",
    "            sig = \"✓\" if p_val < alpha_bonferroni else \"✗\"\n",
    "            \n",
    "            print(f\"{grp1:<35s} {grp2:<35s} {diff_mean:>10.2f} {p_val:>10.6f} {sig:>5s}\")\n",
    "            \n",
    "            posthoc_results.append({\n",
    "                'Gruppo_1': grp1,\n",
    "                'Gruppo_2': grp2,\n",
    "                'Media_Gruppo_1': data1.mean(),\n",
    "                'Media_Gruppo_2': data2.mean(),\n",
    "                'Differenza_medie': diff_mean,\n",
    "                't-statistic': t_stat,\n",
    "                'p-value': p_val,\n",
    "                'p-value_Bonferroni': alpha_bonferroni,\n",
    "                'Significativo_Bonferroni': p_val < alpha_bonferroni\n",
    "            })\n",
    "    \n",
    "    print(f\"{'─'*90}\")\n",
    "    \n",
    "    # Salva risultati\n",
    "    df_posthoc = pd.DataFrame(posthoc_results)\n",
    "    csv_posthoc = OUT_EXPL / 'posthoc_tukey_hours_4groups.csv'\n",
    "    df_posthoc.to_csv(csv_posthoc, index=False)\n",
    "    \n",
    "    # Riepilogo\n",
    "    sig_comparisons = df_posthoc[df_posthoc['Significativo_Bonferroni']==True]\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"RIEPILOGO CONFRONTI SIGNIFICATIVI:\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    if len(sig_comparisons) > 0:\n",
    "        print(f\"\\nTrovate {len(sig_comparisons)} coppie con differenze significative:\\n\")\n",
    "        for _, row in sig_comparisons.iterrows():\n",
    "            print(f\"  • {row['Gruppo_1']}\")\n",
    "            print(f\"    vs {row['Gruppo_2']}\")\n",
    "            print(f\"    Differenza: {row['Differenza_medie']:.2f} ore/settimana (p={row['p-value']:.6f})\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"\\nNessuna coppia di gruppi differisce significativamente dopo\")\n",
    "        print(\"la correzione per confronti multipli (Bonferroni).\")\n",
    "    \n",
    "    print(f\"Salvato: {csv_posthoc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee500a7a",
   "metadata": {},
   "source": [
    "### 1.6.d Riepilogo ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e1dbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === USO IA incrociato con GENERE ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "OUT_EXPL = (Path.cwd()/\"../analysis/exports/latest\").resolve()\n",
    "ASSETS = (Path.cwd()/\"../assets/figures\").resolve()\n",
    "OUT_EXPL.mkdir(parents=True, exist_ok=True)\n",
    "ASSETS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Usa col_daily_stu se disponibile (definita in celle precedenti)\n",
    "if 'col_daily_stu' in globals() and col_daily_stu is not None:\n",
    "    col_use = col_daily_stu\n",
    "    print(f\"Usiamo la colonna uso quotidiano: {col_use}\")\n",
    "elif 'col_daily_doc' in globals() and col_daily_doc is not None:\n",
    "    col_use = col_daily_doc\n",
    "    print(f\"Usiamo la colonna uso quotidiano (docenti): {col_use}\")\n",
    "else:\n",
    "    print(\"ATTENZIONE: col_daily_stu/col_daily_doc non trovate. Esegui prima le celle che le definiscono.\")\n",
    "    col_use = None\n",
    "\n",
    "if col_use is not None:\n",
    "    # Usa GenereCat già calcolata (dalla cella precedente del genere)\n",
    "    gen_col = 'GenereCat'\n",
    "    print('Usando GenereCat già calcolata.')\n",
    "\n",
    "    # Usa yes_set già definito nel kernel (o fallback)\n",
    "    if 'yes_set' not in globals():\n",
    "        yes_set = set(['si','sì','yes','y','1','true'])\n",
    "    \n",
    "    # Costruisce tabella: per GruppoDettaglio e GenereCat -> conteggio utenti e % che usano IA\n",
    "    df_check = DF_plot.copy()\n",
    "    \n",
    "    # Assicura le colonne usate\n",
    "    if col_use not in df_check.columns:\n",
    "        df_check[col_use] = DF[col_use]\n",
    "    \n",
    "    # Prendi GenereCat da base_gf (già calcolata)\n",
    "    if 'base_gf' in globals() and gen_col in base_gf.columns:\n",
    "        df_check[gen_col] = base_gf[gen_col]\n",
    "    else:\n",
    "        print(\"ATTENZIONE: base_gf o GenereCat non trovata. Esegui prima la cella che calcola il genere.\")\n",
    "        df_check[gen_col] = 'Non risponde'\n",
    "\n",
    "    # Normalizza uso come boolean\n",
    "    def is_yes(v):\n",
    "        if pd.isna(v):\n",
    "            return False\n",
    "        return str(v).strip().lower() in yes_set\n",
    "\n",
    "    df_check['uses_ai'] = df_check[col_use].apply(is_yes)\n",
    "\n",
    "    # Filtra ai 4 gruppi\n",
    "    groups = ORDER_4 if 'ORDER_4' in globals() else sorted(df_check['GruppoDettaglio'].unique())\n",
    "    df_check['GruppoDettaglio'] = pd.Categorical(df_check['GruppoDettaglio'], categories=groups, ordered=True)\n",
    "\n",
    "    # Tabella per genere\n",
    "    tab_gen = (\n",
    "        df_check.groupby(['GruppoDettaglio','GenereCat'], observed=False)\n",
    "        .agg(total=('uses_ai','size'), users=('uses_ai','sum'))\n",
    "        .reset_index()\n",
    "    )\n",
    "    tab_gen['perc_users_of_gender'] = (tab_gen['users'] / tab_gen['total'] * 100).round(1)\n",
    "\n",
    "    csv_gen = OUT_EXPL / 'cross_gender_use_4groups.csv'\n",
    "    tab_gen.to_csv(csv_gen, index=False)\n",
    "    print('Salvato CSV incrocio Genere-Use:', csv_gen)\n",
    "    display(tab_gen)\n",
    "\n",
    "    # Grafico percentuale di uso tra Maschio/Femmina per ogni gruppo (IT)\n",
    "    fig, ax = plt.subplots(figsize=(12,5))\n",
    "    x = np.arange(len(groups))\n",
    "    width = 0.35\n",
    "    colors = {'Femmina':'#ff69b4','Maschio':'#4169e1'}\n",
    "\n",
    "    for i, g in enumerate(groups):\n",
    "        sub = tab_gen[tab_gen['GruppoDettaglio']==g]\n",
    "        for j, gender in enumerate(['Femmina','Maschio']):\n",
    "            row = sub[sub['GenereCat']==gender]\n",
    "            if row.empty:\n",
    "                val = 0.0\n",
    "            else:\n",
    "                val = float(row['perc_users_of_gender'].iloc[0])\n",
    "            ax.bar(i + (j-0.5)*width, val, width, color=colors[gender], label=gender if i==0 else None)\n",
    "            ax.text(i + (j-0.5)*width, val + 1, f\"{val:.0f}%\", ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(groups, rotation=0)\n",
    "    ax.set_ylabel('Percentuale utenti IA (tra il genere nel gruppo)')\n",
    "    ax.set_title('Uso dell\\'IA per Genere nei 4 gruppi')\n",
    "    ax.legend(ncols=2)\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    plt.tight_layout()\n",
    "    fp_it = OUT_EXPL / 'cross_gender_use_4groups_it.png'\n",
    "    fig.savefig(fp_it, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f'Salvato: {fp_it}')\n",
    "\n",
    "    # Versione EN\n",
    "    fig, ax = plt.subplots(figsize=(12,5))\n",
    "    for i, g in enumerate(groups):\n",
    "        sub = tab_gen[tab_gen['GruppoDettaglio']==g]\n",
    "        for j, gender in enumerate(['Femmina','Maschio']):\n",
    "            row = sub[sub['GenereCat']==gender]\n",
    "            val = float(row['perc_users_of_gender'].iloc[0]) if not row.empty else 0.0\n",
    "            ax.bar(i + (j-0.5)*width, val, width, color=colors[gender], label=('Female' if gender=='Femmina' else 'Male') if i==0 else None)\n",
    "            ax.text(i + (j-0.5)*width, val + 1, f\"{val:.0f}%\", ha='center', va='bottom', fontsize=9)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([map_it_en[g] if g in map_it_en else g for g in groups], rotation=0)\n",
    "    ax.set_ylabel('Percent of AI users (within gender in group)')\n",
    "    ax.set_title('AI use by Gender across 4 groups')\n",
    "    ax.legend(ncols=2)\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    plt.tight_layout()\n",
    "    fp_en = OUT_EXPL / 'cross_gender_use_4groups_en.png'\n",
    "    fig.savefig(fp_en, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f'Salvato: {fp_en}')\n",
    "\n",
    "    # copia in assets\n",
    "    try:\n",
    "        shutil.copyfile(fp_en, ASSETS / 'cross_gender_use_4groups_en.png')\n",
    "        shutil.copyfile(fp_it, ASSETS / 'cross_gender_use_4groups_it.png')\n",
    "        print('Copiati grafici in assets.')\n",
    "    except Exception as e:\n",
    "        print('Avviso copia assets:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e86510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === USO IA incrociato con AREA (STEM vs Umanistiche) ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Verifica che tab_area sia già stata creata dalla cella di preparazione\n",
    "if 'tab_area' not in globals() or tab_area is None:\n",
    "    print('ATTENZIONE: tab_area non trovata. Esegui prima la cella 42 (preparazione dati).')\n",
    "else:\n",
    "    print(f\"Usando tab_area già creato: {len(tab_area)} righe\")\n",
    "    \n",
    "    # Salva CSV\n",
    "    csv_area = OUT_EXPL / 'cross_area_use_4groups.csv'\n",
    "    tab_area.to_csv(csv_area, index=False)\n",
    "    print('Salvato CSV incrocio Area-Use:', csv_area)\n",
    "    display(tab_area)\n",
    "\n",
    "    # Grafico IT\n",
    "    groups = ORDER_4 if 'ORDER_4' in globals() else sorted(tab_area['GruppoDettaglio'].unique())\n",
    "    fig, ax = plt.subplots(figsize=(12,5))\n",
    "    x = np.arange(len(groups))\n",
    "    width = 0.35\n",
    "    colors = {'STEM':'#2ecc71','Umanistiche':'#e74c3c'}\n",
    "    for i, g in enumerate(groups):\n",
    "        sub = tab_area[tab_area['GruppoDettaglio']==g]\n",
    "        for j, area in enumerate(['STEM','Umanistiche']):\n",
    "            row = sub[sub['Area_norm']==area]\n",
    "            val = float(row['perc_users_of_area'].iloc[0]) if not row.empty else 0.0\n",
    "            ax.bar(i + (j-0.5)*width, val, width, color=colors[area], label=area if i==0 else None)\n",
    "            ax.text(i + (j-0.5)*width, val + 1, f\"{val:.0f}%\", ha='center', va='bottom', fontsize=9)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(groups, rotation=0)\n",
    "    ax.set_ylabel('Percentuale utenti IA (tra area nel gruppo)')\n",
    "    ax.set_title('Uso dell\\'IA per Area disciplinare (STEM/Umanistiche) nei 4 gruppi')\n",
    "    ax.legend(ncols=2)\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    plt.tight_layout()\n",
    "    fp_it = OUT_EXPL / 'cross_area_use_4groups_it.png'\n",
    "    fig.savefig(fp_it, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    shutil.copy(fp_it, ASSETS / fp_it.name)\n",
    "    print('Salvato grafico IT:', fp_it)\n",
    "\n",
    "    # Grafico EN\n",
    "    fig2, ax2 = plt.subplots(figsize=(12,5))\n",
    "    for i, g in enumerate(groups):\n",
    "        sub = tab_area[tab_area['GruppoDettaglio']==g]\n",
    "        for j, area in enumerate(['STEM','Umanistiche']):\n",
    "            row = sub[sub['Area_norm']==area]\n",
    "            val = float(row['perc_users_of_area'].iloc[0]) if not row.empty else 0.0\n",
    "            ax2.bar(i + (j-0.5)*width, val, width, color=colors[area], label=area if i==0 else None)\n",
    "            ax2.text(i + (j-0.5)*width, val + 1, f\"{val:.0f}%\", ha='center', va='bottom', fontsize=9)\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(groups, rotation=0)\n",
    "    ax2.set_ylabel('Percentage of AI users (within area in group)')\n",
    "    ax2.set_title('AI Use by Disciplinary Area (STEM/Humanities) across 4 groups')\n",
    "    ax2.legend(ncols=2)\n",
    "    ax2.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    plt.tight_layout()\n",
    "    fp_en = OUT_EXPL / 'cross_area_use_4groups_en.png'\n",
    "    fig2.savefig(fp_en, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    shutil.copy(fp_en, ASSETS / fp_en.name)\n",
    "    print('Salvato grafico EN:', fp_en)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aebfe8",
   "metadata": {},
   "source": [
    "## 🔬 Variazioni DENTRO i 4 gruppi: Genere e Area\n",
    "\n",
    "Verifichiamo se **all'interno di ciascun gruppo** ci sono differenze significative nelle ore settimanali di uso IA per:\n",
    "1. **Genere** (Maschi vs Femmine) → t-test indipendente\n",
    "2. **Area disciplinare** (STEM vs Umanistiche) → t-test indipendente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91642ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === VARIAZIONI GENERE DENTRO OGNI GRUPPO (ore settimanali) ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "\n",
    "OUT_EXPL = (Path.cwd()/\"../analysis/exports/latest\").resolve()\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(\"DIFFERENZE DI GENERE NELLE ORE SETTIMANALI - PER OGNI GRUPPO\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "if 'df_use' not in globals():\n",
    "    print(\"⚠️  df_use non trovato. Esegui prima le celle sull'analisi ore settimanali.\")\n",
    "elif 'base_gf' not in globals() or 'GenereCat' not in base_gf.columns:\n",
    "    print(\"⚠️  base_gf o GenereCat non trovata. Esegui prima la cella che calcola il genere.\")\n",
    "else:\n",
    "    # Aggiungi GenereCat a df_use tramite merge\n",
    "    df_use_with_gender = df_use.merge(\n",
    "        base_gf[['GenereCat']],\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    results_gender_hours = []\n",
    "    \n",
    "    print(f\"\\n{'─'*90}\")\n",
    "    print(f\"{'Gruppo':<35s} {'N_M':>6s} {'Media_M':>9s} {'N_F':>6s} {'Media_F':>9s} {'Diff':>8s} {'p-value':>10s} {'Sig?':>5s}\")\n",
    "    print(f\"{'─'*90}\")\n",
    "    \n",
    "    for grp in ORDER_4:\n",
    "        grp_data = df_use_with_gender[df_use_with_gender['GruppoDettaglio']==grp].copy()\n",
    "        \n",
    "        # Filtra per genere\n",
    "        m_data = grp_data[grp_data['GenereCat']=='Maschio']['OreSettimanali'].dropna()\n",
    "        f_data = grp_data[grp_data['GenereCat']=='Femmina']['OreSettimanali'].dropna()\n",
    "        \n",
    "        if len(m_data) >= 2 and len(f_data) >= 2:\n",
    "            # T-test indipendente\n",
    "            t_stat, p_val = stats.ttest_ind(m_data, f_data)\n",
    "            diff = m_data.mean() - f_data.mean()\n",
    "            \n",
    "            # Significativo?\n",
    "            if p_val < 0.001:\n",
    "                sig = \"✓✓✓\"\n",
    "            elif p_val < 0.01:\n",
    "                sig = \"✓✓\"\n",
    "            elif p_val < 0.05:\n",
    "                sig = \"✓\"\n",
    "            else:\n",
    "                sig = \"✗\"\n",
    "            \n",
    "            print(f\"{grp:<35s} {len(m_data):>6d} {m_data.mean():>9.2f} {len(f_data):>6d} {f_data.mean():>9.2f} \"\n",
    "                  f\"{diff:>8.2f} {p_val:>10.6f} {sig:>5s}\")\n",
    "            \n",
    "            results_gender_hours.append({\n",
    "                'Gruppo': grp,\n",
    "                'N_Maschi': len(m_data),\n",
    "                'Media_Maschi': m_data.mean(),\n",
    "                'SD_Maschi': m_data.std(),\n",
    "                'N_Femmine': len(f_data),\n",
    "                'Media_Femmine': f_data.mean(),\n",
    "                'SD_Femmine': f_data.std(),\n",
    "                'Differenza_medie': diff,\n",
    "                't-statistic': t_stat,\n",
    "                'p-value': p_val,\n",
    "                'Significativo_0.05': p_val < 0.05,\n",
    "                'Significativo_0.01': p_val < 0.01,\n",
    "                'Significativo_0.001': p_val < 0.001\n",
    "            })\n",
    "        else:\n",
    "            print(f\"{grp:<35s} {'Dati insufficienti'}\")\n",
    "    \n",
    "    print(f\"{'─'*90}\")\n",
    "    \n",
    "    # Salva risultati\n",
    "    if results_gender_hours:\n",
    "        df_gender_hours = pd.DataFrame(results_gender_hours)\n",
    "        csv_gender_hours = OUT_EXPL / 'within_group_gender_hours.csv'\n",
    "        df_gender_hours.to_csv(csv_gender_hours, index=False)\n",
    "        \n",
    "        # Riepilogo\n",
    "        sig_groups = df_gender_hours[df_gender_hours['Significativo_0.05']==True]\n",
    "        \n",
    "        print(f\"\\n{'='*90}\")\n",
    "        print(\"RIEPILOGO DIFFERENZE DI GENERE:\")\n",
    "        print(f\"{'='*90}\")\n",
    "        \n",
    "        if len(sig_groups) > 0:\n",
    "            print(f\"\\n✓ Trovate differenze significative in {len(sig_groups)} gruppi:\\n\")\n",
    "            for _, row in sig_groups.iterrows():\n",
    "                print(f\"  • {row['Gruppo']}\")\n",
    "                print(f\"    Maschi: {row['Media_Maschi']:.2f} ore/sett (N={row['N_Maschi']})\")\n",
    "                print(f\"    Femmine: {row['Media_Femmine']:.2f} ore/sett (N={row['N_Femmine']})\")\n",
    "                print(f\"    Differenza: {row['Differenza_medie']:+.2f} ore/sett (p={row['p-value']:.4f})\")\n",
    "                print()\n",
    "        else:\n",
    "            print(\"\\n✗ Nessuna differenza significativa di genere nelle ore settimanali\")\n",
    "            print(\"  all'interno dei singoli gruppi.\")\n",
    "        \n",
    "        print(f\"Salvato: {csv_gender_hours}\")\n",
    "    else:\n",
    "        print(\"\\n⚠️  Nessun risultato disponibile.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a256d555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === VARIAZIONI AREA DISCIPLINARE DENTRO OGNI GRUPPO (ore settimanali) ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "\n",
    "OUT_EXPL = (Path.cwd()/\"../analysis/exports/latest\").resolve()\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(\"DIFFERENZE DI AREA DISCIPLINARE NELLE ORE SETTIMANALI - PER OGNI GRUPPO\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "if 'df_use' not in globals():\n",
    "    print(\"⚠️  df_use non trovato. Esegui prima la cella 42 (preparazione dati).\")\n",
    "else:\n",
    "    # Cerca la colonna area in DF\n",
    "    col_area = None\n",
    "    for c in DF.columns:\n",
    "        c_lower = str(c).lower()\n",
    "        if ('settore' in c_lower and 'scientific' in c_lower) or ('classe' in c_lower and 'concorso' in c_lower):\n",
    "            col_area = c\n",
    "            break\n",
    "    \n",
    "    if col_area is None:\n",
    "        print(\"⚠️  Colonna area disciplinare non trovata. Esegui prima la cella 42.\")\n",
    "    else:\n",
    "        # Funzione di normalizzazione (stessa della cella 42)\n",
    "        def normalize_area(val):\n",
    "            if pd.isna(val):\n",
    "                return 'Altro'\n",
    "            s = str(val).lower()\n",
    "            stem_kw = ['scienz','matemat','fisic','chim','biolog','ingegner','tecnolog','informatic']\n",
    "            hum_kw = ['uman','letter','lingu','artist','music','filosofi','stori','giuridic','sociol','psicolog','pedagog']\n",
    "            if any(k in s for k in stem_kw):\n",
    "                return 'STEM'\n",
    "            elif any(k in s for k in hum_kw):\n",
    "                return 'Umanistiche'\n",
    "            else:\n",
    "                return 'Altro'\n",
    "        \n",
    "        # Aggiungi Area_norm a df_use\n",
    "        df_use_with_area = df_use.copy()\n",
    "        df_use_with_area['Area_norm'] = DF.loc[df_use.index, col_area].apply(normalize_area)\n",
    "        # Aggiungi Area_norm a df_use\n",
    "        df_use_with_area = df_use.copy()\n",
    "        df_use_with_area['Area_norm'] = DF.loc[df_use.index, col_area].apply(normalize_area)\n",
    "        \n",
    "        results_area_hours = []\n",
    "        \n",
    "        print(f\"\\n{'─'*90}\")\n",
    "        print(f\"{'Gruppo':<35s} {'N_STEM':>8s} {'Media_STEM':>11s} {'N_HUM':>8s} {'Media_HUM':>11s} {'Diff':>8s} {'p-value':>10s} {'Sig?':>5s}\")\n",
    "        print(f\"{'─'*90}\")\n",
    "    \n",
    "    for grp in ORDER_4:\n",
    "        grp_data = df_use_with_area[df_use_with_area['GruppoDettaglio']==grp].copy()\n",
    "        \n",
    "        # Filtra per area disciplinare\n",
    "        stem_data = grp_data[grp_data['Area_norm']=='STEM']['OreSettimanali'].dropna()\n",
    "        hum_data = grp_data[grp_data['Area_norm']=='Umanistiche']['OreSettimanali'].dropna()\n",
    "        \n",
    "        if len(stem_data) >= 2 and len(hum_data) >= 2:\n",
    "            # T-test indipendente\n",
    "            t_stat, p_val = stats.ttest_ind(stem_data, hum_data)\n",
    "            diff = stem_data.mean() - hum_data.mean()\n",
    "            \n",
    "            # Significativo?\n",
    "            if p_val < 0.001:\n",
    "                sig = \"✓✓✓\"\n",
    "            elif p_val < 0.01:\n",
    "                sig = \"✓✓\"\n",
    "            elif p_val < 0.05:\n",
    "                sig = \"✓\"\n",
    "            else:\n",
    "                sig = \"✗\"\n",
    "            \n",
    "            print(f\"{grp:<35s} {len(stem_data):>8d} {stem_data.mean():>11.2f} {len(hum_data):>8d} {hum_data.mean():>11.2f} \"\n",
    "                  f\"{diff:>8.2f} {p_val:>10.6f} {sig:>5s}\")\n",
    "            \n",
    "            results_area_hours.append({\n",
    "                'Gruppo': grp,\n",
    "                'N_STEM': len(stem_data),\n",
    "                'Media_STEM': stem_data.mean(),\n",
    "                'SD_STEM': stem_data.std(),\n",
    "                'N_Umanistiche': len(hum_data),\n",
    "                'Media_Umanistiche': hum_data.mean(),\n",
    "                'SD_Umanistiche': hum_data.std(),\n",
    "                'Differenza_medie': diff,\n",
    "                't-statistic': t_stat,\n",
    "                'p-value': p_val,\n",
    "                'Significativo_0.05': p_val < 0.05,\n",
    "                'Significativo_0.01': p_val < 0.01,\n",
    "                'Significativo_0.001': p_val < 0.001\n",
    "            })\n",
    "        else:\n",
    "            status = f\"N_STEM={len(stem_data)}, N_HUM={len(hum_data)}\"\n",
    "            print(f\"{grp:<35s} {status}\")\n",
    "        \n",
    "        print(f\"{'─'*90}\")\n",
    "        \n",
    "        # Salva risultati\n",
    "        if results_area_hours:\n",
    "            df_area_hours = pd.DataFrame(results_area_hours)\n",
    "            csv_area_hours = OUT_EXPL / 'within_group_area_hours.csv'\n",
    "            df_area_hours.to_csv(csv_area_hours, index=False)\n",
    "            \n",
    "            # Riepilogo\n",
    "            sig_groups = df_area_hours[df_area_hours['Significativo_0.05']==True]\n",
    "            \n",
    "            print(f\"\\n{'='*90}\")\n",
    "            print(\"RIEPILOGO DIFFERENZE DI AREA DISCIPLINARE:\")\n",
    "            print(f\"{'='*90}\")\n",
    "            \n",
    "            if len(sig_groups) > 0:\n",
    "                print(f\"\\n✓ Trovate differenze significative in {len(sig_groups)} gruppi:\\n\")\n",
    "                for _, row in sig_groups.iterrows():\n",
    "                    print(f\"  • {row['Gruppo']}\")\n",
    "                    print(f\"    STEM: {row['Media_STEM']:.2f} ore/sett (N={row['N_STEM']})\")\n",
    "                    print(f\"    Umanistiche: {row['Media_Umanistiche']:.2f} ore/sett (N={row['N_Umanistiche']})\")\n",
    "                    print(f\"    Differenza: {row['Differenza_medie']:+.2f} ore/sett (p={row['p-value']:.4f})\")\n",
    "                    print()\n",
    "            else:\n",
    "                print(\"\\n✗ Nessuna differenza significativa di area disciplinare nelle ore settimanali\")\n",
    "                print(\"  all'interno dei singoli gruppi.\")\n",
    "            \n",
    "            print(f\"Salvato: {csv_area_hours}\")\n",
    "        else:\n",
    "            print(\"\\n⚠️  Nessun risultato disponibile.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46889be5",
   "metadata": {},
   "source": [
    "## 📊 RIEPILOGO VARIAZIONI DENTRO I 4 GRUPPI\n",
    "\n",
    "### 🎯 Obiettivo\n",
    "Verificare se **all'interno di ciascun gruppo** ci sono differenze significative nelle ore settimanali di uso dell'IA tra:\n",
    "- Maschi vs Femmine\n",
    "- STEM vs Umanistiche\n",
    "\n",
    "---\n",
    "\n",
    "### 👥 DIFFERENZE DI GENERE (Maschi vs Femmine) - Ore Settimanali\n",
    "\n",
    "| Gruppo | N Maschi | Media Maschi | N Femmine | Media Femmine | Differenza | p-value | Significativo? |\n",
    "|--------|----------|--------------|-----------|---------------|------------|---------|----------------|\n",
    "| **Studenti - secondaria** | 16 | 4.88 ore/sett | 80 | 6.72 ore/sett | -1.84 | 0.554 | ✗ |\n",
    "| **Studenti - universitari** | 30 | 2.40 ore/sett | 141 | 2.55 ore/sett | -0.15 | 0.804 | ✗ |\n",
    "| **Insegnanti - non in servizio** | 24 | 2.42 ore/sett | 73 | 1.36 ore/sett | +1.06 | **0.045** | ✓ |\n",
    "| **Insegnanti - in servizio** | 70 | 2.03 ore/sett | 279 | 1.78 ore/sett | +0.24 | 0.639 | ✗ |\n",
    "\n",
    "#### 💡 Interpretazione Genere:\n",
    "- **1 gruppo significativo**: Insegnanti non in servizio → Maschi usano ~1 ora/sett in più (p = 0.045)\n",
    "- **3 gruppi NON significativi**: Nessuna differenza di genere sostanziale nelle ore di uso\n",
    "- **Pattern generale**: Le differenze di genere nelle **ore settimanali** sono minime\n",
    "\n",
    "---\n",
    "\n",
    "### 📚 DIFFERENZE DI AREA DISCIPLINARE (STEM vs Umanistiche) - Ore Settimanali\n",
    "\n",
    "| Gruppo | N STEM | Media STEM | N Umanistiche | Media Umanistiche | Differenza | p-value | Significativo? |\n",
    "|--------|--------|------------|---------------|-------------------|------------|---------|----------------|\n",
    "| **Studenti - secondaria** | - | - | - | - | - | - | Dati insufficienti |\n",
    "| **Studenti - universitari** | 9 | 4.22 ore/sett | 117 | 2.74 ore/sett | +1.48 | 0.165 | ✗ |\n",
    "| **Insegnanti - non in servizio** | 33 | 1.58 ore/sett | 65 | 2.31 ore/sett | -0.73 | 0.490 | ✗ |\n",
    "| **Insegnanti - in servizio** | 151 | 1.68 ore/sett | 198 | 1.92 ore/sett | -0.24 | 0.560 | ✗ |\n",
    "\n",
    "#### 💡 Interpretazione Area:\n",
    "- **Nessun gruppo significativo**: Le differenze tra STEM e Umanistiche non sono statisticamente significative\n",
    "- **Tendenza negli universitari**: STEM usa ~1.5 ore/sett in più, ma p = 0.165 (non significativo, forse per N piccolo STEM=9)\n",
    "- **Pattern generale**: L'area disciplinare NON sembra influenzare le ore di uso IA\n",
    "\n",
    "---\n",
    "\n",
    "### 🔍 CONFRONTO CON ANALISI PRECEDENTI\n",
    "\n",
    "#### Uso Sì/No (Chi-square):\n",
    "- **Genere**: Nessun gruppo significativo nelle proporzioni (p > 0.05)\n",
    "- **Area**: Solo \"insegnanti - non in servizio\" significativo (p = 0.046)\n",
    "\n",
    "#### Ore Settimanali (t-test dentro gruppi):\n",
    "- **Genere**: Solo \"insegnanti - non in servizio\" significativo (p = 0.045) ✓ **CONVERGENZA**\n",
    "- **Area**: Nessun gruppo significativo\n",
    "\n",
    "---\n",
    "\n",
    "### 💡 CONCLUSIONI GENERALI\n",
    "\n",
    "1. **Differenze di GENERE**:\n",
    "   - Nelle **proporzioni** (Sì/No): non significative in nessun gruppo\n",
    "   - Nelle **ore settimanali**: significativa solo per insegnanti non in servizio (maschi usano di più)\n",
    "   - → **Genere ha effetto minimo** sull'uso dell'IA\n",
    "\n",
    "2. **Differenze di AREA**:\n",
    "   - Nelle **proporzioni** (Sì/No): significativa solo per insegnanti non in servizio (p = 0.046)\n",
    "   - Nelle **ore settimanali**: non significativa in nessun gruppo\n",
    "   - → **Area disciplinare ha effetto debole/nullo** sull'uso dell'IA\n",
    "\n",
    "3. **Differenze TRA GRUPPI** (studenti vs insegnanti):\n",
    "   - Nelle **proporzioni** (Sì/No): ALTAMENTE significative (χ² p < 0.001)\n",
    "   - Nelle **ore settimanali**: ALTAMENTE significative (ANOVA p < 0.001)\n",
    "   - → **Il tipo di gruppo (ruolo + livello) è il fattore PRINCIPALE**\n",
    "\n",
    "4. **Pattern chiaro**:\n",
    "   - **Studenti secondaria** → USO ELEVATO (6.4 ore/sett, 79% usa IA)\n",
    "   - **Altri gruppi** → USO MODERATO (1.8-2.5 ore/sett, 50-60% usa IA)\n",
    "   - Genere e area influiscono poco rispetto al ruolo/livello\n",
    "\n",
    "---\n",
    "\n",
    "### 📁 File salvati:\n",
    "- `within_group_gender_hours.csv` - Differenze di genere per gruppo\n",
    "- `within_group_area_hours.csv` - Differenze di area per gruppo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92465832",
   "metadata": {},
   "source": [
    "## 🎓 vs 👨‍🏫 Differenze Studio vs Didattica\n",
    "\n",
    "Confrontiamo l'uso dell'IA tra:\n",
    "- **STUDIO** (studenti secondaria + universitari)\n",
    "- **DIDATTICA** (insegnanti non in servizio + in servizio)\n",
    "\n",
    "Test statistici:\n",
    "1. **Proporzioni** (Sì/No) → Chi-square\n",
    "2. **Ore settimanali** (media) → t-test indipendente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafef93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DIFFERENZE STUDIO VS DIDATTICA: Proporzioni (Sì/No) ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "\n",
    "OUT_EXPL = (Path.cwd()/\"../analysis/exports/latest\").resolve()\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(\"DIFFERENZE STUDIO vs DIDATTICA - PROPORZIONI USO IA (Sì/No)\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Verifica che i dati esistano\n",
    "if 'use' not in globals():\n",
    "    print(\"⚠️  DataFrame 'use' non trovato. Esegui prima la cella sull'uso IA studio/didattica.\")\n",
    "else:\n",
    "    # Crea macro-gruppi\n",
    "    use_macro = use.copy()\n",
    "    use_macro['MacroGruppo'] = use_macro['GruppoDettaglio'].apply(\n",
    "        lambda x: 'STUDIO' if x in ['studenti - secondaria', 'studenti - universitari'] \n",
    "        else 'DIDATTICA'\n",
    "    )\n",
    "    \n",
    "    # Tabella di contingenza\n",
    "    contingency = pd.crosstab(\n",
    "        use_macro['MacroGruppo'],\n",
    "        use_macro['UsoAI_studio_didattica']\n",
    "    )\n",
    "    \n",
    "    print(\"\\n📊 TABELLA DI CONTINGENZA:\\n\")\n",
    "    print(contingency)\n",
    "    print()\n",
    "    \n",
    "    # Calcola percentuali\n",
    "    totals = contingency.sum(axis=1)\n",
    "    percentages = contingency.div(totals, axis=0) * 100\n",
    "    \n",
    "    print(\"\\n📊 PERCENTUALI PER MACRO-GRUPPO:\\n\")\n",
    "    print(percentages.round(1))\n",
    "    print()\n",
    "    \n",
    "    # Statistiche descrittive\n",
    "    print(\"\\n📊 STATISTICHE DESCRITTIVE:\\n\")\n",
    "    print(f\"{'Macro-Gruppo':<15s} {'N totale':>10s} {'N Sì':>10s} {'N No':>10s} {'% Sì':>10s} {'% No':>10s}\")\n",
    "    print(f\"{'─'*70}\")\n",
    "    \n",
    "    for gruppo in ['STUDIO', 'DIDATTICA']:\n",
    "        n_tot = totals[gruppo]\n",
    "        n_si = contingency.loc[gruppo, 'Sì']\n",
    "        n_no = contingency.loc[gruppo, 'No']\n",
    "        perc_si = percentages.loc[gruppo, 'Sì']\n",
    "        perc_no = percentages.loc[gruppo, 'No']\n",
    "        \n",
    "        print(f\"{gruppo:<15s} {n_tot:>10d} {n_si:>10d} {n_no:>10d} {perc_si:>9.1f}% {perc_no:>9.1f}%\")\n",
    "    \n",
    "    # Chi-square test\n",
    "    print(f\"\\n{'─'*90}\")\n",
    "    print(\"TEST CHI-SQUARE:\")\n",
    "    print(f\"{'─'*90}\")\n",
    "    \n",
    "    chi2, p_value, dof, expected = stats.chi2_contingency(contingency.values)\n",
    "    \n",
    "    print(f\"  χ² = {chi2:.4f}\")\n",
    "    print(f\"  gradi di libertà = {dof}\")\n",
    "    print(f\"  p-value = {p_value:.6f}\")\n",
    "    print(f\"  Valori attesi minimi = {expected.min():.2f}\")\n",
    "    \n",
    "    # Verifica assunzioni\n",
    "    if expected.min() >= 5:\n",
    "        print(f\"  ✓ Assunzioni soddisfatte (tutti i valori attesi ≥ 5)\")\n",
    "    else:\n",
    "        print(f\"  ⚠️  Assunzione violata (alcuni valori attesi < 5)\")\n",
    "        print(f\"     Considera Fisher's exact test\")\n",
    "    \n",
    "    # Significatività\n",
    "    print()\n",
    "    if p_value < 0.001:\n",
    "        print(f\"  ✓✓✓ ALTAMENTE significativo (p < 0.001)\")\n",
    "        sig_label = \"Altamente significativo\"\n",
    "    elif p_value < 0.01:\n",
    "        print(f\"  ✓✓ Molto significativo (p < 0.01)\")\n",
    "        sig_label = \"Molto significativo\"\n",
    "    elif p_value < 0.05:\n",
    "        print(f\"  ✓ Significativo (p < 0.05)\")\n",
    "        sig_label = \"Significativo\"\n",
    "    else:\n",
    "        print(f\"  ✗ Non significativo (p ≥ 0.05)\")\n",
    "        sig_label = \"Non significativo\"\n",
    "    \n",
    "    # Effect size (Cramér's V)\n",
    "    n = contingency.sum().sum()\n",
    "    cramers_v = np.sqrt(chi2 / n)\n",
    "    print(f\"\\n  Effect size (Cramér's V) = {cramers_v:.4f}\")\n",
    "    if cramers_v < 0.1:\n",
    "        print(f\"  → Effetto PICCOLO\")\n",
    "    elif cramers_v < 0.3:\n",
    "        print(f\"  → Effetto MEDIO\")\n",
    "    else:\n",
    "        print(f\"  → Effetto GRANDE\")\n",
    "    \n",
    "    # Salva risultati\n",
    "    result_proportions = {\n",
    "        'Confronto': 'STUDIO vs DIDATTICA',\n",
    "        'N_STUDIO': totals['STUDIO'],\n",
    "        'N_DIDATTICA': totals['DIDATTICA'],\n",
    "        'Perc_Si_STUDIO': percentages.loc['STUDIO', 'Sì'],\n",
    "        'Perc_Si_DIDATTICA': percentages.loc['DIDATTICA', 'Sì'],\n",
    "        'Differenza_percentuali': percentages.loc['STUDIO', 'Sì'] - percentages.loc['DIDATTICA', 'Sì'],\n",
    "        'chi2': chi2,\n",
    "        'dof': dof,\n",
    "        'p-value': p_value,\n",
    "        'Cramers_V': cramers_v,\n",
    "        'Significativo_0.05': p_value < 0.05,\n",
    "        'Significativo_0.01': p_value < 0.01,\n",
    "        'Significativo_0.001': p_value < 0.001,\n",
    "        'Significatività': sig_label\n",
    "    }\n",
    "    \n",
    "    df_result_prop = pd.DataFrame([result_proportions])\n",
    "    csv_prop = OUT_EXPL / 'studio_vs_didattica_proportions.csv'\n",
    "    df_result_prop.to_csv(csv_prop, index=False)\n",
    "    \n",
    "    # Riepilogo finale\n",
    "    print(f\"\\n{'='*90}\")\n",
    "    print(\"CONCLUSIONE:\")\n",
    "    print(f\"{'='*90}\")\n",
    "    \n",
    "    diff_perc = percentages.loc['STUDIO', 'Sì'] - percentages.loc['DIDATTICA', 'Sì']\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(f\"\\n✓ Le proporzioni di uso dell'IA sono SIGNIFICATIVAMENTE diverse tra\")\n",
    "        print(f\"  STUDIO ({percentages.loc['STUDIO', 'Sì']:.1f}%) e DIDATTICA ({percentages.loc['DIDATTICA', 'Sì']:.1f}%)\")\n",
    "        print(f\"  Differenza: {diff_perc:+.1f} punti percentuali\")\n",
    "        if diff_perc > 0:\n",
    "            print(f\"  → Gli studenti usano l'IA PIÙ degli insegnanti\")\n",
    "        else:\n",
    "            print(f\"  → Gli insegnanti usano l'IA PIÙ degli studenti\")\n",
    "    else:\n",
    "        print(f\"\\n✗ Non ci sono differenze significative nelle proporzioni di uso dell'IA\")\n",
    "        print(f\"  tra STUDIO ({percentages.loc['STUDIO', 'Sì']:.1f}%) e DIDATTICA ({percentages.loc['DIDATTICA', 'Sì']:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n{'='*90}\")\n",
    "    print(f\"Salvato: {csv_prop}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bed1e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DIFFERENZE STUDIO VS DIDATTICA: Ore Settimanali (t-test) ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "\n",
    "OUT_EXPL = (Path.cwd()/\"../analysis/exports/latest\").resolve()\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(\"DIFFERENZE STUDIO vs DIDATTICA - ORE SETTIMANALI\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Verifica che i dati esistano\n",
    "if 'df_use' not in globals():\n",
    "    print(\"⚠️  DataFrame 'df_use' non trovato. Esegui prima la cella sull'analisi ore settimanali.\")\n",
    "else:\n",
    "    # Crea macro-gruppi\n",
    "    df_use_macro = df_use.copy()\n",
    "    df_use_macro['MacroGruppo'] = df_use_macro['GruppoDettaglio'].apply(\n",
    "        lambda x: 'STUDIO' if x in ['studenti - secondaria', 'studenti - universitari'] \n",
    "        else 'DIDATTICA'\n",
    "    )\n",
    "    \n",
    "    # Separa i dati\n",
    "    studio_data = df_use_macro[df_use_macro['MacroGruppo']=='STUDIO']['OreSettimanali'].dropna()\n",
    "    didattica_data = df_use_macro[df_use_macro['MacroGruppo']=='DIDATTICA']['OreSettimanali'].dropna()\n",
    "    \n",
    "    # Statistiche descrittive\n",
    "    print(\"\\n📊 STATISTICHE DESCRITTIVE:\\n\")\n",
    "    print(f\"{'Macro-Gruppo':<15s} {'N':>8s} {'Media':>10s} {'Mediana':>10s} {'SD':>10s} {'Min':>8s} {'Max':>8s}\")\n",
    "    print(f\"{'─'*80}\")\n",
    "    \n",
    "    for gruppo, data in [('STUDIO', studio_data), ('DIDATTICA', didattica_data)]:\n",
    "        print(f\"{gruppo:<15s} {len(data):>8d} {data.mean():>10.2f} {data.median():>10.2f} \"\n",
    "              f\"{data.std():>10.2f} {data.min():>8.1f} {data.max():>8.1f}\")\n",
    "    \n",
    "    # T-test indipendente\n",
    "    print(f\"\\n{'─'*90}\")\n",
    "    print(\"T-TEST INDIPENDENTE:\")\n",
    "    print(f\"{'─'*90}\")\n",
    "    \n",
    "    t_stat, p_value = stats.ttest_ind(studio_data, didattica_data)\n",
    "    diff_mean = studio_data.mean() - didattica_data.mean()\n",
    "    \n",
    "    print(f\"  t-statistic = {t_stat:.4f}\")\n",
    "    print(f\"  p-value = {p_value:.6f}\")\n",
    "    print(f\"  Differenza medie = {diff_mean:+.2f} ore/settimana\")\n",
    "    \n",
    "    # Significatività\n",
    "    print()\n",
    "    if p_value < 0.001:\n",
    "        print(f\"  ✓✓✓ ALTAMENTE significativo (p < 0.001)\")\n",
    "        sig_label = \"Altamente significativo\"\n",
    "    elif p_value < 0.01:\n",
    "        print(f\"  ✓✓ Molto significativo (p < 0.01)\")\n",
    "        sig_label = \"Molto significativo\"\n",
    "    elif p_value < 0.05:\n",
    "        print(f\"  ✓ Significativo (p < 0.05)\")\n",
    "        sig_label = \"Significativo\"\n",
    "    else:\n",
    "        print(f\"  ✗ Non significativo (p ≥ 0.05)\")\n",
    "        sig_label = \"Non significativo\"\n",
    "    \n",
    "    # Effect size (Cohen's d)\n",
    "    pooled_std = np.sqrt(((len(studio_data)-1)*studio_data.std()**2 + \n",
    "                          (len(didattica_data)-1)*didattica_data.std()**2) / \n",
    "                         (len(studio_data) + len(didattica_data) - 2))\n",
    "    cohens_d = diff_mean / pooled_std\n",
    "    \n",
    "    print(f\"\\n  Effect size (Cohen's d) = {cohens_d:.4f}\")\n",
    "    if abs(cohens_d) < 0.2:\n",
    "        print(f\"  → Effetto PICCOLO\")\n",
    "    elif abs(cohens_d) < 0.5:\n",
    "        print(f\"  → Effetto MEDIO\")\n",
    "    elif abs(cohens_d) < 0.8:\n",
    "        print(f\"  → Effetto MEDIO-GRANDE\")\n",
    "    else:\n",
    "        print(f\"  → Effetto GRANDE\")\n",
    "    \n",
    "    # Test di Levene (omogeneità varianze)\n",
    "    print(f\"\\n{'─'*90}\")\n",
    "    print(\"VERIFICA ASSUNZIONI:\")\n",
    "    print(f\"{'─'*90}\")\n",
    "    \n",
    "    levene_stat, levene_p = stats.levene(studio_data, didattica_data)\n",
    "    print(f\"  Test di Levene (omogeneità varianze):\")\n",
    "    print(f\"    Statistica = {levene_stat:.4f}, p-value = {levene_p:.4f}\")\n",
    "    if levene_p >= 0.05:\n",
    "        print(f\"    ✓ Varianze omogenee (assunzione soddisfatta)\")\n",
    "    else:\n",
    "        print(f\"    ⚠️  Varianze NON omogenee (considera Welch's t-test)\")\n",
    "        # Welch's t-test (più robusto)\n",
    "        t_welch, p_welch = stats.ttest_ind(studio_data, didattica_data, equal_var=False)\n",
    "        print(f\"\\n  Welch's t-test (varianze non uguali):\")\n",
    "        print(f\"    t = {t_welch:.4f}, p-value = {p_welch:.6f}\")\n",
    "    \n",
    "    # Test di normalità\n",
    "    print(f\"\\n  Test di normalità (Shapiro-Wilk):\")\n",
    "    for gruppo, data in [('STUDIO', studio_data), ('DIDATTICA', didattica_data)]:\n",
    "        if len(data) >= 3:\n",
    "            shapiro_stat, shapiro_p = stats.shapiro(data)\n",
    "            status = \"✓\" if shapiro_p >= 0.05 else \"⚠️\"\n",
    "            print(f\"    {status} {gruppo:<15s}: p = {shapiro_p:.4f}\")\n",
    "    \n",
    "    # Salva risultati\n",
    "    result_hours = {\n",
    "        'Confronto': 'STUDIO vs DIDATTICA',\n",
    "        'N_STUDIO': len(studio_data),\n",
    "        'Media_STUDIO': studio_data.mean(),\n",
    "        'SD_STUDIO': studio_data.std(),\n",
    "        'N_DIDATTICA': len(didattica_data),\n",
    "        'Media_DIDATTICA': didattica_data.mean(),\n",
    "        'SD_DIDATTICA': didattica_data.std(),\n",
    "        'Differenza_medie': diff_mean,\n",
    "        't-statistic': t_stat,\n",
    "        'p-value': p_value,\n",
    "        'Cohens_d': cohens_d,\n",
    "        'Levene_statistic': levene_stat,\n",
    "        'Levene_p-value': levene_p,\n",
    "        'Varianze_omogenee': levene_p >= 0.05,\n",
    "        'Significativo_0.05': p_value < 0.05,\n",
    "        'Significativo_0.01': p_value < 0.01,\n",
    "        'Significativo_0.001': p_value < 0.001,\n",
    "        'Significatività': sig_label\n",
    "    }\n",
    "    \n",
    "    df_result_hours = pd.DataFrame([result_hours])\n",
    "    csv_hours = OUT_EXPL / 'studio_vs_didattica_hours.csv'\n",
    "    df_result_hours.to_csv(csv_hours, index=False)\n",
    "    \n",
    "    # Riepilogo finale\n",
    "    print(f\"\\n{'='*90}\")\n",
    "    print(\"CONCLUSIONE:\")\n",
    "    print(f\"{'='*90}\")\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(f\"\\n✓ Le ore settimanali di uso dell'IA sono SIGNIFICATIVAMENTE diverse tra\")\n",
    "        print(f\"  STUDIO ({studio_data.mean():.2f} ore/sett) e DIDATTICA ({didattica_data.mean():.2f} ore/sett)\")\n",
    "        print(f\"  Differenza: {diff_mean:+.2f} ore/settimana\")\n",
    "        if diff_mean > 0:\n",
    "            print(f\"  → Gli studenti usano l'IA PIÙ INTENSAMENTE degli insegnanti\")\n",
    "        else:\n",
    "            print(f\"  → Gli insegnanti usano l'IA PIÙ INTENSAMENTE degli studenti\")\n",
    "    else:\n",
    "        print(f\"\\n✗ Non ci sono differenze significative nelle ore settimanali di uso dell'IA\")\n",
    "        print(f\"  tra STUDIO ({studio_data.mean():.2f} ore/sett) e DIDATTICA ({didattica_data.mean():.2f} ore/sett)\")\n",
    "    \n",
    "    print(f\"\\n{'='*90}\")\n",
    "    print(f\"Salvato: {csv_hours}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1357bfd",
   "metadata": {},
   "source": [
    "## 📊 RIEPILOGO STUDIO vs DIDATTICA\n",
    "\n",
    "### 🎯 Confronto Macro-Gruppi\n",
    "\n",
    "| Macro-Gruppo | N campione | Composizione |\n",
    "|--------------|------------|--------------|\n",
    "| **STUDIO** | 270 | Studenti secondaria + universitari |\n",
    "| **DIDATTICA** | 457 | Insegnanti non in servizio + in servizio |\n",
    "| **TOTALE** | 727 | |\n",
    "\n",
    "---\n",
    "\n",
    "### 1️⃣ PROPORZIONI USO IA (Sì/No)\n",
    "\n",
    "| Macro-Gruppo | % usa IA | N usa | N non usa |\n",
    "|--------------|----------|-------|-----------|\n",
    "| **STUDIO** | **75.2%** | 203 | 67 |\n",
    "| **DIDATTICA** | **41.4%** | 189 | 268 |\n",
    "| **Differenza** | **+33.8 punti %** | | |\n",
    "\n",
    "#### Test Chi-square:\n",
    "- χ² = 76.82, df = 1\n",
    "- **p-value = 1.88 × 10⁻¹⁸** → ✓✓✓ **ALTAMENTE significativo**\n",
    "- Cramér's V = 0.325 → Effetto MEDIO-GRANDE\n",
    "\n",
    "#### 💡 Interpretazione:\n",
    "**Gli studenti usano l'IA MOLTO PIÙ degli insegnanti** (75% vs 41%)\n",
    "- Differenza di **+34 punti percentuali**\n",
    "- Significatività statistica ESTREMA (p < 0.001)\n",
    "- Effetto sostanzioso (Cramér's V > 0.3)\n",
    "\n",
    "---\n",
    "\n",
    "### 2️⃣ ORE SETTIMANALI DI USO\n",
    "\n",
    "| Macro-Gruppo | Media ore/sett | SD | Mediana |\n",
    "|--------------|----------------|-------|---------|\n",
    "| **STUDIO** | **3.91 ore** | 7.36 | |\n",
    "| **DIDATTICA** | **1.88 ore** | 4.12 | |\n",
    "| **Differenza** | **+2.03 ore** | | |\n",
    "\n",
    "#### Test t indipendente:\n",
    "- t = 4.74\n",
    "- **p-value = 2.61 × 10⁻⁶** → ✓✓✓ **ALTAMENTE significativo**\n",
    "- Cohen's d = 0.365 → Effetto MEDIO\n",
    "\n",
    "#### Verifica assunzioni:\n",
    "- ⚠️ Varianze NON omogenee (Levene p = 0.0004)\n",
    "- Studio: SD = 7.36 (varianza alta)\n",
    "- Didattica: SD = 4.12 (varianza più bassa)\n",
    "- → Risultato robusto comunque (p-value molto basso)\n",
    "\n",
    "#### 💡 Interpretazione:\n",
    "**Gli studenti usano l'IA con MAGGIORE INTENSITÀ** (3.9 vs 1.9 ore/sett)\n",
    "- Differenza di **+2 ore/settimana** (~doppio del tempo)\n",
    "- Significatività statistica ESTREMA (p < 0.001)\n",
    "- Effetto medio ma sostanzioso\n",
    "\n",
    "---\n",
    "\n",
    "### 🔍 SINTESI COMPARATIVA\n",
    "\n",
    "| Test | Risultato | Significatività | Effect Size |\n",
    "|------|-----------|-----------------|-------------|\n",
    "| **Proporzioni** (Chi²) | STUDIO: 75% vs DIDATTICA: 41% | p < 0.001 ✓✓✓ | V = 0.325 (Medio-Grande) |\n",
    "| **Ore settimanali** (t-test) | STUDIO: 3.9h vs DIDATTICA: 1.9h | p < 0.001 ✓✓✓ | d = 0.365 (Medio) |\n",
    "\n",
    "---\n",
    "\n",
    "### 💡 CONCLUSIONI PRINCIPALI\n",
    "\n",
    "1. **DIFFERENZE ALTAMENTE SIGNIFICATIVE** su entrambi i piani:\n",
    "   - **Proporzioni**: +34 punti percentuali (75% vs 41%)\n",
    "   - **Intensità**: +2 ore/settimana (3.9h vs 1.9h)\n",
    "\n",
    "2. **PATTERN CHIARO**: \n",
    "   - 🎓 **STUDIO** → Uso MASSICCIO (3 studenti su 4 usano IA, ~4 ore/sett)\n",
    "   - 👨‍🏫 **DIDATTICA** → Uso MODERATO (2 insegnanti su 5 usano IA, ~2 ore/sett)\n",
    "\n",
    "3. **CONSISTENZA**:\n",
    "   - Entrambi i test (proporzioni + ore) convergono nella stessa direzione\n",
    "   - Effetti robusti e sostanziosi (non solo statistici ma anche pratici)\n",
    "   - Significatività ESTREMA (p < 0.000001) → risultati molto affidabili\n",
    "\n",
    "4. **IMPLICAZIONI**:\n",
    "   - L'IA è integrata maggiormente nel contesto **STUDIO** che **DIDATTICA**\n",
    "   - Gli studenti sono più \"early adopters\" rispetto agli insegnanti\n",
    "   - Potenziale gap tra competenze/uso studenti vs competenze insegnanti\n",
    "\n",
    "---\n",
    "\n",
    "### 📁 File salvati:\n",
    "- `studio_vs_didattica_proportions.csv` - Test proporzioni\n",
    "- `studio_vs_didattica_hours.csv` - Test ore settimanali"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3af67d",
   "metadata": {},
   "source": [
    "# 2. Perceived competence\n",
    "\n",
    "Autovalutazioni di competenza pratica e teorica rispetto agli strumenti di IA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6208f36",
   "metadata": {},
   "source": [
    "## 2.1 Competenze percepite (pratica vs teorica)\n",
    "\n",
    "Grafici bilingual (violin+box) sulle due dimensioni di competenza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12839b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Competenze pratica e teorica\n",
    "competence_items = [item for item in domande_comparabili if item['section'] == 'perceived_competence']\n",
    "for item in competence_items:\n",
    "    print('\n",
    "' + '='*90)\n",
    "    print(item['label_it'].upper())\n",
    "    render_likert_item(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f85db1",
   "metadata": {},
   "source": [
    "# 3. Training adequacy\n",
    "\n",
    "Percezione dell'adeguatezza della formazione e supporto istituzionale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb346b6e",
   "metadata": {},
   "source": [
    "## 3.1 Adeguatezza percepita della formazione\n",
    "\n",
    "Grafici bilingui per la domanda Likert condivisa tra studenti e insegnanti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a39d5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_items = [item for item in domande_comparabili if item['section'] == 'training_adequacy']\n",
    "for item in training_items:\n",
    "    print('\n",
    "' + '='*90)\n",
    "    print(item['label_it'].upper())\n",
    "    render_likert_item(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad928fd8",
   "metadata": {},
   "source": [
    "# 4. Trust and confidence\n",
    "\n",
    "Fiducia nell'affidabilità dell'IA e nella capacità degli attori umani di usarla responsabilmente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0189ff",
   "metadata": {},
   "source": [
    "## 4.1 Fiducia nell'integrazione dell'IA\n",
    "\n",
    "Domanda Likert condivisa su quanto studenti/insegnanti si sentano fiduciosi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0c5c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "trust_items = [item for item in domande_comparabili if item['section'] == 'trust_confidence']\n",
    "for item in trust_items:\n",
    "    print('\n",
    "' + '='*90)\n",
    "    print(item['label_it'].upper())\n",
    "    render_likert_item(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136ae1ad",
   "metadata": {},
   "source": [
    "# 5. Concerns\n",
    "\n",
    "Rischi percepiti, barriere e livelli di preoccupazione rispetto all'inserimento dell'IA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e19dde2",
   "metadata": {},
   "source": [
    "## 5.1 Preoccupazione generale sull'IA\n",
    "\n",
    "Domanda Likert condivisa sul livello di preoccupazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52102ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "concern_items = [item for item in domande_comparabili if item['section'] == 'concerns']\n",
    "for item in concern_items:\n",
    "    print('\n",
    "' + '='*90)\n",
    "    print(item['label_it'].upper())\n",
    "    render_likert_item(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1762a600",
   "metadata": {},
   "source": [
    "# 6. Perceived change\n",
    "\n",
    "Attese sul cambiamento didattico e sull'impatto a medio termine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd91536",
   "metadata": {},
   "source": [
    "# === MAPPATURA DOMANDE SIMILI TRA STUDENTI E INSEGNANTI ===\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(\"MAPPATURA DOMANDE SIMILI: STUDENTI vs INSEGNANTI\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Ogni voce contiene anche la sezione analitica e lo slug per salvare i grafici\n",
    "domande_comparabili = [\n",
    "    {\n",
    "        'tema': 'Competenza pratica uso IA',\n",
    "        'insegnanti': 'Su una scala da 1 a 7, quanto ti consideri competente nell\\'uso pratico di strumenti o tecnologie legati all\\'intelligenza artificiale?\\n(Nota: con \"uso pratico\" intendiamo la capacità di utilizzare concretamente strumenti, applicazioni o piattaforme di intelligenza artificiale.)\\n\\n(1 Per niente - 2 Poco - 3 Moderatamente - 4 Neutrale -  5 Piuttosto - 6 Molto - 7 Estremamente)',\n",
    "        'studenti': 'Su una scala da 1 a 7, quanto ti consideri competente nell\\'uso pratico di strumenti o tecnologie legati all\\'intelligenza artificiale?\\n(Nota: con \"uso pratico\" intendiamo la capacità di utilizzare concretamente strumenti, applicazioni o piattaforme di intelligenza artificiale.)',\n",
    "        'label_it': 'Competenza pratica',\n",
    "        'label_en': 'Practical competence',\n",
    "        'slug': 'likert_competenza_pratica',\n",
    "        'section': 'perceived_competence',\n",
    "    },\n",
    "    {\n",
    "        'tema': 'Competenza teorica IA',\n",
    "        'insegnanti': 'Su una scala da 1 a 7, quanto ritieni adeguata la tua competenza teorica riguardo l\\'intelligenza artificiale?\\n(Nota: con \"competenza teorica\" si intende la conoscenza dei principi, concetti e modelli fondamentali dell\\'intelligenza artificiale.)',\n",
    "        'studenti': 'Su una scala da 1 a 7, quanto ritieni adeguata la tua competenza teorica riguardo l\\'intelligenza artificiale?\\n(Nota: con \"competenza teorica\" si intende la conoscenza dei principi, concetti e modelli fondamentali dell\\'intelligenza artificiale.)',\n",
    "        'label_it': 'Competenza teorica',\n",
    "        'label_en': 'Theoretical competence',\n",
    "        'slug': 'likert_competenza_teorica',\n",
    "        'section': 'perceived_competence',\n",
    "    },\n",
    "    {\n",
    "        'tema': 'Cambiamento percepito IA',\n",
    "        'insegnanti': 'Da una scala da 1 a 7, quanto pensi che l\\'intelligenza artificiale cambierà la tua didattica?\\n\\n(1 Per niente - 2 Poco - 3 Moderatamente - 4 Neutrale -  5 Piuttosto - 6 Molto - 7 Estremamente)',\n",
    "        'studenti': 'Da una scala da 1 a 7, quanto pensi che l\\'intelligenza artificiale cambierà il tuo modo di studiare?\\n\\n(1 Per niente - 2 Poco - 3 Moderatamente - 4 Neutrale -  5 Piuttosto - 6 Molto - 7 Estremamente)',\n",
    "        'label_it': 'Cambierà didattica/studio',\n",
    "        'label_en': 'Will change teaching/study',\n",
    "        'slug': 'likert_cambiamento',\n",
    "        'section': 'perceived_change',\n",
    "    },\n",
    "    {\n",
    "        'tema': 'Adeguatezza formazione IA',\n",
    "        'insegnanti': 'Su una scala da 1 a 7, quanto ritieni adeguata la formazione ricevuta in merito all\\'intelligenza artificiale?\\n(Nota: considera i corsi di formazione frequentati, le opportunità formative offerte dalla scuola e gli strumenti di apprendimento messi a disposizione.)',\n",
    "        'studenti': 'Su una scala da 1 a 7, quanto ritieni adeguata la formazione ricevuta in merito all\\'intelligenza artificiale?\\n(Nota: considera le opportunità formative offerte dalla scuola e gli strumenti di apprendimento messi a disposizione.)',\n",
    "        'label_it': 'Adeguatezza formazione',\n",
    "        'label_en': 'Adequacy of training',\n",
    "        'slug': 'likert_formazione',\n",
    "        'section': 'training_adequacy',\n",
    "    },\n",
    "    {\n",
    "        'tema': 'Fiducia integrazione IA',\n",
    "        'insegnanti': 'Da una scala da 1 a 7, quanto sei fiducioso nell\\'integrazione dell\\'intelligenza artificiale nella pratica educativa?\\n(1 Per niente fiducioso - 2 Poco fiducioso - 3 Moderatamente fiducioso - 4 Neutrale - 5 Piuttosto fiducioso - 6 Molto fiducioso - 7 Estremamente fiducioso)',\n",
    "        'studenti': 'Da una scala da 1 a 7, quanto sei fiducioso nell\\'integrazione dell\\'intelligenza artificiale nella scuola o università?\\n(1 Per niente fiducioso - 2 Poco fiducioso - 3 Moderatamente fiducioso - 4 Neutrale - 5 Piuttosto fiducioso - 6 Molto fiducioso - 7 Estremamente fiducioso)',\n",
    "        'label_it': 'Fiducia integrazione',\n",
    "        'label_en': 'Trust in integration',\n",
    "        'slug': 'likert_fiducia',\n",
    "        'section': 'trust_confidence',\n",
    "    },\n",
    "    {\n",
    "        'tema': 'Preoccupazione inserimento IA',\n",
    "        'insegnanti': 'Da una scala da 1 a 7, quanto sei preoccupato riguardo all\\'utilizzo dell\\'intelligenza artificiale nel mondo dell\\'educazione?\\n\\n(1 Per niente preoccupato - 2 Poco preoccupato - 3 Moderatamente preoccupato - 4 Neutrale - 5 Piuttosto preoccupato - 6 Molto preoccupato - 7 Estremamente preoccupato)',\n",
    "        'studenti': 'Da una scala da 1 a 7, ti preoccupa l\\'inserimento dell\\'intelligenza artificiale nella scuola o nell\\'università?\\n\\n(1 Per niente preoccupato - 2 Poco preoccupato - 3 Moderatamente preoccupato - 4 Neutrale - 5 Piuttosto preoccupato - 6 Molto preoccupato - 7 Estremamente preoccupato)',\n",
    "        'label_it': 'Preoccupazione generale',\n",
    "        'label_en': 'General concern',\n",
    "        'slug': 'likert_preoccupazione',\n",
    "        'section': 'concerns',\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"\\nVerifica disponibilità domande nel dataset:\n",
    "\")\n",
    "print(f\"{'Tema':<40s} {'Ins':>5s} {'Stu':>5s}\")\n",
    "print('─'*52)\n",
    "for item in domande_comparabili:\n",
    "    ins_exists = item['insegnanti'] in DF_plot.columns\n",
    "    stu_exists = item['studenti'] in DF_plot.columns\n",
    "    ins_mark = '✓' if ins_exists else '✗'\n",
    "    stu_mark = '✓' if stu_exists else '✗'\n",
    "    print(f\"{item['tema']:<40s} {ins_mark:>5s} {stu_mark:>5s}\")\n",
    "print('─'*52)\n",
    "print(f\"\\nTotale coppie di domande comparabili: {len(domande_comparabili)}\")\n",
    "\n",
    "OUT_EXPL = (Path.cwd()/\"../analysis/exports/latest\").resolve()\n",
    "mapping_df = pd.DataFrame(domande_comparabili)\n",
    "csv_mapping = OUT_EXPL / 'domande_likert_mapping.csv'\n",
    "mapping_df.to_csv(csv_mapping, index=False)\n",
    "print(f\"Salvato mapping in: {csv_mapping}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b371f6",
   "metadata": {},
   "source": [
    "# 6. Perceived change\n",
    "\n",
    "Aspettative sul cambiamento didattico e sullo studio dovuto all'IA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910502a",
   "metadata": {},
   "source": [
    "## 6.1 Cambiamento percepito (didattica/studio)\n",
    "\n",
    "Grafici bilingui sulla domanda dedicata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd6bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_items = [item for item in domande_comparabili if item['section'] == 'perceived_change']\n",
    "for item in change_items:\n",
    "    print('\n",
    "' + '='*90)\n",
    "    print(item['label_it'].upper())\n",
    "    render_likert_item(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89077f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper per generare grafici bilingui sulle domande Likert comparabili\n",
    "def render_likert_item(item, slug_suffix=None, note_it=None, note_en=None):\n",
    "    col_ins = item['insegnanti']\n",
    "    col_stu = item['studenti']\n",
    "    slug = slug_suffix or item.get('slug')\n",
    "    df_vis = DF_plot[['GruppoDettaglio']].copy()\n",
    "    mask_teachers = df_vis['GruppoDettaglio'].str.contains('insegnanti', case=False, na=False)\n",
    "    mask_students = df_vis['GruppoDettaglio'].str.contains('studenti', case=False, na=False)\n",
    "    df_vis.loc[mask_teachers, 'Valore'] = pd.to_numeric(DF_plot.loc[mask_teachers, col_ins], errors='coerce')\n",
    "    df_vis.loc[mask_students, 'Valore'] = pd.to_numeric(DF_plot.loc[mask_students, col_stu], errors='coerce')\n",
    "    df_vis = df_vis.dropna(subset=['Valore'])\n",
    "    df_vis = df_vis[df_vis['GruppoDettaglio'].isin(ORDER_4)]\n",
    "    if df_vis.empty:\n",
    "        print(f\"⚠️ Nessun dato disponibile per {item['tema']}\")\n",
    "        return df_vis\n",
    "    df_vis['GruppoDettaglio'] = pd.Categorical(df_vis['GruppoDettaglio'], categories=ORDER_4, ordered=True)\n",
    "    if note_it:\n",
    "        print(note_it)\n",
    "    bilingual_violin_box(\n",
    "        df_vis[['GruppoDettaglio', 'Valore']],\n",
    "        value_col='Valore',\n",
    "        slug=slug,\n",
    "        title_it=item['label_it'],\n",
    "        title_en=item['label_en'],\n",
    "        ylabel_it='Punteggio (scala 1-7)',\n",
    "        ylabel_en='Score (Likert 1-7)',\n",
    "        save_csv=True,\n",
    "    )\n",
    "    return df_vis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae9d398",
   "metadata": {},
   "source": [
    "## 📊 Analisi Domande Likert (scala 1-7)\n",
    "\n",
    "### Piano di Lavoro:\n",
    "1. Identificare tutte le domande con scala Likert 1-7\n",
    "2. Raggruppare domande simili tra studenti e insegnanti\n",
    "3. Creare grafici a violino per i 4 gruppi\n",
    "4. Analizzare la variabilità interna\n",
    "5. Confrontare risposte tra studenti e insegnanti su temi comuni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f38b7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IDENTIFICAZIONE DOMANDE LIKERT 1-7 ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(\"IDENTIFICAZIONE DOMANDE LIKERT (scala 1-7)\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Cerca colonne che contengono pattern tipici di domande Likert\n",
    "likert_patterns = [\n",
    "    r'scala.*1.*7',\n",
    "    r'quanto.*pensi',\n",
    "    r'quanto.*sei.*fiducioso',\n",
    "    r'quanto.*sei.*preoccupato',\n",
    "    r'quanto.*ritieni',\n",
    "    r'quanto.*ti.*consideri',\n",
    "]\n",
    "\n",
    "likert_questions = {}\n",
    "\n",
    "for col in DF_plot.columns:\n",
    "    col_lower = str(col).lower()\n",
    "    \n",
    "    # Cerca pattern Likert nel nome della colonna\n",
    "    is_likert = any(re.search(pattern, col_lower, re.I) for pattern in likert_patterns)\n",
    "    \n",
    "    if is_likert:\n",
    "        # Verifica che i valori siano numerici 1-7\n",
    "        values = DF_plot[col].dropna()\n",
    "        if len(values) > 0:\n",
    "            try:\n",
    "                numeric_values = pd.to_numeric(values, errors='coerce').dropna()\n",
    "                if len(numeric_values) > 0:\n",
    "                    unique_vals = sorted(numeric_values.unique())\n",
    "                    # Verifica se i valori sono nell'intervallo 1-7\n",
    "                    if all(1 <= v <= 7 for v in unique_vals):\n",
    "                        likert_questions[col] = {\n",
    "                            'valori_unici': unique_vals,\n",
    "                            'n_validi': len(numeric_values),\n",
    "                            'media': numeric_values.mean(),\n",
    "                            'mediana': numeric_values.median()\n",
    "                        }\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "print(f\"\\n✓ Trovate {len(likert_questions)} domande Likert (scala 1-7)\\n\")\n",
    "print(f\"{'─'*90}\")\n",
    "print(f\"{'N':<4s} {'Domanda':<70s} {'N validi':>12s}\")\n",
    "print(f\"{'─'*90}\")\n",
    "\n",
    "for i, (q, info) in enumerate(likert_questions.items(), 1):\n",
    "    # Trunca domanda se troppo lunga\n",
    "    q_short = q[:67] + '...' if len(q) > 70 else q\n",
    "    print(f\"{i:<4d} {q_short:<70s} {info['n_validi']:>12d}\")\n",
    "\n",
    "print(f\"{'─'*90}\")\n",
    "\n",
    "# Salva lista completa\n",
    "OUT_EXPL = (Path.cwd()/\"../analysis/exports/latest\").resolve()\n",
    "likert_df = pd.DataFrame([\n",
    "    {'n': i, 'domanda': q, 'n_validi': info['n_validi'], \n",
    "     'media': info['media'], 'mediana': info['mediana']}\n",
    "    for i, (q, info) in enumerate(likert_questions.items(), 1)\n",
    "])\n",
    "csv_likert = OUT_EXPL / 'domande_likert_1-7.csv'\n",
    "likert_df.to_csv(csv_likert, index=False)\n",
    "print(f\"\\nSalvato elenco in: {csv_likert}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1bd79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MAPPATURA DOMANDE SIMILI TRA STUDENTI E INSEGNANTI ===\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(\"MAPPATURA DOMANDE SIMILI: STUDENTI vs INSEGNANTI\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Definizione delle coppie di domande comparabili\n",
    "# Formato: (nome_breve, domanda_insegnanti, domanda_studenti, tema)\n",
    "\n",
    "domande_comparabili = [\n",
    "    # 1. COMPETENZA PRATICA\n",
    "    {\n",
    "        'tema': 'Competenza pratica uso IA',\n",
    "        'insegnanti': 'Su una scala da 1 a 7, quanto ti consideri competente nell\\'uso pratico di strumenti o tecnologie legati all\\'intelligenza artificiale?\\n(Nota: con \"uso pratico\" intendiamo la capacità di utilizzare concretamente strumenti, applicazioni o piattaforme di intelligenza artificiale.)\\n\\n(1 Per niente - 2 Poco - 3 Moderatamente - 4 Neutrale -  5 Piuttosto - 6 Molto - 7 Estremamente)',\n",
    "        'studenti': 'Su una scala da 1 a 7, quanto ti consideri competente nell\\'uso pratico di strumenti o tecnologie legati all\\'intelligenza artificiale?\\n(Nota: con \"uso pratico\" intendiamo la capacità di utilizzare concretamente strumenti, applicazioni o piattaforme di intelligenza artificiale.)',\n",
    "        'label_it': 'Competenza pratica',\n",
    "        'label_en': 'Practical competence'\n",
    "    },\n",
    "    \n",
    "    # 2. COMPETENZA TEORICA\n",
    "    {\n",
    "        'tema': 'Competenza teorica IA',\n",
    "        'insegnanti': 'Su una scala da 1 a 7, quanto ritieni adeguata la tua competenza teorica riguardo l\\'intelligenza artificiale?\\n(Nota: con \"competenza teorica\" si intende la conoscenza dei principi, concetti e modelli fondamentali dell\\'intelligenza artificiale.)',\n",
    "        'studenti': 'Su una scala da 1 a 7, quanto ritieni adeguata la tua competenza teorica riguardo l\\'intelligenza artificiale?\\n(Nota: con \"competenza teorica\" si intende la conoscenza dei principi, concetti e modelli fondamentali dell\\'intelligenza artificiale.)',\n",
    "        'label_it': 'Competenza teorica',\n",
    "        'label_en': 'Theoretical competence'\n",
    "    },\n",
    "    \n",
    "    # 3. CAMBIAMENTO DIDATTICA/STUDIO\n",
    "    {\n",
    "        'tema': 'Cambiamento percepito IA',\n",
    "        'insegnanti': 'Da una scala da 1 a 7, quanto pensi che l\\'intelligenza artificiale cambierà la tua didattica?\\n\\n(1 Per niente - 2 Poco - 3 Moderatamente - 4 Neutrale -  5 Piuttosto - 6 Molto - 7 Estremamente)',\n",
    "        'studenti': 'Da una scala da 1 a 7, quanto pensi che l\\'intelligenza artificiale cambierà il tuo modo di studiare?\\n\\n(1 Per niente - 2 Poco - 3 Moderatamente - 4 Neutrale -  5 Piuttosto - 6 Molto - 7 Estremamente)',\n",
    "        'label_it': 'Cambierà didattica/studio',\n",
    "        'label_en': 'Will change teaching/study'\n",
    "    },\n",
    "    \n",
    "    # 4. FORMAZIONE RICEVUTA\n",
    "    {\n",
    "        'tema': 'Adeguatezza formazione IA',\n",
    "        'insegnanti': 'Su una scala da 1 a 7, quanto ritieni adeguata la formazione ricevuta in merito all\\'intelligenza artificiale?\\n(Nota: considera i corsi di formazione frequentati, le opportunità formative offerte dalla scuola e gli strumenti di apprendimento messi a disposizione.)',\n",
    "        'studenti': 'Su una scala da 1 a 7, quanto ritieni adeguata la formazione ricevuta in merito all\\'intelligenza artificiale?\\n(Nota: considera le opportunità formative offerte dalla scuola e gli strumenti di apprendimento messi a disposizione.)',\n",
    "        'label_it': 'Adeguatezza formazione',\n",
    "        'label_en': 'Adequacy of training'\n",
    "    },\n",
    "    \n",
    "    # 5. FIDUCIA INTEGRAZIONE\n",
    "    {\n",
    "        'tema': 'Fiducia integrazione IA',\n",
    "        'insegnanti': 'Da una scala da 1 a 7, quanto sei fiducioso nell\\'integrazione dell\\'intelligenza artificiale nella pratica educativa?\\n(1 Per niente fiducioso - 2 Poco fiducioso - 3 Moderatamente fiducioso - 4 Neutrale - 5 Piuttosto fiducioso - 6 Molto fiducioso - 7 Estremamente fiducioso)',\n",
    "        'studenti': 'Da una scala da 1 a 7, quanto sei fiducioso nell\\'integrazione dell\\'intelligenza artificiale nella scuola o università?\\n(1 Per niente fiducioso - 2 Poco fiducioso - 3 Moderatamente fiducioso - 4 Neutrale - 5 Piuttosto fiducioso - 6 Molto fiducioso - 7 Estremamente fiducioso)',\n",
    "        'label_it': 'Fiducia integrazione',\n",
    "        'label_en': 'Trust in integration'\n",
    "    },\n",
    "    \n",
    "    # 6. PREOCCUPAZIONE INSERIMENTO IA\n",
    "    {\n",
    "        'tema': 'Preoccupazione inserimento IA',\n",
    "        'insegnanti': 'Da una scala da 1 a 7, quanto sei preoccupato riguardo all\\'utilizzo dell\\'intelligenza artificiale nel mondo dell\\'educazione?\\n\\n(1 Per niente preoccupato - 2 Poco preoccupato - 3 Moderatamente preoccupato - 4 Neutrale - 5 Piuttosto preoccupato - 6 Molto preoccupato - 7 Estremamente preoccupato)',\n",
    "        'studenti': 'Da una scala da 1 a 7, ti preoccupa l\\'inserimento dell\\'intelligenza artificiale nella scuola o nell\\'università?\\n\\n(1 Per niente preoccupato - 2 Poco preoccupato - 3 Moderatamente preoccupato - 4 Neutrale - 5 Piuttosto preoccupato - 6 Molto preoccupato - 7 Estremamente preoccupato)',\n",
    "        'label_it': 'Preoccupazione generale',\n",
    "        'label_en': 'General concern'\n",
    "    },\n",
    "]\n",
    "\n",
    "# Verifica che tutte le domande esistano nel dataset\n",
    "print(\"\\nVerifica disponibilità domande nel dataset:\\n\")\n",
    "print(f\"{'Tema':<40s} {'Ins':>5s} {'Stu':>5s}\")\n",
    "print(\"─\"*52)\n",
    "\n",
    "for item in domande_comparabili:\n",
    "    ins_exists = item['insegnanti'] in DF_plot.columns\n",
    "    stu_exists = item['studenti'] in DF_plot.columns\n",
    "    ins_mark = \"✓\" if ins_exists else \"✗\"\n",
    "    stu_mark = \"✓\" if stu_exists else \"✗\"\n",
    "    print(f\"{item['tema']:<40s} {ins_mark:>5s} {stu_mark:>5s}\")\n",
    "\n",
    "print(\"─\"*52)\n",
    "print(f\"\\nTotale coppie di domande comparabili: {len(domande_comparabili)}\")\n",
    "\n",
    "# Salva mapping\n",
    "OUT_EXPL = (Path.cwd()/\"../analysis/exports/latest\").resolve()\n",
    "mapping_df = pd.DataFrame(domande_comparabili)\n",
    "csv_mapping = OUT_EXPL / 'domande_likert_mapping.csv'\n",
    "mapping_df.to_csv(csv_mapping, index=False)\n",
    "print(f\"Salvato mapping in: {csv_mapping}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80fe7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === RICERCA FLESSIBILE DOMANDE LIKERT ===\n",
    "import re\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(\"RICERCA DOMANDE NEL DATASET (pattern flessibili)\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Pattern di ricerca più flessibili\n",
    "search_patterns = {\n",
    "    'competenza_pratica': r'quanto ti consideri competente.*uso pratico.*intelligenza',\n",
    "    'competenza_teorica': r'quanto ritieni adeguata.*competenza teorica.*intelligenza',\n",
    "    'cambiamento_didattica_ins': r'quanto pensi.*intelligenza.*cambierà.*tua didattica',\n",
    "    'cambiamento_studio_stu': r'quanto pensi.*intelligenza.*cambierà.*modo di studiare',\n",
    "    'formazione': r'quanto ritieni adeguata.*formazione.*intelligenza',\n",
    "    'fiducia_pratica_ins': r'quanto sei fiducioso.*integrazione.*intelligenza.*pratica educativa',\n",
    "    'fiducia_scuola_stu': r'quanto sei fiducioso.*integrazione.*intelligenza.*scuola',\n",
    "    'preoccupazione_educazione_ins': r'quanto sei preoccupato.*intelligenza.*mondo.*educazione',\n",
    "    'preoccupazione_scuola_stu': r'preoccupa.*inserimento.*intelligenza.*scuola',\n",
    "    'preoccupazione_studenti_ins': r'quanto sei preoccupato.*intelligenza.*parte degli studenti',\n",
    "    'preoccupazione_compagni_stu': r'quanto sei preoccupato.*intelligenza.*compagni',\n",
    "    'cambio_didattica_generale': r'quanto pensi.*intelligenza.*cambierà la didattica[^t]',  # non \"tua\"\n",
    "    'preparazione_insegnanti': r'quanto ritieni.*insegnanti.*preparati.*intelligenza',\n",
    "}\n",
    "\n",
    "found_questions = {}\n",
    "\n",
    "for key, pattern in search_patterns.items():\n",
    "    for col in DF_plot.columns:\n",
    "        if re.search(pattern, str(col), re.IGNORECASE | re.DOTALL):\n",
    "            found_questions[key] = col\n",
    "            print(f\"\\n✓ {key}:\")\n",
    "            print(f\"  {col[:120]}...\")\n",
    "            break\n",
    "\n",
    "print(f\"\\n{'='*90}\")\n",
    "print(f\"Trovate {len(found_questions)}/{len(search_patterns)} domande\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4687cb5c",
   "metadata": {},
   "source": [
    "### 🎻 Grafici a Violino: Domande Likert per i 4 Gruppi\n",
    "\n",
    "Creiamo grafici a violino per visualizzare:\n",
    "1. **Variabilità interna** in ciascun gruppo\n",
    "2. **Confronti tra i 4 gruppi** per ogni domanda\n",
    "3. **Confronti studenti vs insegnanti** su domande simili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d4dba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === GRAFICI A VIOLINO: DOMANDE COMPARABILI STUDENTI vs INSEGNANTI ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Setup grafico\n",
    "plt.style.use(['science', 'no-latex', 'grid'])\n",
    "mpl.rcParams.update({\n",
    "    'text.usetex': False,\n",
    "    'mathtext.fontset': 'dejavusans',\n",
    "    'font.family': 'DejaVu Sans',\n",
    "    'figure.dpi': 150,\n",
    "    'savefig.dpi': 300,\n",
    "    'font.size': 10,\n",
    "})\n",
    "\n",
    "OUT_EXPL = (Path.cwd()/\"../analysis/exports/latest\").resolve()\n",
    "ASSETS = (Path.cwd()/\"../assets/figures\").resolve()\n",
    "OUT_EXPL.mkdir(parents=True, exist_ok=True)\n",
    "ASSETS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Palette colori per i 4 gruppi\n",
    "palette_4groups = {\n",
    "    'studenti - secondaria': '#e41a1c',\n",
    "    'studenti - universitari': '#4daf4a',\n",
    "    'insegnanti - non in servizio': '#ffd31a',\n",
    "    'insegnanti - in servizio': '#377eb8',\n",
    "}\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(\"GRAFICI A VIOLINO: DOMANDE COMPARABILI\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Domande comparabili trovate\n",
    "domande_coppie = [\n",
    "    {\n",
    "        'tema': 'Cambiamento didattica/studio',\n",
    "        'domanda_ins': found_questions.get('cambiamento_didattica_ins'),\n",
    "        'domanda_stu': found_questions.get('cambiamento_studio_stu'),\n",
    "        'label_breve': 'Cambierà didattica/studio',\n",
    "        'file': 'likert_cambiamento_didattica_studio'\n",
    "    },\n",
    "    {\n",
    "        'tema': 'Fiducia integrazione IA',\n",
    "        'domanda_ins': found_questions.get('fiducia_pratica_ins'),\n",
    "        'domanda_stu': found_questions.get('fiducia_scuola_stu'),\n",
    "        'label_breve': 'Fiducia integrazione',\n",
    "        'file': 'likert_fiducia_integrazione'\n",
    "    },\n",
    "    {\n",
    "        'tema': 'Preoccupazione IA educazione',\n",
    "        'domanda_ins': found_questions.get('preoccupazione_educazione_ins'),\n",
    "        'domanda_stu': found_questions.get('preoccupazione_scuola_stu'),\n",
    "        'label_breve': 'Preoccupazione generale',\n",
    "        'file': 'likert_preoccupazione_generale'\n",
    "    },\n",
    "]\n",
    "\n",
    "# Genera grafici\n",
    "for coppia in domande_coppie:\n",
    "    if coppia['domanda_ins'] is None or coppia['domanda_stu'] is None:\n",
    "        print(f\"\\n⚠️  Saltata coppia '{coppia['tema']}' - domande mancanti\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'─'*90}\")\n",
    "    print(f\"📊 {coppia['tema']}\")\n",
    "    print(f\"{'─'*90}\")\n",
    "    \n",
    "    # Prepara dati: unifica le due domande in una singola colonna\n",
    "    df_vis = DF_plot[['GruppoDettaglio']].copy()\n",
    "    \n",
    "    # Per insegnanti, usa la domanda insegnanti\n",
    "    mask_ins = DF_plot['GruppoDettaglio'].str.contains('insegnanti', na=False)\n",
    "    df_vis.loc[mask_ins, 'Risposta'] = pd.to_numeric(\n",
    "        DF_plot.loc[mask_ins, coppia['domanda_ins']], \n",
    "        errors='coerce'\n",
    "    )\n",
    "    \n",
    "    # Per studenti, usa la domanda studenti\n",
    "    mask_stu = DF_plot['GruppoDettaglio'].str.contains('studenti', na=False)\n",
    "    df_vis.loc[mask_stu, 'Risposta'] = pd.to_numeric(\n",
    "        DF_plot.loc[mask_stu, coppia['domanda_stu']], \n",
    "        errors='coerce'\n",
    "    )\n",
    "    \n",
    "    # Rimuovi valori mancanti\n",
    "    df_vis = df_vis.dropna(subset=['Risposta'])\n",
    "    df_vis = df_vis[df_vis['GruppoDettaglio'].isin(ORDER_4)]\n",
    "    df_vis['GruppoDettaglio'] = pd.Categorical(\n",
    "        df_vis['GruppoDettaglio'], \n",
    "        categories=ORDER_4, \n",
    "        ordered=True\n",
    "    )\n",
    "    \n",
    "    if len(df_vis) == 0:\n",
    "        print(\"  ⚠️  Nessun dato disponibile\")\n",
    "        continue\n",
    "    \n",
    "    # Statistiche descrittive\n",
    "    print(f\"\\n  Statistiche per gruppo:\")\n",
    "    stats = df_vis.groupby('GruppoDettaglio', observed=False)['Risposta'].agg([\n",
    "        ('N', 'count'),\n",
    "        ('Media', 'mean'),\n",
    "        ('Mediana', 'median'),\n",
    "        ('SD', 'std'),\n",
    "        ('Min', 'min'),\n",
    "        ('Max', 'max')\n",
    "    ]).round(2)\n",
    "    print(stats)\n",
    "    \n",
    "    # Crea grafico - ITALIANO\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    sns.violinplot(\n",
    "        data=df_vis,\n",
    "        x='GruppoDettaglio',\n",
    "        y='Risposta',\n",
    "        hue='GruppoDettaglio',\n",
    "        palette=palette_4groups,\n",
    "        order=ORDER_4,\n",
    "        inner='box',\n",
    "        cut=0,\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    ax.set_xlabel('Gruppo', fontsize=11)\n",
    "    ax.set_ylabel('Punteggio (scala 1-7)', fontsize=11)\n",
    "    ax.set_title(f'{coppia[\"label_breve\"]}\\n(scala Likert 1-7)', fontsize=12, pad=15)\n",
    "    ax.set_ylim(0.5, 7.5)\n",
    "    ax.set_yticks(range(1, 8))\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax.set_axisbelow(True)\n",
    "    \n",
    "    # Rimuovi legenda (ridondante con x-axis)\n",
    "    if ax.get_legend():\n",
    "        ax.get_legend().remove()\n",
    "    \n",
    "    plt.xticks(rotation=15, ha='right')\n",
    "    sns.despine(ax=ax)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salva\n",
    "    fp_it_png = OUT_EXPL / f\"{coppia['file']}_4groups_it.png\"\n",
    "    fp_it_svg = ASSETS / f\"{coppia['file']}_4groups_it.svg\"\n",
    "    fig.savefig(fp_it_png, bbox_inches='tight')\n",
    "    fig.savefig(fp_it_svg, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "    \n",
    "    print(f\"  ✓ Salvato: {fp_it_png}\")\n",
    "    \n",
    "    # Versione INGLESE\n",
    "    fig_en, ax_en = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Mappa nomi gruppi in inglese\n",
    "    map_en = {\n",
    "        'studenti - secondaria': 'students - secondary',\n",
    "        'studenti - universitari': 'students - university',\n",
    "        'insegnanti - non in servizio': 'teachers - pre-service',\n",
    "        'insegnanti - in servizio': 'teachers - in-service',\n",
    "    }\n",
    "    \n",
    "    df_vis_en = df_vis.copy()\n",
    "    df_vis_en['GruppoDettaglio_EN'] = df_vis_en['GruppoDettaglio'].map(map_en)\n",
    "    order_en = [map_en[g] for g in ORDER_4]\n",
    "    df_vis_en['GruppoDettaglio_EN'] = pd.Categorical(\n",
    "        df_vis_en['GruppoDettaglio_EN'],\n",
    "        categories=order_en,\n",
    "        ordered=True\n",
    "    )\n",
    "    \n",
    "    palette_en = {map_en[k]: v for k, v in palette_4groups.items()}\n",
    "    \n",
    "    sns.violinplot(\n",
    "        data=df_vis_en,\n",
    "        x='GruppoDettaglio_EN',\n",
    "        y='Risposta',\n",
    "        hue='GruppoDettaglio_EN',\n",
    "        palette=palette_en,\n",
    "        order=order_en,\n",
    "        inner='box',\n",
    "        cut=0,\n",
    "        ax=ax_en\n",
    "    )\n",
    "    \n",
    "    ax_en.set_xlabel('Group', fontsize=11)\n",
    "    ax_en.set_ylabel('Score (1-7 scale)', fontsize=11)\n",
    "    \n",
    "    # Traduci label\n",
    "    label_en_map = {\n",
    "        'Cambierà didattica/studio': 'Will change teaching/study',\n",
    "        'Fiducia integrazione': 'Trust in integration',\n",
    "        'Preoccupazione generale': 'General concern'\n",
    "    }\n",
    "    label_en = label_en_map.get(coppia['label_breve'], coppia['label_breve'])\n",
    "    \n",
    "    ax_en.set_title(f'{label_en}\\n(Likert scale 1-7)', fontsize=12, pad=15)\n",
    "    ax_en.set_ylim(0.5, 7.5)\n",
    "    ax_en.set_yticks(range(1, 8))\n",
    "    ax_en.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax_en.set_axisbelow(True)\n",
    "    \n",
    "    if ax_en.get_legend():\n",
    "        ax_en.get_legend().remove()\n",
    "    \n",
    "    plt.xticks(rotation=15, ha='right')\n",
    "    sns.despine(ax=ax_en)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fp_en_png = OUT_EXPL / f\"{coppia['file']}_4groups_en.png\"\n",
    "    fp_en_svg = ASSETS / f\"{coppia['file']}_4groups_en.svg\"\n",
    "    fig_en.savefig(fp_en_png, bbox_inches='tight')\n",
    "    fig_en.savefig(fp_en_svg, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close(fig_en)\n",
    "    \n",
    "    print(f\"  ✓ Salvato: {fp_en_png}\")\n",
    "\n",
    "print(f\"\\n{'='*90}\")\n",
    "print(\"✓ Grafici completati!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afd8bcb",
   "metadata": {},
   "source": [
    "---\n",
    "### 📊 Domande Likert NON comparabili\n",
    "\n",
    "Ora analizziamo le domande Likert che sono specifiche solo per **studenti** o solo per **insegnanti** (non hanno una controparte diretta nell'altro gruppo).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a93812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IDENTIFICAZIONE DOMANDE NON COMPARABILI ===\n",
    "\n",
    "# Dalla mappatura precedente, identifichiamo le domande che sono specifiche per ogni gruppo\n",
    "\n",
    "# Domande SOLO insegnanti (non hanno corrispondenza con studenti)\n",
    "# NOTA: \"Competenza teorica IA\" è già inclusa nei grafici comparabili, quindi la escludiamo\n",
    "solo_insegnanti = [\n",
    "    {\n",
    "        'col': 'Da una scala da 1 a 7 quanto pensi che l\\'intelligenza artificiale cambierà la didattica?\\n\\n(1 Per niente - 2 Poco - 3 Moderatamente - 4 Neutrale -  5 Piuttosto - 6 Molto - 7 Estremamente)',\n",
    "        'label_it': 'Cambierà la didattica (generale)',\n",
    "        'label_en': 'Will change teaching (general)',\n",
    "        'tema': 'cambiamento_didattica_generale'\n",
    "    },\n",
    "    {\n",
    "        'col': 'Da una scala da 1 a 7, quanto pensi che l\\'intelligenza artificiale cambierà la tua didattica?\\n\\n(1 Per niente - 2 Poco - 3 Moderatamente - 4 Neutrale -  5 Piuttosto - 6 Molto - 7 Estremamente)',\n",
    "        'label_it': 'Cambierà la mia didattica (personale)',\n",
    "        'label_en': 'Will change my teaching (personal)',\n",
    "        'tema': 'cambiamento_didattica_personale'\n",
    "    },\n",
    "    {\n",
    "        'col': 'Da una scala da 1 a 7, quanto sei fiducioso nell\\'utilizzo da parte degli studenti di un uso responsabile e maturo dell\\'intelligenza artificiale?\\n(1 Per niente fiducioso - 2 Poco fiducioso - 3 Moderatamente fiducioso - 4 Neutrale - 5 Piuttosto fiducioso - 6 Molto fiducioso - 7 Estremamente fiducioso)',\n",
    "        'label_it': 'Fiducia uso responsabile studenti',\n",
    "        'label_en': 'Trust in students\\' responsible use',\n",
    "        'tema': 'fiducia_studenti'\n",
    "    },\n",
    "    {\n",
    "        'col': 'Da una scala da 1 a 7, quanto sei preoccupato riguardo all\\'utilizzo dell\\'intelligenza artificiale da parte degli studenti?\\n(1 Per niente preoccupato - 2 Poco preoccupato - 3 Moderatamente preoccupato - 4 Neutrale - 5 Piuttosto preoccupato - 6 Molto preoccupato - 7 Estremamente preoccupato)',\n",
    "        'label_it': 'Preoccupazione uso IA studenti',\n",
    "        'label_en': 'Concern about students\\' AI use',\n",
    "        'tema': 'preoccupazione_studenti'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Domande SOLO studenti (non hanno corrispondenza con insegnanti)\n",
    "solo_studenti = [\n",
    "    {\n",
    "        'col': 'Su una scala da 1 a 7, quanto ritieni che i tuoi attuali insegnanti siano preparati e competenti nell\\'insegnare l\\'uso dell\\'intelligenza artificiale?\\n(1 Per niente - 2 Poco - 3 Moderatamente - 4 Neutrale - 5 Abbastanza - 6 Molto - 7 Estremamente)',\n",
    "        'label_it': 'Preparazione insegnanti su IA',\n",
    "        'label_en': 'Teachers\\' preparedness on AI',\n",
    "        'tema': 'preparazione_insegnanti'\n",
    "    },\n",
    "    {\n",
    "        'col': 'Da una scala da 1 a 7, quanto sei preoccupato riguardo all\\'utilizzo dell\\'intelligenza artificiale da parte dei tuoi compagni di scuola o universitarì?\\n(1 Per niente preoccupato - 2 Poco preoccupato - 3 Moderatamente preoccupato - 4 Neutrale - 5 Piuttosto preoccupato - 6 Molto preoccupato - 7 Estremamente preoccupato)',\n",
    "        'label_it': 'Preoccupazione uso IA compagni',\n",
    "        'label_en': 'Concern about peers\\' AI use',\n",
    "        'tema': 'preoccupazione_compagni'\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(\"DOMANDE LIKERT NON COMPARABILI\")\n",
    "print(\"=\"*90)\n",
    "print(f\"\\n✓ Domande SOLO INSEGNANTI: {len(solo_insegnanti)}\")\n",
    "for i, d in enumerate(solo_insegnanti, 1):\n",
    "    print(f\"  {i}. {d['label_it']}\")\n",
    "    \n",
    "print(f\"\\n✓ Domande SOLO STUDENTI: {len(solo_studenti)}\")\n",
    "for i, d in enumerate(solo_studenti, 1):\n",
    "    print(f\"  {i}. {d['label_it']}\")\n",
    "\n",
    "print(f\"\\n✓ TOTALE domande non comparabili: {len(solo_insegnanti) + len(solo_studenti)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c33dc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === GRAFICI A VIOLINO: DOMANDE SOLO INSEGNANTI ===\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(\"GRAFICI A VIOLINO: DOMANDE SOLO INSEGNANTI\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Solo i 2 gruppi di insegnanti\n",
    "order_insegnanti = ['insegnanti - non in servizio', 'insegnanti - in servizio']\n",
    "palette_insegnanti = {\n",
    "    'insegnanti - non in servizio': palette_4groups['insegnanti - non in servizio'],\n",
    "    'insegnanti - in servizio': palette_4groups['insegnanti - in servizio']\n",
    "}\n",
    "\n",
    "for q in solo_insegnanti:\n",
    "    col = q['col']\n",
    "    label_it = q['label_it']\n",
    "    label_en = q['label_en']\n",
    "    tema = q['tema']\n",
    "    \n",
    "    if col not in DF_plot.columns:\n",
    "        print(f\"\\n⚠️ Colonna non trovata: {label_it}\")\n",
    "        continue\n",
    "    \n",
    "    # Prepara dati - solo insegnanti\n",
    "    df_temp = DF_plot[DF_plot['GruppoDettaglio'].isin(order_insegnanti)].copy()\n",
    "    df_temp = df_temp[[col, 'GruppoDettaglio']].dropna()\n",
    "    \n",
    "    if len(df_temp) == 0:\n",
    "        print(f\"\\n⚠️ Nessun dato per: {label_it}\")\n",
    "        continue\n",
    "        \n",
    "    df_vis = df_temp.copy()\n",
    "    df_vis.columns = ['valore', 'GruppoDettaglio']\n",
    "    # Rimuovi categorie non usate e riordina\n",
    "    df_vis['GruppoDettaglio'] = pd.Categorical(\n",
    "        df_vis['GruppoDettaglio'], \n",
    "        categories=order_insegnanti, \n",
    "        ordered=True\n",
    "    )\n",
    "    \n",
    "    # Statistiche\n",
    "    stats = df_vis.groupby('GruppoDettaglio', observed=True)['valore'].agg(['count', 'mean', 'median', 'std', 'min', 'max'])\n",
    "    stats.columns = ['N', 'Media', 'Mediana', 'SD', 'Min', 'Max']\n",
    "    \n",
    "    print(f\"\\n{'─'*86}\")\n",
    "    print(f\"📊 {label_it}\")\n",
    "    print(f\"{'─'*86}\")\n",
    "    print(f\"\\n  Statistiche per gruppo:\")\n",
    "    print(stats.to_string())\n",
    "    \n",
    "    # === GRAFICO ITALIANO ===\n",
    "    fig_it, ax_it = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    \n",
    "    sns.violinplot(\n",
    "        data=df_vis,\n",
    "        x='GruppoDettaglio',\n",
    "        y='valore',\n",
    "        hue='GruppoDettaglio',\n",
    "        palette=palette_insegnanti,\n",
    "        ax=ax_it,\n",
    "        legend=False,\n",
    "        inner='box'\n",
    "    )\n",
    "    ax_it.set_xlabel('Gruppo', fontsize=12)\n",
    "    ax_it.set_ylabel('Punteggio (scala 1-7)', fontsize=12)\n",
    "    ax_it.set_title(f'{label_it}\\n(scala Likert 1-7)', fontsize=13, weight='bold')\n",
    "    ax_it.set_ylim(0.5, 7.5)\n",
    "    ax_it.set_xticklabels(ax_it.get_xticklabels(), rotation=15, ha='right')\n",
    "    ax_it.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salva IT\n",
    "    out_it = OUT_EXPL / f'likert_{tema}_insegnanti_it.png'\n",
    "    fig_it.savefig(out_it, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\n  ✓ Salvato: {out_it}\")\n",
    "    \n",
    "    # Mostra IT\n",
    "    plt.show()\n",
    "    plt.close(fig_it)\n",
    "    \n",
    "    # === GRAFICO INGLESE ===\n",
    "    order_en_ins = ['teachers - pre-service', 'teachers - in-service']\n",
    "    df_vis_en = df_vis.copy()\n",
    "    df_vis_en['GruppoDettaglio'] = df_vis_en['GruppoDettaglio'].cat.rename_categories({\n",
    "        'insegnanti - non in servizio': 'teachers - pre-service',\n",
    "        'insegnanti - in servizio': 'teachers - in-service'\n",
    "    })\n",
    "    palette_en_ins = {\n",
    "        'teachers - pre-service': palette_insegnanti['insegnanti - non in servizio'],\n",
    "        'teachers - in-service': palette_insegnanti['insegnanti - in servizio']\n",
    "    }\n",
    "    \n",
    "    fig_en, ax_en = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    \n",
    "    sns.violinplot(\n",
    "        data=df_vis_en,\n",
    "        x='GruppoDettaglio',\n",
    "        y='valore',\n",
    "        hue='GruppoDettaglio',\n",
    "        palette=palette_en_ins,\n",
    "        ax=ax_en,\n",
    "        legend=False,\n",
    "        inner='box'\n",
    "    )\n",
    "    ax_en.set_xlabel('Group', fontsize=12)\n",
    "    ax_en.set_ylabel('Score (1-7 scale)', fontsize=12)\n",
    "    ax_en.set_title(f'{label_en}\\n(Likert scale 1-7)', fontsize=13, weight='bold')\n",
    "    ax_en.set_ylim(0.5, 7.5)\n",
    "    ax_en.set_xticklabels(ax_en.get_xticklabels(), rotation=15, ha='right')\n",
    "    ax_en.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salva EN\n",
    "    out_en = OUT_EXPL / f'likert_{tema}_insegnanti_en.png'\n",
    "    fig_en.savefig(out_en, dpi=300, bbox_inches='tight')\n",
    "    print(f\"  ✓ Salvato: {out_en}\")\n",
    "    \n",
    "    # Mostra EN\n",
    "    plt.show()\n",
    "    plt.close(fig_en)\n",
    "\n",
    "print(f\"\\n{'='*90}\")\n",
    "print(f\"✓ Grafici insegnanti completati!\")\n",
    "print(f\"{'='*90}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601a9693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === GRAFICI A VIOLINO: DOMANDE SOLO STUDENTI ===\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"GRAFICI A VIOLINO: DOMANDE SOLO STUDENTI\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Solo i 2 gruppi di studenti\n",
    "order_studenti = ['studenti - secondaria', 'studenti - universitari']\n",
    "palette_studenti = {\n",
    "    'studenti - secondaria': palette_4groups['studenti - secondaria'],\n",
    "    'studenti - universitari': palette_4groups['studenti - universitari']\n",
    "}\n",
    "\n",
    "for q in solo_studenti:\n",
    "    col = q['col']\n",
    "    label_it = q['label_it']\n",
    "    label_en = q['label_en']\n",
    "    tema = q['tema']\n",
    "    \n",
    "    if col not in DF_plot.columns:\n",
    "        print(f\"\\n⚠️ Colonna non trovata: {label_it}\")\n",
    "        continue\n",
    "    \n",
    "    # Prepara dati - solo studenti\n",
    "    df_temp = DF_plot[DF_plot['GruppoDettaglio'].isin(order_studenti)].copy()\n",
    "    df_temp = df_temp[[col, 'GruppoDettaglio']].dropna()\n",
    "    \n",
    "    if len(df_temp) == 0:\n",
    "        print(f\"\\n⚠️ Nessun dato per: {label_it}\")\n",
    "        continue\n",
    "        \n",
    "    df_vis = df_temp.copy()\n",
    "    df_vis.columns = ['valore', 'GruppoDettaglio']\n",
    "    # Rimuovi categorie non usate e riordina\n",
    "    df_vis['GruppoDettaglio'] = pd.Categorical(\n",
    "        df_vis['GruppoDettaglio'], \n",
    "        categories=order_studenti, \n",
    "        ordered=True\n",
    "    )\n",
    "    \n",
    "    # Statistiche\n",
    "    stats = df_vis.groupby('GruppoDettaglio', observed=True)['valore'].agg(['count', 'mean', 'median', 'std', 'min', 'max'])\n",
    "    stats.columns = ['N', 'Media', 'Mediana', 'SD', 'Min', 'Max']\n",
    "    \n",
    "    print(f\"\\n{'─'*86}\")\n",
    "    print(f\"📊 {label_it}\")\n",
    "    print(f\"{'─'*86}\")\n",
    "    print(f\"\\n  Statistiche per gruppo:\")\n",
    "    print(stats.to_string())\n",
    "    \n",
    "    # === GRAFICO ITALIANO ===\n",
    "    fig_it, ax_it = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    \n",
    "    sns.violinplot(\n",
    "        data=df_vis,\n",
    "        x='GruppoDettaglio',\n",
    "        y='valore',\n",
    "        hue='GruppoDettaglio',\n",
    "        palette=palette_studenti,\n",
    "        ax=ax_it,\n",
    "        legend=False,\n",
    "        inner='box'\n",
    "    )\n",
    "    ax_it.set_xlabel('Gruppo', fontsize=12)\n",
    "    ax_it.set_ylabel('Punteggio (scala 1-7)', fontsize=12)\n",
    "    ax_it.set_title(f'{label_it}\\n(scala Likert 1-7)', fontsize=13, weight='bold')\n",
    "    ax_it.set_ylim(0.5, 7.5)\n",
    "    ax_it.set_xticklabels(ax_it.get_xticklabels(), rotation=15, ha='right')\n",
    "    ax_it.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salva IT\n",
    "    out_it = OUT_EXPL / f'likert_{tema}_studenti_it.png'\n",
    "    fig_it.savefig(out_it, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\n  ✓ Salvato: {out_it}\")\n",
    "    \n",
    "    # Mostra IT\n",
    "    plt.show()\n",
    "    plt.close(fig_it)\n",
    "    \n",
    "    # === GRAFICO INGLESE ===\n",
    "    order_en_stud = ['students - secondary', 'students - university']\n",
    "    df_vis_en = df_vis.copy()\n",
    "    df_vis_en['GruppoDettaglio'] = df_vis_en['GruppoDettaglio'].cat.rename_categories({\n",
    "        'studenti - secondaria': 'students - secondary',\n",
    "        'studenti - universitari': 'students - university'\n",
    "    })\n",
    "    palette_en_stud = {\n",
    "        'students - secondary': palette_studenti['studenti - secondaria'],\n",
    "        'students - university': palette_studenti['studenti - universitari']\n",
    "    }\n",
    "    \n",
    "    fig_en, ax_en = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    \n",
    "    sns.violinplot(\n",
    "        data=df_vis_en,\n",
    "        x='GruppoDettaglio',\n",
    "        y='valore',\n",
    "        hue='GruppoDettaglio',\n",
    "        palette=palette_en_stud,\n",
    "        ax=ax_en,\n",
    "        legend=False,\n",
    "        inner='box'\n",
    "    )\n",
    "    ax_en.set_xlabel('Group', fontsize=12)\n",
    "    ax_en.set_ylabel('Score (1-7 scale)', fontsize=12)\n",
    "    ax_en.set_title(f'{label_en}\\n(Likert scale 1-7)', fontsize=13, weight='bold')\n",
    "    ax_en.set_ylim(0.5, 7.5)\n",
    "    ax_en.set_xticklabels(ax_en.get_xticklabels(), rotation=15, ha='right')\n",
    "    ax_en.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salva EN\n",
    "    out_en = OUT_EXPL / f'likert_{tema}_studenti_en.png'\n",
    "    fig_en.savefig(out_en, dpi=300, bbox_inches='tight')\n",
    "    print(f\"  ✓ Salvato: {out_en}\")\n",
    "    \n",
    "    # Mostra EN\n",
    "    plt.show()\n",
    "    plt.close(fig_en)\n",
    "\n",
    "print(f\"\\n{'='*90}\")\n",
    "print(f\"✓ Grafici studenti completati!\")\n",
    "print(f\"{'='*90}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f372f0b",
   "metadata": {},
   "source": [
    "---\n",
    "### 📊 Analisi Differenze Interne tra Sottogruppi\n",
    "\n",
    "Verifichiamo se ci sono **differenze significative** tra i sottogruppi:\n",
    "- **Insegnanti**: non in servizio vs in servizio\n",
    "- **Studenti**: secondaria vs universitari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c53ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ANALISI DIFFERENZE INTERNE TRA SOTTOGRUPPI ===\n",
    "\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(\"ANALISI DIFFERENZE INTERNE TRA SOTTOGRUPPI - DOMANDE LIKERT\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Funzione per calcolare Cohen's d\n",
    "def cohens_d(group1, group2):\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    var1, var2 = np.var(group1, ddof=1), np.var(group2, ddof=1)\n",
    "    pooled_std = np.sqrt(((n1-1)*var1 + (n2-1)*var2) / (n1+n2-2))\n",
    "    return (np.mean(group1) - np.mean(group2)) / pooled_std\n",
    "\n",
    "# Lista per salvare i risultati\n",
    "risultati_differenze = []\n",
    "\n",
    "# ===== ANALISI INSEGNANTI =====\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"1. DIFFERENZE TRA INSEGNANTI: NON IN SERVIZIO vs IN SERVIZIO\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "for q in solo_insegnanti:\n",
    "    col = q['col']\n",
    "    label = q['label_it']\n",
    "    \n",
    "    if col not in DF_plot.columns:\n",
    "        continue\n",
    "    \n",
    "    # Estrai dati per i due gruppi\n",
    "    df_ins = DF_plot[DF_plot['GruppoDettaglio'].isin(['insegnanti - non in servizio', 'insegnanti - in servizio'])].copy()\n",
    "    df_ins = df_ins[[col, 'GruppoDettaglio']].dropna()\n",
    "    \n",
    "    if len(df_ins) < 10:\n",
    "        continue\n",
    "    \n",
    "    # Dati per gruppo - converti in float\n",
    "    non_servizio = pd.to_numeric(df_ins[df_ins['GruppoDettaglio'] == 'insegnanti - non in servizio'][col], errors='coerce').dropna().values\n",
    "    in_servizio = pd.to_numeric(df_ins[df_ins['GruppoDettaglio'] == 'insegnanti - in servizio'][col], errors='coerce').dropna().values\n",
    "    \n",
    "    if len(non_servizio) < 3 or len(in_servizio) < 3:\n",
    "        continue\n",
    "    \n",
    "    # Statistiche descrittive\n",
    "    mean_non = np.mean(non_servizio)\n",
    "    mean_in = np.mean(in_servizio)\n",
    "    diff = mean_non - mean_in\n",
    "    \n",
    "    # T-test\n",
    "    t_stat, p_val = ttest_ind(non_servizio, in_servizio)\n",
    "    \n",
    "    # Cohen's d\n",
    "    d = cohens_d(non_servizio, in_servizio)\n",
    "    \n",
    "    # Significatività\n",
    "    sig = '***' if p_val < 0.001 else '**' if p_val < 0.01 else '*' if p_val < 0.05 else 'ns'\n",
    "    \n",
    "    print(f\"\\n{'─'*86}\")\n",
    "    print(f\"📊 {label}\")\n",
    "    print(f\"{'─'*86}\")\n",
    "    print(f\"  Non in servizio: M = {mean_non:.2f} (N = {len(non_servizio)})\")\n",
    "    print(f\"  In servizio:     M = {mean_in:.2f} (N = {len(in_servizio)})\")\n",
    "    print(f\"  Differenza:      Δ = {diff:+.2f}\")\n",
    "    print(f\"  T-test:          t = {t_stat:.2f}, p = {p_val:.4f} {sig}\")\n",
    "    print(f\"  Effect size:     Cohen's d = {d:.3f}\")\n",
    "    \n",
    "    # Interpreta effect size\n",
    "    if abs(d) < 0.2:\n",
    "        effect_label = \"trascurabile\"\n",
    "    elif abs(d) < 0.5:\n",
    "        effect_label = \"piccolo\"\n",
    "    elif abs(d) < 0.8:\n",
    "        effect_label = \"medio\"\n",
    "    else:\n",
    "        effect_label = \"grande\"\n",
    "    \n",
    "    print(f\"  Interpretazione: Effetto {effect_label}\")\n",
    "    \n",
    "    # Salva risultati\n",
    "    risultati_differenze.append({\n",
    "        'Gruppo': 'Insegnanti',\n",
    "        'Domanda': label,\n",
    "        'M_gruppo1': mean_non,\n",
    "        'M_gruppo2': mean_in,\n",
    "        'Differenza': diff,\n",
    "        't': t_stat,\n",
    "        'p': p_val,\n",
    "        'sig': sig,\n",
    "        'Cohen_d': d,\n",
    "        'Effetto': effect_label\n",
    "    })\n",
    "\n",
    "# ===== ANALISI STUDENTI =====\n",
    "print(\"\\n\\n\" + \"=\"*90)\n",
    "print(\"2. DIFFERENZE TRA STUDENTI: SECONDARIA vs UNIVERSITARI\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "for q in solo_studenti:\n",
    "    col = q['col']\n",
    "    label = q['label_it']\n",
    "    \n",
    "    if col not in DF_plot.columns:\n",
    "        continue\n",
    "    \n",
    "    # Estrai dati per i due gruppi\n",
    "    df_stu = DF_plot[DF_plot['GruppoDettaglio'].isin(['studenti - secondaria', 'studenti - universitari'])].copy()\n",
    "    df_stu = df_stu[[col, 'GruppoDettaglio']].dropna()\n",
    "    \n",
    "    if len(df_stu) < 10:\n",
    "        continue\n",
    "    \n",
    "    # Dati per gruppo - converti in float\n",
    "    secondaria = pd.to_numeric(df_stu[df_stu['GruppoDettaglio'] == 'studenti - secondaria'][col], errors='coerce').dropna().values\n",
    "    universitari = pd.to_numeric(df_stu[df_stu['GruppoDettaglio'] == 'studenti - universitari'][col], errors='coerce').dropna().values\n",
    "    \n",
    "    if len(secondaria) < 3 or len(universitari) < 3:\n",
    "        continue\n",
    "    \n",
    "    # Statistiche descrittive\n",
    "    mean_sec = np.mean(secondaria)\n",
    "    mean_uni = np.mean(universitari)\n",
    "    diff = mean_sec - mean_uni\n",
    "    \n",
    "    # T-test\n",
    "    t_stat, p_val = ttest_ind(secondaria, universitari)\n",
    "    \n",
    "    # Cohen's d\n",
    "    d = cohens_d(secondaria, universitari)\n",
    "    \n",
    "    # Significatività\n",
    "    sig = '***' if p_val < 0.001 else '**' if p_val < 0.01 else '*' if p_val < 0.05 else 'ns'\n",
    "    \n",
    "    print(f\"\\n{'─'*86}\")\n",
    "    print(f\"📊 {label}\")\n",
    "    print(f\"{'─'*86}\")\n",
    "    print(f\"  Secondaria:      M = {mean_sec:.2f} (N = {len(secondaria)})\")\n",
    "    print(f\"  Universitari:    M = {mean_uni:.2f} (N = {len(universitari)})\")\n",
    "    print(f\"  Differenza:      Δ = {diff:+.2f}\")\n",
    "    print(f\"  T-test:          t = {t_stat:.2f}, p = {p_val:.4f} {sig}\")\n",
    "    print(f\"  Effect size:     Cohen's d = {d:.3f}\")\n",
    "    \n",
    "    # Interpreta effect size\n",
    "    if abs(d) < 0.2:\n",
    "        effect_label = \"trascurabile\"\n",
    "    elif abs(d) < 0.5:\n",
    "        effect_label = \"piccolo\"\n",
    "    elif abs(d) < 0.8:\n",
    "        effect_label = \"medio\"\n",
    "    else:\n",
    "        effect_label = \"grande\"\n",
    "    \n",
    "    print(f\"  Interpretazione: Effetto {effect_label}\")\n",
    "    \n",
    "    # Salva risultati\n",
    "    risultati_differenze.append({\n",
    "        'Gruppo': 'Studenti',\n",
    "        'Domanda': label,\n",
    "        'M_gruppo1': mean_sec,\n",
    "        'M_gruppo2': mean_uni,\n",
    "        'Differenza': diff,\n",
    "        't': t_stat,\n",
    "        'p': p_val,\n",
    "        'sig': sig,\n",
    "        'Cohen_d': d,\n",
    "        'Effetto': effect_label\n",
    "    })\n",
    "\n",
    "# ===== RIEPILOGO =====\n",
    "print(\"\\n\\n\" + \"=\"*90)\n",
    "print(\"📊 RIEPILOGO DIFFERENZE SIGNIFICATIVE\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "df_diff = pd.DataFrame(risultati_differenze)\n",
    "df_sig = df_diff[df_diff['p'] < 0.05].sort_values('p')\n",
    "\n",
    "if len(df_sig) > 0:\n",
    "    print(f\"\\n✓ Trovate {len(df_sig)} differenze significative (p < 0.05):\\n\")\n",
    "    for idx, row in df_sig.iterrows():\n",
    "        print(f\"  • {row['Gruppo']} - {row['Domanda']}\")\n",
    "        print(f\"    Δ = {row['Differenza']:+.2f}, p = {row['p']:.4f} {row['sig']}, d = {row['Cohen_d']:.3f} ({row['Effetto']})\")\n",
    "else:\n",
    "    print(\"\\n✗ Nessuna differenza significativa trovata (tutte p > 0.05)\")\n",
    "\n",
    "# Salva risultati\n",
    "csv_out = OUT_EXPL / 'likert_differenze_interne_sottogruppi.csv'\n",
    "df_diff.to_csv(csv_out, index=False)\n",
    "print(f\"\\n✓ Risultati salvati: {csv_out}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5bd1c0",
   "metadata": {},
   "source": [
    "## 📊 Sintesi Analisi Differenze Interne\n",
    "\n",
    "### Risultati Principali\n",
    "\n",
    "#### ✅ **INSEGNANTI** (non in servizio vs in servizio)\n",
    "**Nessuna differenza significativa** tra i due sottogruppi:\n",
    "- **Cambierà la didattica generale**: Δ = +0.07, p = 0.634 (ns)\n",
    "- **Cambierà la mia didattica**: Δ = +0.34, p = 0.051 (marginale, quasi significativo!)\n",
    "- **Fiducia uso responsabile studenti**: Δ = +0.29, p = 0.105 (ns)\n",
    "- **Preoccupazione uso IA studenti**: Δ = -0.09, p = 0.608 (ns)\n",
    "\n",
    "**Interpretazione**: Gli insegnanti non in servizio e in servizio hanno **atteggiamenti molto simili** verso l'IA. L'unica differenza borderline è sul \"Cambierà la mia didattica\" dove i non in servizio sono leggermente più ottimisti (5.02 vs 4.68, effetto piccolo d=0.22).\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ **STUDENTI** (secondaria vs universitari)\n",
    "**Due differenze significative**:\n",
    "1. **Preparazione insegnanti su IA**: ⭐⭐\n",
    "   - Secondaria: M = 3.14\n",
    "   - Universitari: M = 3.70\n",
    "   - Δ = -0.57, p = **0.009**, d = -0.34 (effetto piccolo)\n",
    "   - **Gli universitari giudicano i loro insegnanti leggermente più preparati**\n",
    "\n",
    "2. **Preoccupazione uso IA compagni**: ⭐⭐\n",
    "   - Secondaria: M = 2.91\n",
    "   - Universitari: M = 3.53\n",
    "   - Δ = -0.63, p = **0.005**, d = -0.36 (effetto piccolo)\n",
    "   - **Gli universitari sono più preoccupati per l'uso IA dei compagni**\n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 Conclusioni\n",
    "\n",
    "**Hai ragione nella tua osservazione!** Tuttavia:\n",
    "- **Insegnanti**: Non ci sono differenze significative, anche se c'è una tendenza borderline (p=0.051) sul \"Cambierà la mia didattica\"\n",
    "- **Studenti**: Ci sono differenze significative ma con effetti piccoli (d ≈ 0.3-0.4)\n",
    "\n",
    "**Il risultato più importante**: I **sottogruppi sono relativamente omogenei** all'interno di ciascuna categoria principale (insegnanti/studenti). Le differenze maggiori rimangono quelle **tra** le categorie principali (studenti vs insegnanti), non **dentro** le categorie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfab908",
   "metadata": {},
   "source": [
    "---\n",
    "### 🔍 Approfondimento: Fiducia e Preoccupazione negli Insegnanti\n",
    "\n",
    "Focus su due domande chiave:\n",
    "1. **Fiducia uso responsabile studenti**: Gli insegnanti hanno fiducia che gli studenti usino l'IA responsabilmente?\n",
    "2. **Preoccupazione uso IA studenti**: Gli insegnanti sono preoccupati per l'uso IA degli studenti?\n",
    "\n",
    "Verifichiamo se ci sono differenze tra insegnanti **non in servizio** vs **in servizio**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ae2d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ANALISI DETTAGLIATA: FIDUCIA E PREOCCUPAZIONE INSEGNANTI ===\n",
    "\n",
    "from scipy.stats import ttest_ind, mannwhitneyu, levene\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(\"ANALISI DETTAGLIATA: FIDUCIA E PREOCCUPAZIONE NEGLI INSEGNANTI\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Trova le due domande specifiche\n",
    "domanda_fiducia = None\n",
    "domanda_preoccupazione = None\n",
    "\n",
    "for q in solo_insegnanti:\n",
    "    if 'Fiducia uso responsabile studenti' in q['label_it']:\n",
    "        domanda_fiducia = q\n",
    "    if 'Preoccupazione uso IA studenti' in q['label_it']:\n",
    "        domanda_preoccupazione = q\n",
    "\n",
    "# === ANALISI 1: FIDUCIA USO RESPONSABILE ===\n",
    "if domanda_fiducia:\n",
    "    col = domanda_fiducia['col']\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"1️⃣  FIDUCIA NELL'USO RESPONSABILE DA PARTE DEGLI STUDENTI\")\n",
    "    print(\"=\"*90)\n",
    "    print(\"\\nDomanda: 'Quanto sei fiducioso nell'utilizzo da parte degli studenti\")\n",
    "    print(\"         di un uso responsabile e maturo dell'intelligenza artificiale?'\")\n",
    "    print(\"         (1 = Per niente fiducioso ... 7 = Estremamente fiducioso)\")\n",
    "    \n",
    "    # Estrai dati\n",
    "    df_ins = DF_plot[DF_plot['GruppoDettaglio'].isin(['insegnanti - non in servizio', 'insegnanti - in servizio'])].copy()\n",
    "    df_ins = df_ins[[col, 'GruppoDettaglio']].dropna()\n",
    "    df_ins[col] = pd.to_numeric(df_ins[col], errors='coerce')\n",
    "    df_ins = df_ins.dropna()\n",
    "    \n",
    "    # Dati per gruppo\n",
    "    non_servizio = df_ins[df_ins['GruppoDettaglio'] == 'insegnanti - non in servizio'][col].values\n",
    "    in_servizio = df_ins[df_ins['GruppoDettaglio'] == 'insegnanti - in servizio'][col].values\n",
    "    \n",
    "    # Statistiche descrittive complete\n",
    "    print(f\"\\n{'─'*86}\")\n",
    "    print(\"📊 STATISTICHE DESCRITTIVE\")\n",
    "    print(f\"{'─'*86}\")\n",
    "    \n",
    "    print(f\"\\n  Insegnanti NON IN SERVIZIO (N = {len(non_servizio)}):\")\n",
    "    print(f\"    Media:    {np.mean(non_servizio):.2f}\")\n",
    "    print(f\"    Mediana:  {np.median(non_servizio):.2f}\")\n",
    "    print(f\"    Dev.Std:  {np.std(non_servizio, ddof=1):.2f}\")\n",
    "    print(f\"    Min-Max:  {np.min(non_servizio):.0f} - {np.max(non_servizio):.0f}\")\n",
    "    \n",
    "    print(f\"\\n  Insegnanti IN SERVIZIO (N = {len(in_servizio)}):\")\n",
    "    print(f\"    Media:    {np.mean(in_servizio):.2f}\")\n",
    "    print(f\"    Mediana:  {np.median(in_servizio):.2f}\")\n",
    "    print(f\"    Dev.Std:  {np.std(in_servizio, ddof=1):.2f}\")\n",
    "    print(f\"    Min-Max:  {np.min(in_servizio):.0f} - {np.max(in_servizio):.0f}\")\n",
    "    \n",
    "    # Differenza\n",
    "    diff = np.mean(non_servizio) - np.mean(in_servizio)\n",
    "    print(f\"\\n  Differenza (non servizio - in servizio): {diff:+.2f}\")\n",
    "    \n",
    "    # Test di Levene per omogeneità delle varianze\n",
    "    lev_stat, lev_p = levene(non_servizio, in_servizio)\n",
    "    print(f\"\\n{'─'*86}\")\n",
    "    print(\"📊 TEST DI OMOGENEITÀ VARIANZE (Levene)\")\n",
    "    print(f\"{'─'*86}\")\n",
    "    print(f\"  Statistica: {lev_stat:.3f}\")\n",
    "    print(f\"  p-value:    {lev_p:.4f}\")\n",
    "    print(f\"  Risultato:  {'Varianze omogenee' if lev_p > 0.05 else 'Varianze NON omogenee'}\")\n",
    "    \n",
    "    # T-test\n",
    "    t_stat, p_val = ttest_ind(non_servizio, in_servizio)\n",
    "    \n",
    "    # Cohen's d\n",
    "    n1, n2 = len(non_servizio), len(in_servizio)\n",
    "    var1, var2 = np.var(non_servizio, ddof=1), np.var(in_servizio, ddof=1)\n",
    "    pooled_std = np.sqrt(((n1-1)*var1 + (n2-1)*var2) / (n1+n2-2))\n",
    "    d = diff / pooled_std\n",
    "    \n",
    "    print(f\"\\n{'─'*86}\")\n",
    "    print(\"📊 TEST T DI STUDENT\")\n",
    "    print(f\"{'─'*86}\")\n",
    "    print(f\"  t-statistic: {t_stat:.3f}\")\n",
    "    print(f\"  p-value:     {p_val:.4f}\")\n",
    "    \n",
    "    if p_val < 0.001:\n",
    "        sig = \"*** ALTAMENTE SIGNIFICATIVO\"\n",
    "    elif p_val < 0.01:\n",
    "        sig = \"** MOLTO SIGNIFICATIVO\"\n",
    "    elif p_val < 0.05:\n",
    "        sig = \"* SIGNIFICATIVO\"\n",
    "    elif p_val < 0.10:\n",
    "        sig = \"(·) MARGINALMENTE SIGNIFICATIVO\"\n",
    "    else:\n",
    "        sig = \"NON SIGNIFICATIVO\"\n",
    "    \n",
    "    print(f\"  Significatività: {sig}\")\n",
    "    print(f\"\\n  Cohen's d:   {d:.3f}\")\n",
    "    \n",
    "    if abs(d) < 0.2:\n",
    "        effect_label = \"TRASCURABILE\"\n",
    "    elif abs(d) < 0.5:\n",
    "        effect_label = \"PICCOLO\"\n",
    "    elif abs(d) < 0.8:\n",
    "        effect_label = \"MEDIO\"\n",
    "    else:\n",
    "        effect_label = \"GRANDE\"\n",
    "    \n",
    "    print(f\"  Effect size: {effect_label}\")\n",
    "    \n",
    "    print(f\"\\n{'─'*86}\")\n",
    "    print(\"💡 INTERPRETAZIONE\")\n",
    "    print(f\"{'─'*86}\")\n",
    "    if p_val >= 0.05:\n",
    "        print(\"  ❌ NON ci sono differenze statisticamente significative tra i due gruppi.\")\n",
    "        print(f\"     Entrambi i gruppi hanno un livello SIMILE di fiducia negli studenti.\")\n",
    "        print(f\"     (Fiducia media: ~{np.mean(df_ins[col]):.2f} su scala 1-7, quindi BASSA)\")\n",
    "    else:\n",
    "        print(f\"  ✅ CI SONO differenze statisticamente significative (p = {p_val:.4f})!\")\n",
    "        if diff > 0:\n",
    "            print(f\"     Gli insegnanti NON in servizio hanno PIÙ fiducia (+{diff:.2f} punti)\")\n",
    "        else:\n",
    "            print(f\"     Gli insegnanti IN servizio hanno PIÙ fiducia (+{abs(diff):.2f} punti)\")\n",
    "\n",
    "# === ANALISI 2: PREOCCUPAZIONE USO IA ===\n",
    "if domanda_preoccupazione:\n",
    "    col = domanda_preoccupazione['col']\n",
    "    \n",
    "    print(\"\\n\\n\" + \"=\"*90)\n",
    "    print(\"2️⃣  PREOCCUPAZIONE SULL'USO IA DA PARTE DEGLI STUDENTI\")\n",
    "    print(\"=\"*90)\n",
    "    print(\"\\nDomanda: 'Quanto sei preoccupato riguardo all'utilizzo dell'intelligenza\")\n",
    "    print(\"         artificiale da parte degli studenti?'\")\n",
    "    print(\"         (1 = Per niente preoccupato ... 7 = Estremamente preoccupato)\")\n",
    "    \n",
    "    # Estrai dati\n",
    "    df_ins = DF_plot[DF_plot['GruppoDettaglio'].isin(['insegnanti - non in servizio', 'insegnanti - in servizio'])].copy()\n",
    "    df_ins = df_ins[[col, 'GruppoDettaglio']].dropna()\n",
    "    df_ins[col] = pd.to_numeric(df_ins[col], errors='coerce')\n",
    "    df_ins = df_ins.dropna()\n",
    "    \n",
    "    # Dati per gruppo\n",
    "    non_servizio = df_ins[df_ins['GruppoDettaglio'] == 'insegnanti - non in servizio'][col].values\n",
    "    in_servizio = df_ins[df_ins['GruppoDettaglio'] == 'insegnanti - in servizio'][col].values\n",
    "    \n",
    "    # Statistiche descrittive complete\n",
    "    print(f\"\\n{'─'*86}\")\n",
    "    print(\"📊 STATISTICHE DESCRITTIVE\")\n",
    "    print(f\"{'─'*86}\")\n",
    "    \n",
    "    print(f\"\\n  Insegnanti NON IN SERVIZIO (N = {len(non_servizio)}):\")\n",
    "    print(f\"    Media:    {np.mean(non_servizio):.2f}\")\n",
    "    print(f\"    Mediana:  {np.median(non_servizio):.2f}\")\n",
    "    print(f\"    Dev.Std:  {np.std(non_servizio, ddof=1):.2f}\")\n",
    "    print(f\"    Min-Max:  {np.min(non_servizio):.0f} - {np.max(non_servizio):.0f}\")\n",
    "    \n",
    "    print(f\"\\n  Insegnanti IN SERVIZIO (N = {len(in_servizio)}):\")\n",
    "    print(f\"    Media:    {np.mean(in_servizio):.2f}\")\n",
    "    print(f\"    Mediana:  {np.median(in_servizio):.2f}\")\n",
    "    print(f\"    Dev.Std:  {np.std(in_servizio, ddof=1):.2f}\")\n",
    "    print(f\"    Min-Max:  {np.min(in_servizio):.0f} - {np.max(in_servizio):.0f}\")\n",
    "    \n",
    "    # Differenza\n",
    "    diff = np.mean(non_servizio) - np.mean(in_servizio)\n",
    "    print(f\"\\n  Differenza (non servizio - in servizio): {diff:+.2f}\")\n",
    "    \n",
    "    # Test di Levene\n",
    "    lev_stat, lev_p = levene(non_servizio, in_servizio)\n",
    "    print(f\"\\n{'─'*86}\")\n",
    "    print(\"📊 TEST DI OMOGENEITÀ VARIANZE (Levene)\")\n",
    "    print(f\"{'─'*86}\")\n",
    "    print(f\"  Statistica: {lev_stat:.3f}\")\n",
    "    print(f\"  p-value:    {lev_p:.4f}\")\n",
    "    print(f\"  Risultato:  {'Varianze omogenee' if lev_p > 0.05 else 'Varianze NON omogenee'}\")\n",
    "    \n",
    "    # T-test\n",
    "    t_stat, p_val = ttest_ind(non_servizio, in_servizio)\n",
    "    \n",
    "    # Cohen's d\n",
    "    n1, n2 = len(non_servizio), len(in_servizio)\n",
    "    var1, var2 = np.var(non_servizio, ddof=1), np.var(in_servizio, ddof=1)\n",
    "    pooled_std = np.sqrt(((n1-1)*var1 + (n2-1)*var2) / (n1+n2-2))\n",
    "    d = diff / pooled_std\n",
    "    \n",
    "    print(f\"\\n{'─'*86}\")\n",
    "    print(\"📊 TEST T DI STUDENT\")\n",
    "    print(f\"{'─'*86}\")\n",
    "    print(f\"  t-statistic: {t_stat:.3f}\")\n",
    "    print(f\"  p-value:     {p_val:.4f}\")\n",
    "    \n",
    "    if p_val < 0.001:\n",
    "        sig = \"*** ALTAMENTE SIGNIFICATIVO\"\n",
    "    elif p_val < 0.01:\n",
    "        sig = \"** MOLTO SIGNIFICATIVO\"\n",
    "    elif p_val < 0.05:\n",
    "        sig = \"* SIGNIFICATIVO\"\n",
    "    elif p_val < 0.10:\n",
    "        sig = \"(·) MARGINALMENTE SIGNIFICATIVO\"\n",
    "    else:\n",
    "        sig = \"NON SIGNIFICATIVO\"\n",
    "    \n",
    "    print(f\"  Significatività: {sig}\")\n",
    "    print(f\"\\n  Cohen's d:   {d:.3f}\")\n",
    "    \n",
    "    if abs(d) < 0.2:\n",
    "        effect_label = \"TRASCURABILE\"\n",
    "    elif abs(d) < 0.5:\n",
    "        effect_label = \"PICCOLO\"\n",
    "    elif abs(d) < 0.8:\n",
    "        effect_label = \"MEDIO\"\n",
    "    else:\n",
    "        effect_label = \"GRANDE\"\n",
    "    \n",
    "    print(f\"  Effect size: {effect_label}\")\n",
    "    \n",
    "    print(f\"\\n{'─'*86}\")\n",
    "    print(\"💡 INTERPRETAZIONE\")\n",
    "    print(f\"{'─'*86}\")\n",
    "    if p_val >= 0.05:\n",
    "        print(\"  ❌ NON ci sono differenze statisticamente significative tra i due gruppi.\")\n",
    "        print(f\"     Entrambi i gruppi hanno un livello SIMILE di preoccupazione.\")\n",
    "        print(f\"     (Preoccupazione media: ~{np.mean(df_ins[col]):.2f} su scala 1-7, quindi MODERATA)\")\n",
    "    else:\n",
    "        print(f\"  ✅ CI SONO differenze statisticamente significative (p = {p_val:.4f})!\")\n",
    "        if diff > 0:\n",
    "            print(f\"     Gli insegnanti NON in servizio sono PIÙ preoccupati (+{diff:.2f} punti)\")\n",
    "        else:\n",
    "            print(f\"     Gli insegnanti IN servizio sono PIÙ preoccupati (+{abs(diff):.2f} punti)\")\n",
    "\n",
    "# === RIEPILOGO FINALE ===\n",
    "print(\"\\n\\n\" + \"=\"*90)\n",
    "print(\"🎯 RIEPILOGO FINALE\")\n",
    "print(\"=\"*90)\n",
    "print(\"\\n📌 Le due domande sono legate:\")\n",
    "print(\"   • Bassa FIDUCIA nell'uso responsabile\")\n",
    "print(\"   • Alta PREOCCUPAZIONE sull'uso IA\")\n",
    "print(\"\\n📌 Risultato:\")\n",
    "print(\"   ❌ NON ci sono differenze significative tra insegnanti in servizio e non\")\n",
    "print(\"   ✅ Entrambi i gruppi condividono:\")\n",
    "print(\"      - BASSA fiducia negli studenti (~3.2-3.5 su 7)\")\n",
    "print(\"      - ALTA preoccupazione (~4.6-4.7 su 7)\")\n",
    "print(\"\\n💡 Conclusione: È un atteggiamento TRASVERSALE al mondo degli insegnanti,\")\n",
    "print(\"   indipendentemente dal fatto che siano già in servizio o meno.\")\n",
    "print(\"=\"*90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309d432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === GRAFICI A VIOLINO: DOMANDE SOLO STUDENTI ===\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"GRAFICI A VIOLINO: DOMANDE SOLO STUDENTI\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Solo i 2 gruppi di studenti\n",
    "order_studenti = ['studenti - secondaria', 'studenti - universitari']\n",
    "palette_studenti = {\n",
    "    'studenti - secondaria': palette_4groups['studenti - secondaria'],\n",
    "    'studenti - universitari': palette_4groups['studenti - universitari']\n",
    "}\n",
    "\n",
    "for q in solo_studenti:\n",
    "    col = q['col']\n",
    "    label_it = q['label_it']\n",
    "    label_en = q['label_en']\n",
    "    tema = q['tema']\n",
    "    \n",
    "    if col not in DF_plot.columns:\n",
    "        print(f\"\\n⚠️ Colonna non trovata: {label_it}\")\n",
    "        continue\n",
    "    \n",
    "    # Prepara dati - solo studenti\n",
    "    df_temp = DF_plot[DF_plot['GruppoDettaglio'].isin(order_studenti)].copy()\n",
    "    df_temp = df_temp[[col, 'GruppoDettaglio']].dropna()\n",
    "    \n",
    "    if len(df_temp) == 0:\n",
    "        print(f\"\\n⚠️ Nessun dato per: {label_it}\")\n",
    "        continue\n",
    "        \n",
    "    df_vis = df_temp.copy()\n",
    "    df_vis.columns = ['valore', 'GruppoDettaglio']\n",
    "    # Rimuovi categorie non usate e riordina\n",
    "    df_vis['GruppoDettaglio'] = pd.Categorical(\n",
    "        df_vis['GruppoDettaglio'], \n",
    "        categories=order_studenti, \n",
    "        ordered=True\n",
    "    )\n",
    "    \n",
    "    # Statistiche\n",
    "    stats = df_vis.groupby('GruppoDettaglio', observed=True)['valore'].agg(['count', 'mean', 'median', 'std', 'min', 'max'])\n",
    "    stats.columns = ['N', 'Media', 'Mediana', 'SD', 'Min', 'Max']\n",
    "    \n",
    "    print(f\"\\n{'─'*86}\")\n",
    "    print(f\"📊 {label_it}\")\n",
    "    print(f\"{'─'*86}\")\n",
    "    print(f\"\\n  Statistiche per gruppo:\")\n",
    "    print(stats.to_string())\n",
    "    \n",
    "    # Crea grafico doppio (IT + EN)\n",
    "    fig, (ax_it, ax_en) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # ITALIANO\n",
    "    sns.violinplot(\n",
    "        data=df_vis,\n",
    "        x='GruppoDettaglio',\n",
    "        y='valore',\n",
    "        hue='GruppoDettaglio',\n",
    "        palette=palette_studenti,\n",
    "        ax=ax_it,\n",
    "        legend=False,\n",
    "        inner='box'\n",
    "    )\n",
    "    ax_it.set_xlabel('Gruppo', fontsize=11)\n",
    "    ax_it.set_ylabel('Punteggio (scala 1-7)', fontsize=11)\n",
    "    ax_it.set_title(f'{label_it}\\n(scala Likert 1-7)', fontsize=12, weight='bold')\n",
    "    ax_it.set_ylim(0.5, 7.5)\n",
    "    ax_it.set_xticklabels(ax_it.get_xticklabels(), rotation=15, ha='right')\n",
    "    ax_it.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # INGLESE\n",
    "    order_en_stu = ['students - secondary', 'students - university']\n",
    "    df_vis_en = df_vis.copy()\n",
    "    df_vis_en['GruppoDettaglio'] = df_vis_en['GruppoDettaglio'].cat.rename_categories({\n",
    "        'studenti - secondaria': 'students - secondary',\n",
    "        'studenti - universitari': 'students - university'\n",
    "    })\n",
    "    palette_en_stu = {\n",
    "        'students - secondary': palette_studenti['studenti - secondaria'],\n",
    "        'students - university': palette_studenti['studenti - universitari']\n",
    "    }\n",
    "    \n",
    "    sns.violinplot(\n",
    "        data=df_vis_en,\n",
    "        x='GruppoDettaglio',\n",
    "        y='valore',\n",
    "        hue='GruppoDettaglio',\n",
    "        palette=palette_en_stu,\n",
    "        ax=ax_en,\n",
    "        legend=False,\n",
    "        inner='box'\n",
    "    )\n",
    "    ax_en.set_xlabel('Group', fontsize=11)\n",
    "    ax_en.set_ylabel('Score (1-7 scale)', fontsize=11)\n",
    "    ax_en.set_title(f'{label_en}\\n(Likert scale 1-7)', fontsize=12, weight='bold')\n",
    "    ax_en.set_ylim(0.5, 7.5)\n",
    "    ax_en.set_xticklabels(ax_en.get_xticklabels(), rotation=15, ha='right')\n",
    "    ax_en.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salva\n",
    "    out_it = OUT_EXPL / f'likert_{tema}_studenti_it.png'\n",
    "    out_en = OUT_EXPL / f'likert_{tema}_studenti_en.png'\n",
    "    \n",
    "    fig.savefig(out_it, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\n  ✓ Salvato: {out_it}\")\n",
    "    \n",
    "    fig.savefig(out_en, dpi=300, bbox_inches='tight')\n",
    "    print(f\"  ✓ Salvato: {out_en}\")\n",
    "    \n",
    "plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "print(f\"\\n{'='*90}\")\n",
    "print(f\"✓ Grafici studenti completati!\")\n",
    "print(f\"{'='*90}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678140ef",
   "metadata": {},
   "source": [
    "---\n",
    "## 🔍 Confronto Preoccupazione: Insegnanti vs Studenti (4 gruppi)\n",
    "\n",
    "Analizziamo la **preoccupazione generale** sull'inserimento dell'IA nell'educazione confrontando:\n",
    "- I 4 gruppi principali (studenti-secondaria, studenti-universitari, insegnanti-non servizio, insegnanti-in servizio)\n",
    "- Differenze tra studenti e insegnanti\n",
    "- Differenze interne ai sottogruppi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe777faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ANALISI PREOCCUPAZIONE GENERALE: CONFRONTO TRA TUTTI I GRUPPI ===\n",
    "\n",
    "from scipy.stats import f_oneway, kruskal, ttest_ind\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(\"ANALISI PREOCCUPAZIONE GENERALE SULL'IA NELL'EDUCAZIONE\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Trova la domanda sulla preoccupazione generale\n",
    "# Cerca direttamente nel dizionario found_questions\n",
    "col_preoccupazione_ins = found_questions.get('preoccupazione_educazione_ins')\n",
    "col_preoccupazione_stu = found_questions.get('preoccupazione_scuola_stu')\n",
    "\n",
    "if col_preoccupazione_ins and col_preoccupazione_stu:\n",
    "    print(f\"\\n✓ Domanda insegnanti: {col_preoccupazione_ins}\")\n",
    "    print(f\"✓ Domanda studenti: {col_preoccupazione_stu}\")\n",
    "    \n",
    "    # Prepara i dati per tutti i 4 gruppi\n",
    "    df_analisi = DF_plot[['GruppoDettaglio', col_preoccupazione_ins, col_preoccupazione_stu]].copy()\n",
    "    \n",
    "    # Crea una colonna unificata con la preoccupazione\n",
    "    df_analisi['Preoccupazione'] = np.nan\n",
    "    \n",
    "    # Per gli insegnanti, usa la domanda insegnanti\n",
    "    mask_ins = df_analisi['GruppoDettaglio'].str.contains('insegnanti', case=False, na=False)\n",
    "    df_analisi.loc[mask_ins, 'Preoccupazione'] = pd.to_numeric(\n",
    "        df_analisi.loc[mask_ins, col_preoccupazione_ins], errors='coerce'\n",
    "    )\n",
    "    \n",
    "    # Per gli studenti, usa la domanda studenti\n",
    "    mask_stu = df_analisi['GruppoDettaglio'].str.contains('studenti', case=False, na=False)\n",
    "    df_analisi.loc[mask_stu, 'Preoccupazione'] = pd.to_numeric(\n",
    "        df_analisi.loc[mask_stu, col_preoccupazione_stu], errors='coerce'\n",
    "    )\n",
    "    \n",
    "    # Rimuovi i valori mancanti\n",
    "    df_analisi = df_analisi[['GruppoDettaglio', 'Preoccupazione']].dropna()\n",
    "    \n",
    "    print(f\"\\n📊 Campione totale: N = {len(df_analisi)}\")\n",
    "    \n",
    "    # ===== 1. STATISTICHE DESCRITTIVE PER TUTTI I 4 GRUPPI =====\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"1. STATISTICHE DESCRITTIVE PER GRUPPO\")\n",
    "    print(\"=\"*90)\n",
    "    \n",
    "    stats_preoccupazione = []\n",
    "    \n",
    "    for gruppo in ORDER_4:\n",
    "        dati = df_analisi[df_analisi['GruppoDettaglio'] == gruppo]['Preoccupazione'].values\n",
    "        \n",
    "        if len(dati) > 0:\n",
    "            stats_preoccupazione.append({\n",
    "                'Gruppo': gruppo,\n",
    "                'N': len(dati),\n",
    "                'Media': np.mean(dati),\n",
    "                'Mediana': np.median(dati),\n",
    "                'SD': np.std(dati, ddof=1),\n",
    "                'Min': np.min(dati),\n",
    "                'Max': np.max(dati)\n",
    "            })\n",
    "            \n",
    "            print(f\"\\n{gruppo}:\")\n",
    "            print(f\"  N = {len(dati)}\")\n",
    "            print(f\"  Media = {np.mean(dati):.2f}\")\n",
    "            print(f\"  Mediana = {np.median(dati):.0f}\")\n",
    "            print(f\"  SD = {np.std(dati, ddof=1):.2f}\")\n",
    "            print(f\"  Range = {np.min(dati):.0f} - {np.max(dati):.0f}\")\n",
    "    \n",
    "    df_stats_preocc = pd.DataFrame(stats_preoccupazione)\n",
    "    \n",
    "    # ===== 2. ANOVA TRA I 4 GRUPPI =====\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"2. ANOVA: CONFRONTO TRA TUTTI I 4 GRUPPI\")\n",
    "    print(\"=\"*90)\n",
    "    \n",
    "    # Estrai i dati per gruppo\n",
    "    gruppo_dati = []\n",
    "    for gruppo in ORDER_4:\n",
    "        dati = df_analisi[df_analisi['GruppoDettaglio'] == gruppo]['Preoccupazione'].values\n",
    "        gruppo_dati.append(dati)\n",
    "    \n",
    "    # ANOVA\n",
    "    f_stat, p_anova = f_oneway(*gruppo_dati)\n",
    "    \n",
    "    print(f\"\\nF-statistic = {f_stat:.3f}\")\n",
    "    print(f\"p-value = {p_anova:.6f}\")\n",
    "    \n",
    "    if p_anova < 0.001:\n",
    "        sig_anova = \"*** (p < 0.001)\"\n",
    "    elif p_anova < 0.01:\n",
    "        sig_anova = \"** (p < 0.01)\"\n",
    "    elif p_anova < 0.05:\n",
    "        sig_anova = \"* (p < 0.05)\"\n",
    "    else:\n",
    "        sig_anova = \"ns (p ≥ 0.05)\"\n",
    "    \n",
    "    print(f\"Significatività: {sig_anova}\")\n",
    "    \n",
    "    if p_anova < 0.05:\n",
    "        print(\"\\n✓ Ci sono DIFFERENZE SIGNIFICATIVE tra i 4 gruppi\")\n",
    "    else:\n",
    "        print(\"\\n✗ NON ci sono differenze significative tra i 4 gruppi\")\n",
    "    \n",
    "    # ===== 3. CONFRONTO MACRO: STUDENTI vs INSEGNANTI =====\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"3. CONFRONTO MACRO: TUTTI GLI STUDENTI vs TUTTI GLI INSEGNANTI\")\n",
    "    print(\"=\"*90)\n",
    "    \n",
    "    # Dati studenti (secondaria + universitari)\n",
    "    studenti_data = df_analisi[df_analisi['GruppoDettaglio'].str.contains('studenti', case=False, na=False)]['Preoccupazione'].values\n",
    "    \n",
    "    # Dati insegnanti (non in servizio + in servizio)\n",
    "    insegnanti_data = df_analisi[df_analisi['GruppoDettaglio'].str.contains('insegnanti', case=False, na=False)]['Preoccupazione'].values\n",
    "    \n",
    "    print(f\"\\nStudenti: N = {len(studenti_data)}, M = {np.mean(studenti_data):.2f}, SD = {np.std(studenti_data, ddof=1):.2f}\")\n",
    "    print(f\"Insegnanti: N = {len(insegnanti_data)}, M = {np.mean(insegnanti_data):.2f}, SD = {np.std(insegnanti_data, ddof=1):.2f}\")\n",
    "    \n",
    "    diff_macro = np.mean(studenti_data) - np.mean(insegnanti_data)\n",
    "    print(f\"\\nDifferenza: Δ = {diff_macro:+.2f}\")\n",
    "    \n",
    "    # T-test\n",
    "    t_macro, p_macro = ttest_ind(studenti_data, insegnanti_data)\n",
    "    \n",
    "    # Cohen's d\n",
    "    def cohens_d(group1, group2):\n",
    "        n1, n2 = len(group1), len(group2)\n",
    "        var1, var2 = np.var(group1, ddof=1), np.var(group2, ddof=1)\n",
    "        pooled_std = np.sqrt(((n1-1)*var1 + (n2-1)*var2) / (n1+n2-2))\n",
    "        return (np.mean(group1) - np.mean(group2)) / pooled_std\n",
    "    \n",
    "    d_macro = cohens_d(studenti_data, insegnanti_data)\n",
    "    \n",
    "    print(f\"\\nT-test: t = {t_macro:.3f}, p = {p_macro:.6f}\")\n",
    "    print(f\"Cohen's d = {d_macro:.3f}\")\n",
    "    \n",
    "    if abs(d_macro) < 0.2:\n",
    "        effect_macro = \"trascurabile\"\n",
    "    elif abs(d_macro) < 0.5:\n",
    "        effect_macro = \"piccolo\"\n",
    "    elif abs(d_macro) < 0.8:\n",
    "        effect_macro = \"medio\"\n",
    "    else:\n",
    "        effect_macro = \"grande\"\n",
    "    \n",
    "    print(f\"Effect size: {effect_macro}\")\n",
    "    \n",
    "    if p_macro < 0.001:\n",
    "        sig_macro = \"***\"\n",
    "        print(\"\\n✓ Differenza ALTAMENTE SIGNIFICATIVA tra studenti e insegnanti\")\n",
    "    elif p_macro < 0.01:\n",
    "        sig_macro = \"**\"\n",
    "        print(\"\\n✓ Differenza MOLTO SIGNIFICATIVA tra studenti e insegnanti\")\n",
    "    elif p_macro < 0.05:\n",
    "        sig_macro = \"*\"\n",
    "        print(\"\\n✓ Differenza SIGNIFICATIVA tra studenti e insegnanti\")\n",
    "    else:\n",
    "        sig_macro = \"ns\"\n",
    "        print(\"\\n✗ NON ci sono differenze significative tra studenti e insegnanti\")\n",
    "    \n",
    "    # ===== 4. POST-HOC: CONFRONTI A COPPIE =====\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"4. POST-HOC: CONFRONTI A COPPIE TRA I 4 GRUPPI\")\n",
    "    print(\"=\"*90)\n",
    "    \n",
    "    posthoc_preocc = []\n",
    "    \n",
    "    for i, grp1 in enumerate(ORDER_4):\n",
    "        for j, grp2 in enumerate(ORDER_4):\n",
    "            if i < j:  # Evita confronti duplicati\n",
    "                data1 = df_analisi[df_analisi['GruppoDettaglio'] == grp1]['Preoccupazione'].values\n",
    "                data2 = df_analisi[df_analisi['GruppoDettaglio'] == grp2]['Preoccupazione'].values\n",
    "                \n",
    "                if len(data1) >= 3 and len(data2) >= 3:\n",
    "                    mean1 = np.mean(data1)\n",
    "                    mean2 = np.mean(data2)\n",
    "                    diff = mean1 - mean2\n",
    "                    \n",
    "                    t, p = ttest_ind(data1, data2)\n",
    "                    d = cohens_d(data1, data2)\n",
    "                    \n",
    "                    if p < 0.001:\n",
    "                        sig = \"***\"\n",
    "                    elif p < 0.01:\n",
    "                        sig = \"**\"\n",
    "                    elif p < 0.05:\n",
    "                        sig = \"*\"\n",
    "                    else:\n",
    "                        sig = \"ns\"\n",
    "                    \n",
    "                    if abs(d) < 0.2:\n",
    "                        effect = \"trascurabile\"\n",
    "                    elif abs(d) < 0.5:\n",
    "                        effect = \"piccolo\"\n",
    "                    elif abs(d) < 0.8:\n",
    "                        effect = \"medio\"\n",
    "                    else:\n",
    "                        effect = \"grande\"\n",
    "                    \n",
    "                    posthoc_preocc.append({\n",
    "                        'Gruppo_1': grp1,\n",
    "                        'Gruppo_2': grp2,\n",
    "                        'M1': mean1,\n",
    "                        'M2': mean2,\n",
    "                        'Differenza': diff,\n",
    "                        't': t,\n",
    "                        'p': p,\n",
    "                        'sig': sig,\n",
    "                        'Cohen_d': d,\n",
    "                        'Effetto': effect\n",
    "                    })\n",
    "                    \n",
    "                    print(f\"\\n{grp1} vs {grp2}:\")\n",
    "                    print(f\"  M1 = {mean1:.2f}, M2 = {mean2:.2f}, Δ = {diff:+.2f}\")\n",
    "                    print(f\"  t = {t:.3f}, p = {p:.6f} {sig}\")\n",
    "                    print(f\"  Cohen's d = {d:.3f} ({effect})\")\n",
    "    \n",
    "    df_posthoc_preocc = pd.DataFrame(posthoc_preocc)\n",
    "    \n",
    "    # ===== 5. SINTESI E INTERPRETAZIONE =====\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"5. SINTESI E INTERPRETAZIONE\")\n",
    "    print(\"=\"*90)\n",
    "    \n",
    "    print(\"\\n📊 MEDIE PER GRUPPO (scala 1-7):\")\n",
    "    for _, row in df_stats_preocc.iterrows():\n",
    "        print(f\"  {row['Gruppo']}: M = {row['Media']:.2f} (SD = {row['SD']:.2f})\")\n",
    "    \n",
    "    print(f\"\\n🔍 ANOVA: F = {f_stat:.3f}, p = {p_anova:.6f} {sig_anova}\")\n",
    "    \n",
    "    print(f\"\\n📈 CONFRONTO MACRO:\")\n",
    "    print(f\"  Studenti:    M = {np.mean(studenti_data):.2f}\")\n",
    "    print(f\"  Insegnanti:  M = {np.mean(insegnanti_data):.2f}\")\n",
    "    print(f\"  Differenza:  Δ = {diff_macro:+.2f} {sig_macro}\")\n",
    "    print(f\"  Effect size: Cohen's d = {d_macro:.3f} ({effect_macro})\")\n",
    "    \n",
    "    # Trova i confronti più significativi\n",
    "    if len(df_posthoc_preocc) > 0:\n",
    "        sig_comparisons = df_posthoc_preocc[df_posthoc_preocc['sig'] != 'ns'].sort_values('p')\n",
    "        \n",
    "        if len(sig_comparisons) > 0:\n",
    "            print(\"\\n🎯 CONFRONTI SIGNIFICATIVI (post-hoc):\")\n",
    "            for _, row in sig_comparisons.iterrows():\n",
    "                print(f\"  {row['Gruppo_1']} vs {row['Gruppo_2']}: Δ = {row['Differenza']:+.2f} {row['sig']}, d = {row['Cohen_d']:.3f}\")\n",
    "        else:\n",
    "            print(\"\\n✗ Nessun confronto post-hoc significativo\")\n",
    "    \n",
    "    # Interpretazione finale\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"💡 INTERPRETAZIONE FINALE\")\n",
    "    print(\"=\"*90)\n",
    "    \n",
    "    if p_anova < 0.05:\n",
    "        print(\"\\n✓ Ci sono differenze significative nella preoccupazione tra i gruppi.\")\n",
    "        \n",
    "        # Chi è più preoccupato?\n",
    "        gruppo_max = df_stats_preocc.loc[df_stats_preocc['Media'].idxmax(), 'Gruppo']\n",
    "        media_max = df_stats_preocc['Media'].max()\n",
    "        gruppo_min = df_stats_preocc.loc[df_stats_preocc['Media'].idxmin(), 'Gruppo']\n",
    "        media_min = df_stats_preocc['Media'].min()\n",
    "        \n",
    "        print(f\"\\n  PIÙ PREOCCUPATI: {gruppo_max} (M = {media_max:.2f})\")\n",
    "        print(f\"  MENO PREOCCUPATI: {gruppo_min} (M = {media_min:.2f})\")\n",
    "        \n",
    "        if p_macro < 0.05:\n",
    "            if diff_macro > 0:\n",
    "                print(f\"\\n  → Gli STUDENTI sono significativamente PIÙ preoccupati degli insegnanti\")\n",
    "            else:\n",
    "                print(f\"\\n  → Gli INSEGNANTI sono significativamente PIÙ preoccupati degli studenti\")\n",
    "        else:\n",
    "            print(f\"\\n  → NON ci sono differenze significative tra studenti e insegnanti nel complesso\")\n",
    "            print(f\"    (le differenze sono principalmente tra sottogruppi)\")\n",
    "    else:\n",
    "        print(\"\\n✗ NON ci sono differenze significative nella preoccupazione tra i gruppi.\")\n",
    "        print(f\"  Tutti i gruppi mostrano un livello di preoccupazione simile (~{df_stats_preocc['Media'].mean():.1f}/7)\")\n",
    "    \n",
    "    # Salva risultati\n",
    "    csv_stats = OUT_EXPL / 'preoccupazione_stats_4gruppi.csv'\n",
    "    df_stats_preocc.to_csv(csv_stats, index=False)\n",
    "    print(f\"\\n✓ Statistiche salvate: {csv_stats}\")\n",
    "    \n",
    "    if len(df_posthoc_preocc) > 0:\n",
    "        csv_posthoc = OUT_EXPL / 'preoccupazione_posthoc_4gruppi.csv'\n",
    "        df_posthoc_preocc.to_csv(csv_posthoc, index=False)\n",
    "        print(f\"✓ Post-hoc salvato: {csv_posthoc}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n⚠️ Domanda sulla preoccupazione generale non trovata!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f19debe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === VISUALIZZAZIONE: PREOCCUPAZIONE PER GRUPPO ===\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(\"VISUALIZZAZIONE: VIOLIN PLOT PREOCCUPAZIONE GENERALE\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "if col_preoccupazione_ins and col_preoccupazione_stu:\n",
    "    # Prepara i dati - filtra solo i 4 gruppi principali\n",
    "    df_vis_preocc = df_analisi[df_analisi['GruppoDettaglio'].isin(ORDER_4)][['GruppoDettaglio', 'Preoccupazione']].copy()\n",
    "    \n",
    "    # === GRAFICO ITALIANO ===\n",
    "    fig_it, ax_it = plt.subplots(1, 1, figsize=(12, 7))\n",
    "    \n",
    "    # Create color list based on order\n",
    "    colors_ordered = [palette_4groups[g] for g in ORDER_4]\n",
    "    \n",
    "    sns.violinplot(\n",
    "        data=df_vis_preocc,\n",
    "        x='GruppoDettaglio',\n",
    "        y='Preoccupazione',\n",
    "        order=ORDER_4,\n",
    "        palette=colors_ordered,\n",
    "        ax=ax_it,\n",
    "        inner='box'\n",
    "    )\n",
    "    \n",
    "    ax_it.set_xlabel('Gruppo', fontsize=13, fontweight='bold')\n",
    "    ax_it.set_ylabel('Preoccupazione (scala 1-7)', fontsize=13, fontweight='bold')\n",
    "    ax_it.set_title('Preoccupazione generale sull\\'inserimento dell\\'IA nell\\'educazione', \n",
    "                    fontsize=15, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Aggiungi linee di riferimento\n",
    "    ax_it.axhline(y=4, color='gray', linestyle='--', alpha=0.5, linewidth=1)\n",
    "    ax_it.text(3.5, 4.1, 'Neutrale (4)', fontsize=9, color='gray', ha='right')\n",
    "    \n",
    "    # Ruota le etichette\n",
    "    ax_it.set_xticklabels(ax_it.get_xticklabels(), rotation=15, ha='right')\n",
    "    ax_it.grid(axis='y', alpha=0.3, linestyle=':')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salva\n",
    "    out_it_png = OUT_EXPL / 'preoccupazione_generale_4gruppi_it.png'\n",
    "    fig_it.savefig(out_it_png, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\n✓ Salvato: {out_it_png}\")\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close(fig_it)\n",
    "    \n",
    "    # === GRAFICO INGLESE ===\n",
    "    fig_en, ax_en = plt.subplots(1, 1, figsize=(12, 7))\n",
    "    \n",
    "    # Map dei nomi in inglese\n",
    "    df_vis_preocc_en = df_vis_preocc.copy()\n",
    "    map_en = {\n",
    "        'studenti - secondaria': 'students - secondary',\n",
    "        'studenti - universitari': 'students - university',\n",
    "        'insegnanti - non in servizio': 'teachers - pre-service',\n",
    "        'insegnanti - in servizio': 'teachers - in-service'\n",
    "    }\n",
    "    df_vis_preocc_en['Group'] = df_vis_preocc_en['GruppoDettaglio'].map(map_en)\n",
    "    order_en = [map_en[g] for g in ORDER_4]\n",
    "    palette_en = {map_en[k]: v for k, v in palette_4groups.items()}\n",
    "    \n",
    "    # Create color list based on order\n",
    "    colors_ordered_en = [palette_en[g] for g in order_en]\n",
    "    \n",
    "    sns.violinplot(\n",
    "        data=df_vis_preocc_en,\n",
    "        x='Group',\n",
    "        y='Preoccupazione',\n",
    "        order=order_en,\n",
    "        palette=colors_ordered_en,\n",
    "        ax=ax_en,\n",
    "        inner='box'\n",
    "    )\n",
    "    \n",
    "    ax_en.set_xlabel('Group', fontsize=13, fontweight='bold')\n",
    "    ax_en.set_ylabel('Concern (scale 1-7)', fontsize=13, fontweight='bold')\n",
    "    ax_en.set_title('General concern about AI integration in education', \n",
    "                    fontsize=15, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Aggiungi linee di riferimento\n",
    "    ax_en.axhline(y=4, color='gray', linestyle='--', alpha=0.5, linewidth=1)\n",
    "    ax_en.text(3.5, 4.1, 'Neutral (4)', fontsize=9, color='gray', ha='right')\n",
    "    \n",
    "    # Ruota le etichette\n",
    "    ax_en.set_xticklabels(ax_en.get_xticklabels(), rotation=15, ha='right')\n",
    "    ax_en.grid(axis='y', alpha=0.3, linestyle=':')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salva\n",
    "    out_en_png = OUT_EXPL / 'preoccupazione_generale_4gruppi_en.png'\n",
    "    fig_en.savefig(out_en_png, dpi=300, bbox_inches='tight')\n",
    "    print(f\"✓ Salvato: {out_en_png}\")\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close(fig_en)\n",
    "    \n",
    "    print(\"\\n✓ Grafici completati\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffe3638",
   "metadata": {},
   "source": [
    "---\n",
    "## 📋 Sintesi Finale: Differenze nella Preoccupazione tra Insegnanti e Studenti\n",
    "\n",
    "### 🎯 Risultati Principali\n",
    "\n",
    "**1. DIFFERENZE ALTAMENTE SIGNIFICATIVE TRA I 4 GRUPPI**\n",
    "- ANOVA: F = 19.723, p < 0.001 ***\n",
    "- Ci sono differenze molto significative nella preoccupazione generale sull'IA tra i 4 gruppi\n",
    "\n",
    "**2. CONFRONTO MACRO: INSEGNANTI vs STUDENTI**\n",
    "- **Studenti**: M = 3.31/7 (bassa preoccupazione)\n",
    "- **Insegnanti**: M = 4.24/7 (preoccupazione moderata)\n",
    "- **Differenza**: Δ = -0.93 punti\n",
    "- **Significatività**: p < 0.001 *** (altamente significativa)\n",
    "- **Effect size**: Cohen's d = -0.583 (effetto **medio**)\n",
    "\n",
    "**3. DETTAGLIO PER GRUPPO**\n",
    "- **Studenti secondaria**: M = 3.16 (i MENO preoccupati)\n",
    "- **Studenti universitari**: M = 3.39\n",
    "- **Insegnanti non in servizio**: M = 4.30 (i PIÙ preoccupati)\n",
    "- **Insegnanti in servizio**: M = 4.22\n",
    "\n",
    "**4. CONFRONTI POST-HOC SIGNIFICATIVI**\n",
    "\n",
    "Tutti i confronti **studenti vs insegnanti** sono altamente significativi (p < 0.001):\n",
    "- Studenti secondaria vs Insegnanti in servizio: Δ = -1.06, d = -0.662 (medio)\n",
    "- Studenti secondaria vs Insegnanti non servizio: Δ = -1.15, d = -0.731 (medio)\n",
    "- Studenti universitari vs Insegnanti in servizio: Δ = -0.84, d = -0.517 (medio)\n",
    "- Studenti universitari vs Insegnanti non servizio: Δ = -0.92, d = -0.575 (medio)\n",
    "\n",
    "I confronti **all'interno della stessa categoria** NON sono significativi:\n",
    "- Studenti secondaria vs universitari: p = 0.285 (ns)\n",
    "- Insegnanti non servizio vs in servizio: p = 0.641 (ns)\n",
    "\n",
    "### 💡 Interpretazione\n",
    "\n",
    "1. **Gli INSEGNANTI sono significativamente PIÙ PREOCCUPATI degli STUDENTI** riguardo l'inserimento dell'IA nell'educazione\n",
    "\n",
    "2. **La differenza è TRASVERSALE**: non dipende dal sottogruppo\n",
    "   - Tra studenti (secondaria vs universitari): nessuna differenza significativa\n",
    "   - Tra insegnanti (pre-service vs in-service): nessuna differenza significativa\n",
    "   \n",
    "3. **La differenza è di RUOLO**, non di esperienza:\n",
    "   - Tutti gli studenti hanno una preoccupazione bassa (~3.3/7)\n",
    "   - Tutti gli insegnanti hanno una preoccupazione moderata (~4.2/7)\n",
    "   - L'esperienza professionale (essere in servizio o meno) NON cambia il livello di preoccupazione\n",
    "\n",
    "4. **Effect size medio** (d ≈ 0.6): la differenza è statisticamente significativa e anche **praticamente rilevante**\n",
    "\n",
    "### 🔍 Implicazioni\n",
    "\n",
    "- La **preoccupazione** sull'IA è legata al **ruolo educativo** (insegnante vs studente), non all'esperienza o al livello di istruzione\n",
    "- Gli insegnanti potrebbero percepire maggiori rischi o responsabilità legate all'integrazione dell'IA\n",
    "- Gli studenti, essendo più giovani e \"nativi digitali\", potrebbero essere più aperti/meno preoccupati verso le nuove tecnologie\n",
    "- **Questa differenza di percezione** potrebbe influenzare l'adozione e l'uso dell'IA nelle pratiche educative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb43a64",
   "metadata": {},
   "source": [
    "---\n",
    "## 🔍 Analisi Fattori Demografici: Genere, Materia ed Età\n",
    "\n",
    "Verifichiamo se **genere**, **area disciplinare** (STEM vs Umanistica) ed **età** influenzano il livello di **preoccupazione** sull'IA nell'educazione, analizzando separatamente studenti e insegnanti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d78c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ANALISI FATTORI DEMOGRAFICI: GENERE, MATERIA, ETÀ ===\n",
    "\n",
    "from scipy.stats import ttest_ind, mannwhitneyu, pearsonr, spearmanr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(\"ANALISI INFLUENZA FATTORI DEMOGRAFICI SULLA PREOCCUPAZIONE\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "# Prepara dataset con tutte le variabili necessarie\n",
    "if col_preoccupazione_ins and col_preoccupazione_stu:\n",
    "    \n",
    "    # Colonne necessarie\n",
    "    cols_needed = ['GruppoDettaglio', 'Genere', 'Area']\n",
    "    \n",
    "    # Aggiungi colonna età se esiste\n",
    "    col_eta = None\n",
    "    for col in DF_plot.columns:\n",
    "        if 'età' in col.lower() or 'age' in col.lower() or 'eta' in col.lower():\n",
    "            col_eta = col\n",
    "            cols_needed.append(col)\n",
    "            break\n",
    "    \n",
    "    # Crea dataframe completo\n",
    "    df_demo = DF_plot[cols_needed + [col_preoccupazione_ins, col_preoccupazione_stu]].copy()\n",
    "    \n",
    "    # Unifica la colonna preoccupazione\n",
    "    df_demo['Preoccupazione'] = np.nan\n",
    "    \n",
    "    mask_ins = df_demo['GruppoDettaglio'].str.contains('insegnanti', case=False, na=False)\n",
    "    df_demo.loc[mask_ins, 'Preoccupazione'] = pd.to_numeric(\n",
    "        df_demo.loc[mask_ins, col_preoccupazione_ins], errors='coerce'\n",
    "    )\n",
    "    \n",
    "    mask_stu = df_demo['GruppoDettaglio'].str.contains('studenti', case=False, na=False)\n",
    "    df_demo.loc[mask_stu, 'Preoccupazione'] = pd.to_numeric(\n",
    "        df_demo.loc[mask_stu, col_preoccupazione_stu], errors='coerce'\n",
    "    )\n",
    "    \n",
    "    # Filtra solo i 4 gruppi principali\n",
    "    df_demo = df_demo[df_demo['GruppoDettaglio'].isin(ORDER_4)].copy()\n",
    "    \n",
    "    # Rimuovi valori mancanti per preoccupazione\n",
    "    df_demo = df_demo.dropna(subset=['Preoccupazione'])\n",
    "    \n",
    "    print(f\"\\n✓ Dataset preparato: N = {len(df_demo)}\")\n",
    "    print(f\"✓ Variabili disponibili: {cols_needed}\")\n",
    "    \n",
    "    # Separa studenti e insegnanti\n",
    "    df_studenti = df_demo[df_demo['GruppoDettaglio'].str.contains('studenti', case=False, na=False)].copy()\n",
    "    df_insegnanti = df_demo[df_demo['GruppoDettaglio'].str.contains('insegnanti', case=False, na=False)].copy()\n",
    "    \n",
    "    print(f\"\\n  Studenti: N = {len(df_studenti)}\")\n",
    "    print(f\"  Insegnanti: N = {len(df_insegnanti)}\")\n",
    "    \n",
    "    # ===================================================================\n",
    "    # 1. ANALISI GENERE\n",
    "    # ===================================================================\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"1. INFLUENZA DEL GENERE\")\n",
    "    print(\"=\"*90)\n",
    "    \n",
    "    risultati_genere = []\n",
    "    \n",
    "    for categoria, df_cat in [('Studenti', df_studenti), ('Insegnanti', df_insegnanti)]:\n",
    "        print(f\"\\n{'─'*86}\")\n",
    "        print(f\"📊 {categoria.upper()}\")\n",
    "        print(f\"{'─'*86}\")\n",
    "        \n",
    "        df_gen = df_cat[['Genere', 'Preoccupazione']].dropna()\n",
    "        \n",
    "        if len(df_gen) < 10:\n",
    "            print(f\"  ⚠️ Dati insufficienti\")\n",
    "            continue\n",
    "        \n",
    "        # Controlla quali generi sono presenti\n",
    "        generi_presenti = df_gen['Genere'].unique()\n",
    "        print(f\"\\n  Generi presenti: {list(generi_presenti)}\")\n",
    "        \n",
    "        # Statistiche per genere\n",
    "        for gen in generi_presenti:\n",
    "            dati_gen = df_gen[df_gen['Genere'] == gen]['Preoccupazione'].values\n",
    "            if len(dati_gen) > 0:\n",
    "                print(f\"\\n  {gen}: N = {len(dati_gen)}, M = {np.mean(dati_gen):.2f}, SD = {np.std(dati_gen, ddof=1):.2f}\")\n",
    "        \n",
    "        # T-test tra maschi e femmine (se presenti entrambi)\n",
    "        if 'M' in generi_presenti and 'F' in generi_presenti:\n",
    "            maschi = df_gen[df_gen['Genere'] == 'M']['Preoccupazione'].values\n",
    "            femmine = df_gen[df_gen['Genere'] == 'F']['Preoccupazione'].values\n",
    "            \n",
    "            if len(maschi) >= 3 and len(femmine) >= 3:\n",
    "                mean_m = np.mean(maschi)\n",
    "                mean_f = np.mean(femmine)\n",
    "                diff = mean_f - mean_m\n",
    "                \n",
    "                t_stat, p_val = ttest_ind(femmine, maschi)\n",
    "                \n",
    "                # Cohen's d\n",
    "                n1, n2 = len(femmine), len(maschi)\n",
    "                var1, var2 = np.var(femmine, ddof=1), np.var(maschi, ddof=1)\n",
    "                pooled_std = np.sqrt(((n1-1)*var1 + (n2-1)*var2) / (n1+n2-2))\n",
    "                d = (mean_f - mean_m) / pooled_std\n",
    "                \n",
    "                if p_val < 0.001:\n",
    "                    sig = \"***\"\n",
    "                elif p_val < 0.01:\n",
    "                    sig = \"**\"\n",
    "                elif p_val < 0.05:\n",
    "                    sig = \"*\"\n",
    "                else:\n",
    "                    sig = \"ns\"\n",
    "                \n",
    "                if abs(d) < 0.2:\n",
    "                    effect = \"trascurabile\"\n",
    "                elif abs(d) < 0.5:\n",
    "                    effect = \"piccolo\"\n",
    "                elif abs(d) < 0.8:\n",
    "                    effect = \"medio\"\n",
    "                else:\n",
    "                    effect = \"grande\"\n",
    "                \n",
    "                print(f\"\\n  CONFRONTO M vs F:\")\n",
    "                print(f\"    Maschi:   M = {mean_m:.2f}\")\n",
    "                print(f\"    Femmine:  M = {mean_f:.2f}\")\n",
    "                print(f\"    Differenza: Δ = {diff:+.2f}\")\n",
    "                print(f\"    T-test: t = {t_stat:.3f}, p = {p_val:.6f} {sig}\")\n",
    "                print(f\"    Cohen's d = {d:.3f} ({effect})\")\n",
    "                \n",
    "                risultati_genere.append({\n",
    "                    'Categoria': categoria,\n",
    "                    'N_M': len(maschi),\n",
    "                    'N_F': len(femmine),\n",
    "                    'M_maschi': mean_m,\n",
    "                    'M_femmine': mean_f,\n",
    "                    'Differenza': diff,\n",
    "                    't': t_stat,\n",
    "                    'p': p_val,\n",
    "                    'sig': sig,\n",
    "                    'Cohen_d': d,\n",
    "                    'Effetto': effect\n",
    "                })\n",
    "    \n",
    "    if risultati_genere:\n",
    "        df_risultati_genere = pd.DataFrame(risultati_genere)\n",
    "        csv_genere = OUT_EXPL / 'preoccupazione_genere_analisi.csv'\n",
    "        df_risultati_genere.to_csv(csv_genere, index=False)\n",
    "        print(f\"\\n✓ Risultati genere salvati: {csv_genere}\")\n",
    "    \n",
    "    # ===================================================================\n",
    "    # 2. ANALISI AREA DISCIPLINARE (STEM vs UMANISTICA)\n",
    "    # ===================================================================\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"2. INFLUENZA DELL'AREA DISCIPLINARE (STEM vs UMANISTICA)\")\n",
    "    print(\"=\"*90)\n",
    "    \n",
    "    risultati_area = []\n",
    "    \n",
    "    for categoria, df_cat in [('Studenti', df_studenti), ('Insegnanti', df_insegnanti)]:\n",
    "        print(f\"\\n{'─'*86}\")\n",
    "        print(f\"📊 {categoria.upper()}\")\n",
    "        print(f\"{'─'*86}\")\n",
    "        \n",
    "        df_area = df_cat[['Area', 'Preoccupazione']].dropna()\n",
    "        \n",
    "        if len(df_area) < 10:\n",
    "            print(f\"  ⚠️ Dati insufficienti\")\n",
    "            continue\n",
    "        \n",
    "        # Controlla quali aree sono presenti\n",
    "        aree_presenti = df_area['Area'].unique()\n",
    "        print(f\"\\n  Aree presenti: {list(aree_presenti)}\")\n",
    "        \n",
    "        # Statistiche per area\n",
    "        for area in aree_presenti:\n",
    "            dati_area = df_area[df_area['Area'] == area]['Preoccupazione'].values\n",
    "            if len(dati_area) > 0:\n",
    "                print(f\"\\n  {area}: N = {len(dati_area)}, M = {np.mean(dati_area):.2f}, SD = {np.std(dati_area, ddof=1):.2f}\")\n",
    "        \n",
    "        # T-test tra STEM e Umanistica (se presenti entrambe)\n",
    "        if 'STEM' in aree_presenti and 'Umanistica' in aree_presenti:\n",
    "            stem = df_area[df_area['Area'] == 'STEM']['Preoccupazione'].values\n",
    "            hum = df_area[df_area['Area'] == 'Umanistica']['Preoccupazione'].values\n",
    "            \n",
    "            if len(stem) >= 3 and len(hum) >= 3:\n",
    "                mean_stem = np.mean(stem)\n",
    "                mean_hum = np.mean(hum)\n",
    "                diff = mean_hum - mean_stem\n",
    "                \n",
    "                t_stat, p_val = ttest_ind(hum, stem)\n",
    "                \n",
    "                # Cohen's d\n",
    "                n1, n2 = len(hum), len(stem)\n",
    "                var1, var2 = np.var(hum, ddof=1), np.var(stem, ddof=1)\n",
    "                pooled_std = np.sqrt(((n1-1)*var1 + (n2-1)*var2) / (n1+n2-2))\n",
    "                d = (mean_hum - mean_stem) / pooled_std\n",
    "                \n",
    "                if p_val < 0.001:\n",
    "                    sig = \"***\"\n",
    "                elif p_val < 0.01:\n",
    "                    sig = \"**\"\n",
    "                elif p_val < 0.05:\n",
    "                    sig = \"*\"\n",
    "                else:\n",
    "                    sig = \"ns\"\n",
    "                \n",
    "                if abs(d) < 0.2:\n",
    "                    effect = \"trascurabile\"\n",
    "                elif abs(d) < 0.5:\n",
    "                    effect = \"piccolo\"\n",
    "                elif abs(d) < 0.8:\n",
    "                    effect = \"medio\"\n",
    "                else:\n",
    "                    effect = \"grande\"\n",
    "                \n",
    "                print(f\"\\n  CONFRONTO STEM vs UMANISTICA:\")\n",
    "                print(f\"    STEM:        M = {mean_stem:.2f}\")\n",
    "                print(f\"    Umanistica:  M = {mean_hum:.2f}\")\n",
    "                print(f\"    Differenza:  Δ = {diff:+.2f}\")\n",
    "                print(f\"    T-test: t = {t_stat:.3f}, p = {p_val:.6f} {sig}\")\n",
    "                print(f\"    Cohen's d = {d:.3f} ({effect})\")\n",
    "                \n",
    "                risultati_area.append({\n",
    "                    'Categoria': categoria,\n",
    "                    'N_STEM': len(stem),\n",
    "                    'N_Umanistica': len(hum),\n",
    "                    'M_STEM': mean_stem,\n",
    "                    'M_Umanistica': mean_hum,\n",
    "                    'Differenza': diff,\n",
    "                    't': t_stat,\n",
    "                    'p': p_val,\n",
    "                    'sig': sig,\n",
    "                    'Cohen_d': d,\n",
    "                    'Effetto': effect\n",
    "                })\n",
    "    \n",
    "    if risultati_area:\n",
    "        df_risultati_area = pd.DataFrame(risultati_area)\n",
    "        csv_area = OUT_EXPL / 'preoccupazione_area_analisi.csv'\n",
    "        df_risultati_area.to_csv(csv_area, index=False)\n",
    "        print(f\"\\n✓ Risultati area salvati: {csv_area}\")\n",
    "    \n",
    "    # ===================================================================\n",
    "    # 3. ANALISI ETÀ (CORRELAZIONE)\n",
    "    # ===================================================================\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"3. INFLUENZA DELL'ETÀ (CORRELAZIONE)\")\n",
    "    print(\"=\"*90)\n",
    "    \n",
    "    if col_eta:\n",
    "        risultati_eta = []\n",
    "        \n",
    "        for categoria, df_cat in [('Studenti', df_studenti), ('Insegnanti', df_insegnanti)]:\n",
    "            print(f\"\\n{'─'*86}\")\n",
    "            print(f\"📊 {categoria.upper()}\")\n",
    "            print(f\"{'─'*86}\")\n",
    "            \n",
    "            df_age = df_cat[[col_eta, 'Preoccupazione']].copy()\n",
    "            \n",
    "            # Converti età in numerico\n",
    "            df_age[col_eta] = pd.to_numeric(df_age[col_eta], errors='coerce')\n",
    "            df_age = df_age.dropna()\n",
    "            \n",
    "            if len(df_age) < 10:\n",
    "                print(f\"  ⚠️ Dati insufficienti\")\n",
    "                continue\n",
    "            \n",
    "            eta_values = df_age[col_eta].values\n",
    "            preocc_values = df_age['Preoccupazione'].values\n",
    "            \n",
    "            print(f\"\\n  N = {len(df_age)}\")\n",
    "            print(f\"  Età: M = {np.mean(eta_values):.1f}, SD = {np.std(eta_values, ddof=1):.1f}, Range = {np.min(eta_values):.0f}-{np.max(eta_values):.0f}\")\n",
    "            print(f\"  Preoccupazione: M = {np.mean(preocc_values):.2f}, SD = {np.std(preocc_values, ddof=1):.2f}\")\n",
    "            \n",
    "            # Correlazione di Pearson\n",
    "            r_pearson, p_pearson = pearsonr(eta_values, preocc_values)\n",
    "            \n",
    "            # Correlazione di Spearman (non parametrica)\n",
    "            r_spearman, p_spearman = spearmanr(eta_values, preocc_values)\n",
    "            \n",
    "            if p_pearson < 0.001:\n",
    "                sig_p = \"***\"\n",
    "            elif p_pearson < 0.01:\n",
    "                sig_p = \"**\"\n",
    "            elif p_pearson < 0.05:\n",
    "                sig_p = \"*\"\n",
    "            else:\n",
    "                sig_p = \"ns\"\n",
    "            \n",
    "            if p_spearman < 0.001:\n",
    "                sig_s = \"***\"\n",
    "            elif p_spearman < 0.01:\n",
    "                sig_s = \"**\"\n",
    "            elif p_spearman < 0.05:\n",
    "                sig_s = \"*\"\n",
    "            else:\n",
    "                sig_s = \"ns\"\n",
    "            \n",
    "            # Interpreta forza correlazione\n",
    "            if abs(r_pearson) < 0.1:\n",
    "                forza = \"trascurabile\"\n",
    "            elif abs(r_pearson) < 0.3:\n",
    "                forza = \"debole\"\n",
    "            elif abs(r_pearson) < 0.5:\n",
    "                forza = \"moderata\"\n",
    "            else:\n",
    "                forza = \"forte\"\n",
    "            \n",
    "            print(f\"\\n  CORRELAZIONE ETÀ - PREOCCUPAZIONE:\")\n",
    "            print(f\"    Pearson:  r = {r_pearson:+.3f}, p = {p_pearson:.6f} {sig_p}\")\n",
    "            print(f\"    Spearman: ρ = {r_spearman:+.3f}, p = {p_spearman:.6f} {sig_s}\")\n",
    "            print(f\"    Forza: {forza}\")\n",
    "            \n",
    "            if r_pearson > 0:\n",
    "                direzione = \"positiva (età maggiore → maggiore preoccupazione)\"\n",
    "            else:\n",
    "                direzione = \"negativa (età maggiore → minore preoccupazione)\"\n",
    "            print(f\"    Direzione: {direzione}\")\n",
    "            \n",
    "            risultati_eta.append({\n",
    "                'Categoria': categoria,\n",
    "                'N': len(df_age),\n",
    "                'M_età': np.mean(eta_values),\n",
    "                'SD_età': np.std(eta_values, ddof=1),\n",
    "                'r_Pearson': r_pearson,\n",
    "                'p_Pearson': p_pearson,\n",
    "                'sig_Pearson': sig_p,\n",
    "                'r_Spearman': r_spearman,\n",
    "                'p_Spearman': p_spearman,\n",
    "                'sig_Spearman': sig_s,\n",
    "                'Forza': forza,\n",
    "                'Direzione': direzione\n",
    "            })\n",
    "        \n",
    "        if risultati_eta:\n",
    "            df_risultati_eta = pd.DataFrame(risultati_eta)\n",
    "            csv_eta = OUT_EXPL / 'preoccupazione_eta_analisi.csv'\n",
    "            df_risultati_eta.to_csv(csv_eta, index=False)\n",
    "            print(f\"\\n✓ Risultati età salvati: {csv_eta}\")\n",
    "    else:\n",
    "        print(\"\\n⚠️ Colonna età non trovata nel dataset\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "\n",
    "else:\n",
    "    print(\"\\n⚠️ Domande sulla preoccupazione non trovate!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facfea12",
   "metadata": {},
   "source": [
    "---\n",
    "## 🔍 Analisi Fattori Demografici su TUTTE le Domande Likert\n",
    "\n",
    "Analizziamo l'influenza di **genere**, **area disciplinare (STEM/Umanistica)** e **età** su tutte le 16 domande Likert (scala 1-7).\n",
    "\n",
    "### Obiettivi:\n",
    "1. **Genere**: Differenze tra Maschi e Femmine\n",
    "2. **Area**: Differenze tra STEM e Umanistica\n",
    "3. **Età**: Correlazione tra età e risposte Likert\n",
    "\n",
    "Per ogni domanda Likert, testeremo se questi fattori influenzano significativamente le risposte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f13f901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ANALISI FATTORI DEMOGRAFICI SU TUTTE LE DOMANDE LIKERT ===\n",
    "\n",
    "from scipy.stats import ttest_ind, mannwhitneyu, spearmanr, pearsonr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"ANALISI FATTORI DEMOGRAFICI SU TUTTE LE DOMANDE LIKERT\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Usa il dizionario likert_questions già in memoria\n",
    "if 'likert_questions' in globals() and len(likert_questions) > 0:\n",
    "    print(f\"\\n✓ Trovate {len(likert_questions)} domande Likert in memoria\")\n",
    "    domande_likert_cols = list(likert_questions.keys())\n",
    "else:\n",
    "    print(\"\\n⚠️ Dizionario likert_questions non trovato!\")\n",
    "    domande_likert_cols = []\n",
    "\n",
    "# Prepara il dataframe con le variabili demografiche\n",
    "df_demo = DF_plot.copy()\n",
    "\n",
    "# Identifica le colonne demografiche\n",
    "col_genere = None\n",
    "col_area = None\n",
    "col_eta = None\n",
    "\n",
    "# Cerca colonna genere\n",
    "for col in df_demo.columns:\n",
    "    if 'genere' in col.lower() or 'gender' in col.lower() or 'sesso' in col.lower():\n",
    "        col_genere = col\n",
    "        break\n",
    "\n",
    "# Cerca colonna area/materia\n",
    "for col in df_demo.columns:\n",
    "    if 'area' in col.lower() or 'materia' in col.lower() or 'disciplin' in col.lower():\n",
    "        col_area = col\n",
    "        break\n",
    "\n",
    "# Cerca colonna età\n",
    "for col in df_demo.columns:\n",
    "    if 'età' in col.lower() or 'age' in col.lower() or 'eta' in col.lower():\n",
    "        col_eta = col\n",
    "        break\n",
    "\n",
    "print(f\"\\n📊 Variabili demografiche identificate:\")\n",
    "print(f\"  - Genere: {col_genere if col_genere else '❌ Non trovato'}\")\n",
    "print(f\"  - Area: {col_area if col_area else '❌ Non trovato'}\")\n",
    "print(f\"  - Età: {col_eta if col_eta else '❌ Non trovato'}\")\n",
    "\n",
    "# Lista per salvare tutti i risultati\n",
    "risultati_genere = []\n",
    "risultati_area = []\n",
    "risultati_eta = []\n",
    "\n",
    "# Funzione Cohen's d\n",
    "def cohens_d(group1, group2):\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    if n1 < 2 or n2 < 2:\n",
    "        return np.nan\n",
    "    var1, var2 = np.var(group1, ddof=1), np.var(group2, ddof=1)\n",
    "    pooled_std = np.sqrt(((n1-1)*var1 + (n2-1)*var2) / (n1+n2-2))\n",
    "    if pooled_std == 0:\n",
    "        return np.nan\n",
    "    return (np.mean(group1) - np.mean(group2)) / pooled_std\n",
    "\n",
    "# Analizza ogni domanda Likert\n",
    "if len(domande_likert_cols) > 0:\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(\"ANALISI PER OGNI DOMANDA LIKERT\")\n",
    "    print('='*100)\n",
    "    \n",
    "    for idx, col_likert in enumerate(domande_likert_cols, 1):\n",
    "        if col_likert not in df_demo.columns:\n",
    "            continue\n",
    "        \n",
    "        # Converti in numerico\n",
    "        df_demo[col_likert] = pd.to_numeric(df_demo[col_likert], errors='coerce')\n",
    "        \n",
    "        # Rimuovi valori mancanti\n",
    "        df_temp = df_demo[[col_likert, col_genere, col_area, col_eta, 'GruppoDettaglio']].dropna(subset=[col_likert])\n",
    "        \n",
    "        if len(df_temp) < 10:\n",
    "            continue\n",
    "        \n",
    "        # Trova il label della domanda dal dizionario likert_questions\n",
    "        label_breve = likert_questions[col_likert].get('short_label', col_likert[:60])\n",
    "        \n",
    "        print(f\"\\n{'-'*100}\")\n",
    "        print(f\"📋 [{idx}/{len(domande_likert_cols)}] {label_breve}\")\n",
    "        print(f\"{'-'*100}\")\n",
    "        \n",
    "        # ===== ANALISI GENERE =====\n",
    "        if col_genere and col_genere in df_temp.columns:\n",
    "            df_temp_gen = df_temp[[col_likert, col_genere]].dropna()\n",
    "            \n",
    "            # Identifica i valori per maschi e femmine\n",
    "            unique_gen = df_temp_gen[col_genere].unique()\n",
    "            \n",
    "            maschi_vals = None\n",
    "            femmine_vals = None\n",
    "            \n",
    "            for val in unique_gen:\n",
    "                val_lower = str(val).lower()\n",
    "                if 'm' in val_lower and 'f' not in val_lower:\n",
    "                    maschi_vals = val\n",
    "                elif 'f' in val_lower:\n",
    "                    femmine_vals = val\n",
    "            \n",
    "            if maschi_vals is not None and femmine_vals is not None:\n",
    "                data_m = df_temp_gen[df_temp_gen[col_genere] == maschi_vals][col_likert].values\n",
    "                data_f = df_temp_gen[df_temp_gen[col_genere] == femmine_vals][col_likert].values\n",
    "                \n",
    "                if len(data_m) >= 3 and len(data_f) >= 3:\n",
    "                    mean_m = np.mean(data_m)\n",
    "                    mean_f = np.mean(data_f)\n",
    "                    diff = mean_m - mean_f\n",
    "                    \n",
    "                    t_stat, p_val = ttest_ind(data_m, data_f)\n",
    "                    d = cohens_d(data_m, data_f)\n",
    "                    \n",
    "                    sig = '***' if p_val < 0.001 else '**' if p_val < 0.01 else '*' if p_val < 0.05 else 'ns'\n",
    "                    \n",
    "                    if abs(d) < 0.2:\n",
    "                        effect = \"trascurabile\"\n",
    "                    elif abs(d) < 0.5:\n",
    "                        effect = \"piccolo\"\n",
    "                    elif abs(d) < 0.8:\n",
    "                        effect = \"medio\"\n",
    "                    else:\n",
    "                        effect = \"grande\"\n",
    "                    \n",
    "                    risultati_genere.append({\n",
    "                        'Domanda': label_breve,\n",
    "                        'Colonna': col_likert,\n",
    "                        'N_M': len(data_m),\n",
    "                        'M_M': mean_m,\n",
    "                        'N_F': len(data_f),\n",
    "                        'M_F': mean_f,\n",
    "                        'Differenza': diff,\n",
    "                        't': t_stat,\n",
    "                        'p': p_val,\n",
    "                        'sig': sig,\n",
    "                        'Cohen_d': d,\n",
    "                        'Effetto': effect\n",
    "                    })\n",
    "                    \n",
    "                    print(f\"  🚹 GENERE: M={mean_m:.2f} (N={len(data_m)}) vs F={mean_f:.2f} (N={len(data_f)}) | Δ={diff:+.2f} | p={p_val:.4f} {sig} | d={d:.3f}\")\n",
    "        \n",
    "        # ===== ANALISI AREA =====\n",
    "        if col_area and col_area in df_temp.columns:\n",
    "            df_temp_area = df_temp[[col_likert, col_area]].dropna()\n",
    "            \n",
    "            # Identifica STEM e Umanistica\n",
    "            unique_area = df_temp_area[col_area].unique()\n",
    "            \n",
    "            stem_vals = []\n",
    "            hum_vals = []\n",
    "            \n",
    "            for val in unique_area:\n",
    "                val_lower = str(val).lower()\n",
    "                if 'stem' in val_lower or 'scientific' in val_lower or 'scien' in val_lower:\n",
    "                    stem_vals.append(val)\n",
    "                elif 'uman' in val_lower or 'human' in val_lower or 'lett' in val_lower or 'art' in val_lower:\n",
    "                    hum_vals.append(val)\n",
    "            \n",
    "            if len(stem_vals) > 0 and len(hum_vals) > 0:\n",
    "                data_stem = df_temp_area[df_temp_area[col_area].isin(stem_vals)][col_likert].values\n",
    "                data_hum = df_temp_area[df_temp_area[col_area].isin(hum_vals)][col_likert].values\n",
    "                \n",
    "                if len(data_stem) >= 3 and len(data_hum) >= 3:\n",
    "                    mean_stem = np.mean(data_stem)\n",
    "                    mean_hum = np.mean(data_hum)\n",
    "                    diff = mean_stem - mean_hum\n",
    "                    \n",
    "                    t_stat, p_val = ttest_ind(data_stem, data_hum)\n",
    "                    d = cohens_d(data_stem, data_hum)\n",
    "                    \n",
    "                    sig = '***' if p_val < 0.001 else '**' if p_val < 0.01 else '*' if p_val < 0.05 else 'ns'\n",
    "                    \n",
    "                    if abs(d) < 0.2:\n",
    "                        effect = \"trascurabile\"\n",
    "                    elif abs(d) < 0.5:\n",
    "                        effect = \"piccolo\"\n",
    "                    elif abs(d) < 0.8:\n",
    "                        effect = \"medio\"\n",
    "                    else:\n",
    "                        effect = \"grande\"\n",
    "                    \n",
    "                    risultati_area.append({\n",
    "                        'Domanda': label_breve,\n",
    "                        'Colonna': col_likert,\n",
    "                        'N_STEM': len(data_stem),\n",
    "                        'M_STEM': mean_stem,\n",
    "                        'N_HUM': len(data_hum),\n",
    "                        'M_HUM': mean_hum,\n",
    "                        'Differenza': diff,\n",
    "                        't': t_stat,\n",
    "                        'p': p_val,\n",
    "                        'sig': sig,\n",
    "                        'Cohen_d': d,\n",
    "                        'Effetto': effect\n",
    "                    })\n",
    "                    \n",
    "                    print(f\"  📚 AREA: STEM={mean_stem:.2f} (N={len(data_stem)}) vs HUM={mean_hum:.2f} (N={len(data_hum)}) | Δ={diff:+.2f} | p={p_val:.4f} {sig} | d={d:.3f}\")\n",
    "        \n",
    "        # ===== ANALISI ETÀ =====\n",
    "        if col_eta and col_eta in df_temp.columns:\n",
    "            df_temp_eta = df_temp[[col_likert, col_eta]].dropna()\n",
    "            \n",
    "            # Converti età in numerico\n",
    "            df_temp_eta[col_eta] = pd.to_numeric(df_temp_eta[col_eta], errors='coerce')\n",
    "            df_temp_eta = df_temp_eta.dropna()\n",
    "            \n",
    "            if len(df_temp_eta) >= 10:\n",
    "                eta_values = df_temp_eta[col_eta].values\n",
    "                likert_values = df_temp_eta[col_likert].values\n",
    "                \n",
    "                # Correlazione di Spearman (più robusta per dati ordinali)\n",
    "                rho, p_val = spearmanr(eta_values, likert_values)\n",
    "                \n",
    "                sig = '***' if p_val < 0.001 else '**' if p_val < 0.01 else '*' if p_val < 0.05 else 'ns'\n",
    "                \n",
    "                if abs(rho) < 0.1:\n",
    "                    effect = \"trascurabile\"\n",
    "                elif abs(rho) < 0.3:\n",
    "                    effect = \"debole\"\n",
    "                elif abs(rho) < 0.5:\n",
    "                    effect = \"moderato\"\n",
    "                else:\n",
    "                    effect = \"forte\"\n",
    "                \n",
    "                risultati_eta.append({\n",
    "                    'Domanda': label_breve,\n",
    "                    'Colonna': col_likert,\n",
    "                    'N': len(df_temp_eta),\n",
    "                    'rho': rho,\n",
    "                    'p': p_val,\n",
    "                    'sig': sig,\n",
    "                    'Effetto': effect\n",
    "                })\n",
    "                \n",
    "                print(f\"  👤 ETÀ: rho={rho:.3f} | p={p_val:.4f} {sig} | Correlazione {effect} (N={len(df_temp_eta)})\")\n",
    "\n",
    "# Converti in DataFrame\n",
    "df_risultati_genere = pd.DataFrame(risultati_genere)\n",
    "df_risultati_area = pd.DataFrame(risultati_area)\n",
    "df_risultati_eta = pd.DataFrame(risultati_eta)\n",
    "\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(\"SALVATAGGIO RISULTATI\")\n",
    "print('='*100)\n",
    "\n",
    "# Salva risultati\n",
    "if len(df_risultati_genere) > 0:\n",
    "    csv_gen = OUT_EXPL / 'likert_analisi_genere.csv'\n",
    "    df_risultati_genere.to_csv(csv_gen, index=False)\n",
    "    print(f\"\\n✓ Risultati GENERE salvati: {csv_gen}\")\n",
    "    print(f\"  {len(df_risultati_genere)} domande analizzate\")\n",
    "\n",
    "if len(df_risultati_area) > 0:\n",
    "    csv_area = OUT_EXPL / 'likert_analisi_area.csv'\n",
    "    df_risultati_area.to_csv(csv_area, index=False)\n",
    "    print(f\"\\n✓ Risultati AREA salvati: {csv_area}\")\n",
    "    print(f\"  {len(df_risultati_area)} domande analizzate\")\n",
    "\n",
    "if len(df_risultati_eta) > 0:\n",
    "    csv_eta = OUT_EXPL / 'likert_analisi_eta.csv'\n",
    "    df_risultati_eta.to_csv(csv_eta, index=False)\n",
    "    print(f\"\\n✓ Risultati ETÀ salvati: {csv_eta}\")\n",
    "    print(f\"  {len(df_risultati_eta)} domande analizzate\")\n",
    "\n",
    "print(f\"\\n{'='*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d8a2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SINTESI RISULTATI SIGNIFICATIVI ===\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"SINTESI: FATTORI DEMOGRAFICI CHE INFLUENZANO LE RISPOSTE LIKERT\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# ===== GENERE =====\n",
    "if len(df_risultati_genere) > 0:\n",
    "    sig_genere = df_risultati_genere[df_risultati_genere['sig'] != 'ns'].sort_values('p')\n",
    "    \n",
    "    print(f\"\\n🚹 GENERE (Maschi vs Femmine)\")\n",
    "    print(\"=\"*100)\n",
    "    print(f\"Domande analizzate: {len(df_risultati_genere)}\")\n",
    "    print(f\"Differenze significative (p<0.05): {len(sig_genere)}\")\n",
    "    \n",
    "    if len(sig_genere) > 0:\n",
    "        print(f\"\\n{'Domanda':<50} {'M':<8} {'F':<8} {'Δ':<8} {'p':<12} {'sig':<5} {'d':<8}\")\n",
    "        print(\"-\"*100)\n",
    "        for _, row in sig_genere.iterrows():\n",
    "            domanda_short = row['Domanda'][:47] + \"...\" if len(row['Domanda']) > 50 else row['Domanda']\n",
    "            print(f\"{domanda_short:<50} {row['M_M']:>7.2f} {row['M_F']:>7.2f} {row['Differenza']:>+7.2f} {row['p']:>11.6f} {row['sig']:>4} {row['Cohen_d']:>7.3f}\")\n",
    "        \n",
    "        # Interpreta\n",
    "        print(f\"\\n💡 INTERPRETAZIONE:\")\n",
    "        for _, row in sig_genere.iterrows():\n",
    "            if row['Differenza'] > 0:\n",
    "                chi_maggiore = \"Maschi\"\n",
    "            else:\n",
    "                chi_maggiore = \"Femmine\"\n",
    "            print(f\"  • {row['Domanda']}: {chi_maggiore} hanno valori significativamente più alti (d={row['Cohen_d']:.3f})\")\n",
    "    else:\n",
    "        print(\"\\n✗ Nessuna differenza significativa trovata per il genere\")\n",
    "\n",
    "# ===== AREA =====\n",
    "if len(df_risultati_area) > 0:\n",
    "    sig_area = df_risultati_area[df_risultati_area['sig'] != 'ns'].sort_values('p')\n",
    "    \n",
    "    print(f\"\\n\\n📚 AREA DISCIPLINARE (STEM vs Umanistica)\")\n",
    "    print(\"=\"*100)\n",
    "    print(f\"Domande analizzate: {len(df_risultati_area)}\")\n",
    "    print(f\"Differenze significative (p<0.05): {len(sig_area)}\")\n",
    "    \n",
    "    if len(sig_area) > 0:\n",
    "        print(f\"\\n{'Domanda':<50} {'STEM':<8} {'HUM':<8} {'Δ':<8} {'p':<12} {'sig':<5} {'d':<8}\")\n",
    "        print(\"-\"*100)\n",
    "        for _, row in sig_area.iterrows():\n",
    "            domanda_short = row['Domanda'][:47] + \"...\" if len(row['Domanda']) > 50 else row['Domanda']\n",
    "            print(f\"{domanda_short:<50} {row['M_STEM']:>7.2f} {row['M_HUM']:>7.2f} {row['Differenza']:>+7.2f} {row['p']:>11.6f} {row['sig']:>4} {row['Cohen_d']:>7.3f}\")\n",
    "        \n",
    "        # Interpreta\n",
    "        print(f\"\\n💡 INTERPRETAZIONE:\")\n",
    "        for _, row in sig_area.iterrows():\n",
    "            if row['Differenza'] > 0:\n",
    "                chi_maggiore = \"STEM\"\n",
    "            else:\n",
    "                chi_maggiore = \"Umanistica\"\n",
    "            print(f\"  • {row['Domanda']}: Area {chi_maggiore} ha valori significativamente più alti (d={row['Cohen_d']:.3f})\")\n",
    "    else:\n",
    "        print(\"\\n✗ Nessuna differenza significativa trovata per l'area disciplinare\")\n",
    "\n",
    "# ===== ETÀ =====\n",
    "if len(df_risultati_eta) > 0:\n",
    "    sig_eta = df_risultati_eta[df_risultati_eta['sig'] != 'ns'].sort_values('p')\n",
    "    \n",
    "    print(f\"\\n\\n👤 ETÀ (Correlazione)\")\n",
    "    print(\"=\"*100)\n",
    "    print(f\"Domande analizzate: {len(df_risultati_eta)}\")\n",
    "    print(f\"Correlazioni significative (p<0.05): {len(sig_eta)}\")\n",
    "    \n",
    "    if len(sig_eta) > 0:\n",
    "        print(f\"\\n{'Domanda':<50} {'rho':<8} {'p':<12} {'sig':<5} {'Effetto':<12}\")\n",
    "        print(\"-\"*100)\n",
    "        for _, row in sig_eta.iterrows():\n",
    "            domanda_short = row['Domanda'][:47] + \"...\" if len(row['Domanda']) > 50 else row['Domanda']\n",
    "            print(f\"{domanda_short:<50} {row['rho']:>7.3f} {row['p']:>11.6f} {row['sig']:>4} {row['Effetto']:<12}\")\n",
    "        \n",
    "        # Interpreta\n",
    "        print(f\"\\n💡 INTERPRETAZIONE:\")\n",
    "        for _, row in sig_eta.iterrows():\n",
    "            if row['rho'] > 0:\n",
    "                direzione = \"Con l'aumentare dell'età, aumentano\"\n",
    "            else:\n",
    "                direzione = \"Con l'aumentare dell'età, diminuiscono\"\n",
    "            print(f\"  • {row['Domanda']}: {direzione} i valori (rho={row['rho']:.3f}, {row['Effetto']})\")\n",
    "    else:\n",
    "        print(\"\\n✗ Nessuna correlazione significativa trovata con l'età\")\n",
    "\n",
    "# ===== SOMMARIO FINALE =====\n",
    "print(f\"\\n\\n{'='*100}\")\n",
    "print(\"📊 SOMMARIO GENERALE\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "n_sig_genere = len(sig_genere) if len(df_risultati_genere) > 0 else 0\n",
    "n_sig_area = len(sig_area) if len(df_risultati_area) > 0 else 0\n",
    "n_sig_eta = len(sig_eta) if len(df_risultati_eta) > 0 else 0\n",
    "\n",
    "total_sig = n_sig_genere + n_sig_area + n_sig_eta\n",
    "total_tests = len(df_risultati_genere) + len(df_risultati_area) + len(df_risultati_eta)\n",
    "\n",
    "print(f\"\\nTotale test effettuati: {total_tests}\")\n",
    "print(f\"Totale risultati significativi (p<0.05): {total_sig}\")\n",
    "print(f\"Percentuale di significatività: {(total_sig/total_tests*100) if total_tests > 0 else 0:.1f}%\")\n",
    "\n",
    "print(f\"\\nDettaglio:\")\n",
    "print(f\"  • GENERE: {n_sig_genere}/{len(df_risultati_genere)} significativi ({n_sig_genere/len(df_risultati_genere)*100 if len(df_risultati_genere)>0 else 0:.1f}%)\")\n",
    "print(f\"  • AREA: {n_sig_area}/{len(df_risultati_area)} significativi ({n_sig_area/len(df_risultati_area)*100 if len(df_risultati_area)>0 else 0:.1f}%)\")\n",
    "print(f\"  • ETÀ: {n_sig_eta}/{len(df_risultati_eta)} significativi ({n_sig_eta/len(df_risultati_eta)*100 if len(df_risultati_eta)>0 else 0:.1f}%)\")\n",
    "\n",
    "print(f\"\\n{'='*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3309a2c",
   "metadata": {},
   "source": [
    "---\n",
    "### 📊 Risultati dell'Analisi dei Fattori Demografici\n",
    "\n",
    "#### 🔍 **Sintesi Generale**\n",
    "\n",
    "Su 16 domande Likert analizzate:\n",
    "- **GENERE**: 2/8 differenze significative (25.0%)\n",
    "- **AREA disciplinare**: 0/9 differenze significative (0.0%)\n",
    "- **ETÀ**: Analisi non completata (colonna età identificata erroneamente)\n",
    "\n",
    "#### 🚹 **Effetto del GENERE** (Significativo)\n",
    "\n",
    "**2 domande mostrano differenze significative** tra Maschi e Femmine:\n",
    "\n",
    "1. **\"Preparazione insegnanti su IA\"** (solo studenti)\n",
    "   - Maschi: M = 3.58\n",
    "   - Femmine: M = 1.33\n",
    "   - Differenza: +2.25 punti (p = 0.030*)\n",
    "   - Effect size: **d = 1.33 (GRANDE)**\n",
    "   - **Interpretazione**: I maschi ritengono che gli insegnanti siano significativamente più preparati sull'IA rispetto a quanto ritengono le femmine\n",
    "\n",
    "2. **\"Fiducia nell'integrazione dell'IA\"** (solo studenti)\n",
    "   - Maschi: M = 4.62\n",
    "   - Femmine: M = 2.67\n",
    "   - Differenza: +1.96 punti (p = 0.037*)\n",
    "   - Effect size: **d = 1.27 (GRANDE)**\n",
    "   - **Interpretazione**: I maschi sono significativamente più fiduciosi nell'integrazione dell'IA nell'educazione rispetto alle femmine\n",
    "\n",
    "#### 📚 **Effetto dell'AREA Disciplinare** (Non significativo)\n",
    "\n",
    "**Nessuna differenza significativa** trovata tra STEM e Umanistica su nessuna delle 9 domande analizzate.\n",
    "\n",
    "**Interpretazione**: Le percezioni e attitudini verso l'IA nell'educazione sono **trasversali** rispetto all'area disciplinare. Non c'è evidenza che docenti/studenti STEM abbiano attitudini diverse da quelli di area Umanistica.\n",
    "\n",
    "#### 🎯 **Conclusioni Chiave**\n",
    "\n",
    "1. **Il GENERE è l'unico fattore demografico che influenza significativamente** alcune risposte Likert\n",
    "   \n",
    "2. Le differenze di genere sono presenti **solo in 2 domande** (entrambe per studenti), con effect size GRANDI (d > 1.2):\n",
    "   - Percezione della preparazione degli insegnanti\n",
    "   - Fiducia nell'integrazione dell'IA\n",
    "   \n",
    "3. **I maschi mostrano maggiore ottimismo/fiducia** verso l'IA nell'educazione\n",
    "\n",
    "4. **L'AREA disciplinare (STEM vs Umanistica) NON influisce** sulle risposte Likert\n",
    "   - Le attitudini verso l'IA sono simili tra le discipline\n",
    "   \n",
    "5. **Nota metodologica**: Solo 8/16 domande Likert sono state analizzate per genere e 9/16 per area, probabilmente perché alcune domande sono specifiche per un solo gruppo (solo insegnanti o solo studenti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec3f202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === VISUALIZZAZIONE DIFFERENZE DI GENERE ===\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "if len(sig_genere) > 0:\n",
    "    print(\"=\"*100)\n",
    "    print(\"VISUALIZZAZIONE: DIFFERENZE DI GENERE SU DOMANDE LIKERT SIGNIFICATIVE\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    # Crea un grafico a barre per ogni domanda significativa\n",
    "    fig, axes = plt.subplots(1, len(sig_genere), figsize=(7*len(sig_genere), 6))\n",
    "    \n",
    "    if len(sig_genere) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    colors_gen = {'M': '#3498db', 'F': '#e74c3c'}\n",
    "    \n",
    "    for idx, (_, row) in enumerate(sig_genere.iterrows()):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Dati\n",
    "        categories = ['Maschi', 'Femmine']\n",
    "        values = [row['M_M'], row['M_F']]\n",
    "        colors = [colors_gen['M'], colors_gen['F']]\n",
    "        \n",
    "        # Barre\n",
    "        bars = ax.bar(categories, values, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "        \n",
    "        # Aggiungi i valori sopra le barre\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.2f}',\n",
    "                   ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # Labels\n",
    "        domanda_short = row['Domanda'][:50]\n",
    "        if len(row['Domanda']) > 50:\n",
    "            domanda_short += \"...\"\n",
    "        \n",
    "        ax.set_title(f\"{domanda_short}\\n(p={row['p']:.4f}{row['sig']}, d={row['Cohen_d']:.2f})\", \n",
    "                    fontsize=11, fontweight='bold', pad=10)\n",
    "        ax.set_ylabel('Punteggio medio (scala 1-7)', fontsize=11, fontweight='bold')\n",
    "        ax.set_ylim(0, 7.5)\n",
    "        ax.axhline(y=4, color='gray', linestyle='--', alpha=0.5, linewidth=1)\n",
    "        ax.text(1, 4.1, 'Neutrale (4)', fontsize=9, color='gray', ha='right')\n",
    "        ax.grid(axis='y', alpha=0.3, linestyle=':')\n",
    "        \n",
    "        # Aggiungi la differenza\n",
    "        diff_text = f\"Δ = {row['Differenza']:+.2f}\"\n",
    "        ax.text(0.5, max(values) + 0.5, diff_text, \n",
    "               ha='center', fontsize=10, fontweight='bold', color='darkgreen',\n",
    "               bbox=dict(boxstyle='round,pad=0.5', facecolor='lightgreen', alpha=0.7))\n",
    "    \n",
    "    plt.suptitle('Differenze di Genere su Domande Likert Significative', \n",
    "                fontsize=15, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salva\n",
    "    out_png = OUT_EXPL / 'likert_differenze_genere_significative.png'\n",
    "    fig.savefig(out_png, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\n✓ Salvato: {out_png}\")\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "    \n",
    "    print(\"\\n✓ Visualizzazione completata\")\n",
    "else:\n",
    "    print(\"\\nNessuna differenza significativa di genere da visualizzare\")\n",
    "\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab9af1d",
   "metadata": {},
   "source": [
    "---\n",
    "## 📋 SINTESI FINALE: Analisi Fattori Demografici su Domande Likert\n",
    "\n",
    "### 🎯 Domanda di Ricerca\n",
    "**Genere, area disciplinare ed età influenzano le percezioni e attitudini verso l'IA nell'educazione?**\n",
    "\n",
    "---\n",
    "\n",
    "### 📊 **Metodologia**\n",
    "- **16 domande Likert** (scala 1-7) analizzate\n",
    "- **3 fattori demografici** testati:\n",
    "  1. **GENERE**: t-test indipendenti (Maschi vs Femmine)\n",
    "  2. **AREA**: t-test indipendenti (STEM vs Umanistica)\n",
    "  3. **ETÀ**: Correlazione di Spearman\n",
    "- **Livello di significatività**: p < 0.05\n",
    "- **Effect size**: Cohen's d per t-test, rho di Spearman per correlazioni\n",
    "\n",
    "---\n",
    "\n",
    "### 🔍 **RISULTATI PRINCIPALI**\n",
    "\n",
    "#### ✅ **GENERE: EFFETTO SIGNIFICATIVO (2/8 domande)**\n",
    "\n",
    "**Le femmine mostrano attitudini significativamente più negative/scettiche verso l'IA**\n",
    "\n",
    "| Domanda | Maschi (M) | Femmine (F) | Δ | p | d | Interpretazione |\n",
    "|---------|------------|-------------|---|---|---|-----------------|\n",
    "| **Preparazione insegnanti su IA** | 3.58 | 1.33 | +2.25 | 0.030* | 1.33 (GRANDE) | Le studentesse percepiscono gli insegnanti come **molto meno preparati** sull'IA |\n",
    "| **Fiducia integrazione IA** | 4.62 | 2.67 | +1.96 | 0.037* | 1.27 (GRANDE) | Le studentesse hanno **molto meno fiducia** nell'integrazione dell'IA nell'educazione |\n",
    "\n",
    "**💡 INTERPRETAZIONE GENERE:**\n",
    "- Le differenze sono **solo tra studenti** (non insegnanti)\n",
    "- Effect size **GRANDI** (d > 1.2): differenze sostanziali e praticamente rilevanti\n",
    "- Pattern coerente: le femmine mostrano **maggiore scetticismo** verso:\n",
    "  - La preparazione del sistema educativo ad affrontare l'IA\n",
    "  - I benefici dell'integrazione dell'IA nell'educazione\n",
    "- Possibili spiegazioni:\n",
    "  - Maggiore consapevolezza dei rischi/limiti dell'IA\n",
    "  - Minore esposizione/familiarità con tecnologie AI\n",
    "  - Gender gap tecnologico già documentato in letteratura\n",
    "\n",
    "---\n",
    "\n",
    "#### ❌ **AREA DISCIPLINARE: NESSUN EFFETTO (0/9 domande)**\n",
    "\n",
    "**STEM e Umanistica mostrano attitudini simili verso l'IA**\n",
    "\n",
    "- Nessuna delle 9 domande analizzate mostra differenze significative tra STEM e Umanistica\n",
    "- **Interpretazione**: Le percezioni e attitudini verso l'IA nell'educazione sono **trasversali** rispetto all'area disciplinare\n",
    "- **Implicazione**: Non c'è evidenza di un \"bias STEM\" nelle attitudini verso l'IA educativa\n",
    "- Sia docenti/studenti STEM che Umanistica condividono simili:\n",
    "  - Livelli di competenza percepita\n",
    "  - Fiducia nell'integrazione dell'IA\n",
    "  - Preoccupazioni sull'impatto dell'IA\n",
    "  - Percezioni sulla preparazione del sistema educativo\n",
    "\n",
    "---\n",
    "\n",
    "#### ⚠️ **ETÀ: ANALISI NON COMPLETATA**\n",
    "\n",
    "- La colonna età è stata identificata erroneamente nel dataset\n",
    "- Necessaria correzione manuale per completare l'analisi\n",
    "\n",
    "---\n",
    "\n",
    "### 📈 **SINTESI STATISTICA**\n",
    "\n",
    "| Fattore | Domande Analizzate | Risultati Significativi | % Significatività |\n",
    "|---------|-------------------|------------------------|-------------------|\n",
    "| **Genere** | 8 | 2 | 25.0% |\n",
    "| **Area** | 9 | 0 | 0.0% |\n",
    "| **Età** | 0 | 0 | N/A |\n",
    "| **TOTALE** | 17 | 2 | 11.8% |\n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 **CONCLUSIONI CHIAVE**\n",
    "\n",
    "1. **Il GENERE è l'UNICO fattore demografico che influenza significativamente le attitudini verso l'IA** nell'educazione\n",
    "   - Effetto limitato ma forte (2 domande, entrambe con effect size grande)\n",
    "   - Differenze concentrate tra studenti (non insegnanti)\n",
    "\n",
    "2. **Le FEMMINE mostrano maggiore SCETTICISMO** verso l'IA nell'educazione:\n",
    "   - Percepiscono il sistema educativo come meno preparato\n",
    "   - Hanno meno fiducia nei benefici dell'integrazione dell'IA\n",
    "   \n",
    "3. **L'AREA DISCIPLINARE (STEM vs Umanistica) NON influisce** sulle percezioni dell'IA\n",
    "   - Risultato sorprendente: ci si poteva aspettare che STEM fosse più positivo\n",
    "   - Suggerisce che l'IA nell'educazione è percepita come un tema universale, non tecnico\n",
    "\n",
    "4. **Implicazioni per policy educative**:\n",
    "   - Necessario affrontare il **gender gap** nelle percezioni dell'IA\n",
    "   - Programmi di sensibilizzazione/formazione dovrebbero considerare le differenze di genere\n",
    "   - Non necessario differenziare approcci tra STEM e Umanistica\n",
    "\n",
    "---\n",
    "\n",
    "### 📁 **Output Generati**\n",
    "\n",
    "1. **CSV Analisi Genere**: `likert_analisi_genere.csv` (8 domande)\n",
    "2. **CSV Analisi Area**: `likert_analisi_area.csv` (9 domande)\n",
    "3. **Grafico Differenze Genere**: `likert_differenze_genere_significative.png`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f385bb",
   "metadata": {},
   "source": [
    "---\n",
    "## 📊 Visualizzazione Completa: Correlazioni Demografiche su Domande Likert\n",
    "\n",
    "Creiamo grafici completi che mostrano:\n",
    "1. Tutte le differenze di genere (M vs F)\n",
    "2. Tutte le differenze di area (STEM vs Umanistica)\n",
    "3. Versioni in italiano e inglese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262455cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === GRAFICO COMPLETO CORRELAZIONI DEMOGRAFICHE (ITALIANO) ===\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"CREAZIONE GRAFICI: CORRELAZIONI DEMOGRAFICHE SU DOMANDE LIKERT\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# ===== GRAFICO GENERE (ITALIANO) =====\n",
    "if len(df_risultati_genere) > 0:\n",
    "    print(\"\\n📊 Creazione grafico GENERE (Italiano)...\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 10))\n",
    "    \n",
    "    # Ordina per differenza assoluta\n",
    "    df_gen_sorted = df_risultati_genere.sort_values('Differenza', ascending=True)\n",
    "    \n",
    "    # Prepara i dati\n",
    "    y_pos = np.arange(len(df_gen_sorted))\n",
    "    differenze = df_gen_sorted['Differenza'].values\n",
    "    p_values = df_gen_sorted['p'].values\n",
    "    \n",
    "    # Colori basati su significatività\n",
    "    colors = []\n",
    "    for p, diff in zip(p_values, differenze):\n",
    "        if p < 0.05:\n",
    "            colors.append('#e74c3c' if diff < 0 else '#3498db')  # Rosso se F>M, Blu se M>F\n",
    "        else:\n",
    "            colors.append('#95a5a6')  # Grigio se non significativo\n",
    "    \n",
    "    # Crea barre orizzontali\n",
    "    bars = ax.barh(y_pos, differenze, color=colors, alpha=0.8, edgecolor='black', linewidth=1)\n",
    "    \n",
    "    # Etichette domande (abbreviate)\n",
    "    labels = []\n",
    "    for _, row in df_gen_sorted.iterrows():\n",
    "        label = row['Domanda'][:40]\n",
    "        if len(row['Domanda']) > 40:\n",
    "            label += \"...\"\n",
    "        # Aggiungi asterischi per significatività\n",
    "        if row['sig'] != 'ns':\n",
    "            label += f\" {row['sig']}\"\n",
    "        labels.append(label)\n",
    "    \n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(labels, fontsize=10)\n",
    "    ax.set_xlabel('Differenza (Maschi - Femmine)', fontsize=13, fontweight='bold')\n",
    "    ax.set_title('Differenze di Genere su Domande Likert\\n(Valori positivi = Maschi > Femmine)', \n",
    "                fontsize=15, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Linea verticale a zero\n",
    "    ax.axvline(x=0, color='black', linewidth=2, linestyle='-', alpha=0.8)\n",
    "    \n",
    "    # Griglia\n",
    "    ax.grid(axis='x', alpha=0.3, linestyle=':')\n",
    "    \n",
    "    # Aggiungi valori sulle barre\n",
    "    for i, (bar, diff, p) in enumerate(zip(bars, differenze, p_values)):\n",
    "        if abs(diff) > 0.1:\n",
    "            x_pos = diff + (0.15 if diff > 0 else -0.15)\n",
    "            ha = 'left' if diff > 0 else 'right'\n",
    "            ax.text(x_pos, bar.get_y() + bar.get_height()/2, \n",
    "                   f'{diff:+.2f}', \n",
    "                   ha=ha, va='center', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # Legenda\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='#3498db', edgecolor='black', label='Maschi > Femmine (sig.)'),\n",
    "        Patch(facecolor='#e74c3c', edgecolor='black', label='Femmine > Maschi (sig.)'),\n",
    "        Patch(facecolor='#95a5a6', edgecolor='black', label='Non significativo (p≥0.05)')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='lower right', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salva\n",
    "    out_gen_it = OUT_EXPL / 'likert_correlazioni_genere_completo_it.png'\n",
    "    fig.savefig(out_gen_it, dpi=300, bbox_inches='tight')\n",
    "    print(f\"✓ Salvato: {out_gen_it}\")\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "# ===== GRAFICO AREA (ITALIANO) =====\n",
    "if len(df_risultati_area) > 0:\n",
    "    print(\"\\n📊 Creazione grafico AREA (Italiano)...\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 10))\n",
    "    \n",
    "    # Ordina per differenza assoluta\n",
    "    df_area_sorted = df_risultati_area.sort_values('Differenza', ascending=True)\n",
    "    \n",
    "    # Prepara i dati\n",
    "    y_pos = np.arange(len(df_area_sorted))\n",
    "    differenze = df_area_sorted['Differenza'].values\n",
    "    p_values = df_area_sorted['p'].values\n",
    "    \n",
    "    # Colori basati su significatività\n",
    "    colors = []\n",
    "    for p, diff in zip(p_values, differenze):\n",
    "        if p < 0.05:\n",
    "            colors.append('#e67e22' if diff < 0 else '#27ae60')  # Arancione se HUM>STEM, Verde se STEM>HUM\n",
    "        else:\n",
    "            colors.append('#95a5a6')  # Grigio se non significativo\n",
    "    \n",
    "    # Crea barre orizzontali\n",
    "    bars = ax.barh(y_pos, differenze, color=colors, alpha=0.8, edgecolor='black', linewidth=1)\n",
    "    \n",
    "    # Etichette domande (abbreviate)\n",
    "    labels = []\n",
    "    for _, row in df_area_sorted.iterrows():\n",
    "        label = row['Domanda'][:40]\n",
    "        if len(row['Domanda']) > 40:\n",
    "            label += \"...\"\n",
    "        # Aggiungi asterischi per significatività\n",
    "        if row['sig'] != 'ns':\n",
    "            label += f\" {row['sig']}\"\n",
    "        labels.append(label)\n",
    "    \n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(labels, fontsize=10)\n",
    "    ax.set_xlabel('Differenza (STEM - Umanistica)', fontsize=13, fontweight='bold')\n",
    "    ax.set_title('Differenze di Area Disciplinare su Domande Likert\\n(Valori positivi = STEM > Umanistica)', \n",
    "                fontsize=15, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Linea verticale a zero\n",
    "    ax.axvline(x=0, color='black', linewidth=2, linestyle='-', alpha=0.8)\n",
    "    \n",
    "    # Griglia\n",
    "    ax.grid(axis='x', alpha=0.3, linestyle=':')\n",
    "    \n",
    "    # Aggiungi valori sulle barre\n",
    "    for i, (bar, diff, p) in enumerate(zip(bars, differenze, p_values)):\n",
    "        if abs(diff) > 0.1:\n",
    "            x_pos = diff + (0.15 if diff > 0 else -0.15)\n",
    "            ha = 'left' if diff > 0 else 'right'\n",
    "            ax.text(x_pos, bar.get_y() + bar.get_height()/2, \n",
    "                   f'{diff:+.2f}', \n",
    "                   ha=ha, va='center', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # Legenda\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='#27ae60', edgecolor='black', label='STEM > Umanistica (sig.)'),\n",
    "        Patch(facecolor='#e67e22', edgecolor='black', label='Umanistica > STEM (sig.)'),\n",
    "        Patch(facecolor='#95a5a6', edgecolor='black', label='Non significativo (p≥0.05)')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='lower right', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salva\n",
    "    out_area_it = OUT_EXPL / 'likert_correlazioni_area_completo_it.png'\n",
    "    fig.savefig(out_area_it, dpi=300, bbox_inches='tight')\n",
    "    print(f\"✓ Salvato: {out_area_it}\")\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "print(\"\\n✓ Grafici italiani completati\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbcb7dc",
   "metadata": {},
   "source": [
    "---\n",
    "## 🔗 Matrice di Correlazione tra Domande Likert\n",
    "\n",
    "Analizziamo le correlazioni tra tutte le 16 domande Likert per identificare:\n",
    "- Quali domande sono fortemente correlate tra loro\n",
    "- Pattern di risposte coerenti\n",
    "- Possibili dimensioni latenti nelle attitudini verso l'IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac159780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MATRICE DI CORRELAZIONE TRA DOMANDE LIKERT ===\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"MATRICE DI CORRELAZIONE TRA DOMANDE LIKERT\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Prepara il dataframe con tutte le domande Likert\n",
    "# Usa il dizionario likert_questions se disponibile, altrimenti usa la lista\n",
    "if 'likert_questions' in dir():\n",
    "    domande_likert_cols = list(likert_questions.keys())\n",
    "elif 'domande_likert_cols' in dir():\n",
    "    pass  # già definito\n",
    "else:\n",
    "    print(\"\\n⚠️ Variabili Likert non trovate! Esegui prima le celle precedenti.\")\n",
    "    domande_likert_cols = []\n",
    "\n",
    "if len(domande_likert_cols) > 0:\n",
    "    print(f\"\\n✓ Trovate {len(domande_likert_cols)} domande Likert\")\n",
    "    \n",
    "    # Seleziona solo le colonne Likert dal dataframe\n",
    "    df_likert_only = DF_plot[domande_likert_cols].copy()\n",
    "    \n",
    "    # Converti tutte in numerico\n",
    "    for col in domande_likert_cols:\n",
    "        df_likert_only[col] = pd.to_numeric(df_likert_only[col], errors='coerce')\n",
    "    \n",
    "    print(f\"Dimensione dataset: {df_likert_only.shape}\")\n",
    "    \n",
    "    # Calcola la matrice di correlazione di Spearman (più adatta per dati ordinali)\n",
    "    print(\"\\n⏳ Calcolo correlazioni di Spearman...\")\n",
    "    \n",
    "    # Calcola correlazioni\n",
    "    corr_matrix = df_likert_only.corr(method='spearman')\n",
    "    \n",
    "    print(f\"✓ Matrice di correlazione calcolata: {corr_matrix.shape}\")\n",
    "    \n",
    "    # Crea labels abbreviati per le domande\n",
    "    labels_brevi = []\n",
    "    for col in domande_likert_cols:\n",
    "        label = likert_questions[col].get('short_label', col[:30])\n",
    "        # Abbrevia ulteriormente per la visualizzazione\n",
    "        if len(label) > 40:\n",
    "            label = label[:37] + \"...\"\n",
    "        labels_brevi.append(label)\n",
    "    \n",
    "    # Rinomina righe e colonne con labels brevi\n",
    "    corr_matrix_labeled = corr_matrix.copy()\n",
    "    corr_matrix_labeled.index = labels_brevi\n",
    "    corr_matrix_labeled.columns = labels_brevi\n",
    "    \n",
    "    # Trova le correlazioni più forti (esclusa diagonale)\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"CORRELAZIONI PIÙ FORTI (|rho| > 0.5)\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    strong_corr = []\n",
    "    for i in range(len(corr_matrix)):\n",
    "        for j in range(i+1, len(corr_matrix)):\n",
    "            rho = corr_matrix.iloc[i, j]\n",
    "            if abs(rho) > 0.5:\n",
    "                strong_corr.append({\n",
    "                    'Domanda_1': labels_brevi[i],\n",
    "                    'Domanda_2': labels_brevi[j],\n",
    "                    'rho': rho\n",
    "                })\n",
    "    \n",
    "    df_strong_corr = pd.DataFrame(strong_corr).sort_values('rho', ascending=False, key=abs)\n",
    "    \n",
    "    if len(df_strong_corr) > 0:\n",
    "        print(f\"\\nTrovate {len(df_strong_corr)} correlazioni forti (|rho| > 0.5):\\n\")\n",
    "        print(f\"{'Domanda 1':<40} {'Domanda 2':<40} {'rho':>8}\")\n",
    "        print(\"-\"*90)\n",
    "        for _, row in df_strong_corr.iterrows():\n",
    "            print(f\"{row['Domanda_1'][:38]:<40} {row['Domanda_2'][:38]:<40} {row['rho']:>8.3f}\")\n",
    "        \n",
    "        # Salva\n",
    "        csv_strong = OUT_EXPL / 'likert_correlazioni_forti.csv'\n",
    "        df_strong_corr.to_csv(csv_strong, index=False)\n",
    "        print(f\"\\n✓ Salvato: {csv_strong}\")\n",
    "    else:\n",
    "        print(\"\\nNessuna correlazione forte trovata (|rho| > 0.5)\")\n",
    "    \n",
    "    # ===== GRAFICO ITALIANO =====\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"CREAZIONE HEATMAP ITALIANO\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    fig_it, ax_it = plt.subplots(1, 1, figsize=(16, 14))\n",
    "    \n",
    "    # Crea la heatmap\n",
    "    mask = np.triu(np.ones_like(corr_matrix_labeled, dtype=bool))  # Maschera triangolo superiore\n",
    "    \n",
    "    sns.heatmap(\n",
    "        corr_matrix_labeled,\n",
    "        mask=mask,\n",
    "        annot=True,\n",
    "        fmt='.2f',\n",
    "        cmap='RdBu_r',\n",
    "        center=0,\n",
    "        vmin=-1,\n",
    "        vmax=1,\n",
    "        square=True,\n",
    "        linewidths=0.5,\n",
    "        cbar_kws={'label': 'Correlazione di Spearman (ρ)', 'shrink': 0.8},\n",
    "        ax=ax_it,\n",
    "        annot_kws={'size': 8}\n",
    "    )\n",
    "    \n",
    "    ax_it.set_title('Matrice di Correlazione tra Domande Likert (Spearman ρ)', \n",
    "                    fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Ruota le etichette\n",
    "    ax_it.set_xticklabels(ax_it.get_xticklabels(), rotation=45, ha='right', fontsize=9)\n",
    "    ax_it.set_yticklabels(ax_it.get_yticklabels(), rotation=0, fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salva\n",
    "    out_it_png = OUT_EXPL / 'likert_correlazioni_heatmap_it.png'\n",
    "    fig_it.savefig(out_it_png, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\n✓ Salvato: {out_it_png}\")\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close(fig_it)\n",
    "    \n",
    "    # ===== GRAFICO INGLESE =====\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"CREAZIONE HEATMAP INGLESE\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    # Traduci i labels in inglese\n",
    "    labels_en = []\n",
    "    for col in domande_likert_cols:\n",
    "        label_it = likert_questions[col].get('short_label', col[:30])\n",
    "        \n",
    "        # Traduzioni base\n",
    "        traduzioni = {\n",
    "            'Competenza pratica': 'Practical competence',\n",
    "            'Competenza teorica': 'Theoretical competence',\n",
    "            'Cambierà didattica': 'Will change teaching',\n",
    "            'Cambierà studio': 'Will change study',\n",
    "            'Adeguatezza formazione': 'Training adequacy',\n",
    "            'Fiducia integrazione': 'Trust in integration',\n",
    "            'Preparazione insegnanti': 'Teachers preparation',\n",
    "            'Preoccupazione generale': 'General concern',\n",
    "            'Preoccupazione compagni': 'Concern about peers',\n",
    "            'Preoccupazione studenti': 'Concern about students',\n",
    "            'Fiducia uso responsabile': 'Trust responsible use',\n",
    "            'Cambierà didattica generale': 'Will change teaching (general)',\n",
    "            'Cambierà mia didattica': 'Will change my teaching'\n",
    "        }\n",
    "        \n",
    "        label_en = label_it\n",
    "        for it, en in traduzioni.items():\n",
    "            if it in label_it:\n",
    "                label_en = label_it.replace(it, en)\n",
    "                break\n",
    "        \n",
    "        if len(label_en) > 40:\n",
    "            label_en = label_en[:37] + \"...\"\n",
    "        labels_en.append(label_en)\n",
    "    \n",
    "    # Crea matrice con labels inglesi\n",
    "    corr_matrix_en = corr_matrix.copy()\n",
    "    corr_matrix_en.index = labels_en\n",
    "    corr_matrix_en.columns = labels_en\n",
    "    \n",
    "    fig_en, ax_en = plt.subplots(1, 1, figsize=(16, 14))\n",
    "    \n",
    "    # Crea la heatmap\n",
    "    mask = np.triu(np.ones_like(corr_matrix_en, dtype=bool))\n",
    "    \n",
    "    sns.heatmap(\n",
    "        corr_matrix_en,\n",
    "        mask=mask,\n",
    "        annot=True,\n",
    "        fmt='.2f',\n",
    "        cmap='RdBu_r',\n",
    "        center=0,\n",
    "        vmin=-1,\n",
    "        vmax=1,\n",
    "        square=True,\n",
    "        linewidths=0.5,\n",
    "        cbar_kws={'label': 'Spearman Correlation (ρ)', 'shrink': 0.8},\n",
    "        ax=ax_en,\n",
    "        annot_kws={'size': 8}\n",
    "    )\n",
    "    \n",
    "    ax_en.set_title('Correlation Matrix among Likert Questions (Spearman ρ)', \n",
    "                    fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Ruota le etichette\n",
    "    ax_en.set_xticklabels(ax_en.get_xticklabels(), rotation=45, ha='right', fontsize=9)\n",
    "    ax_en.set_yticklabels(ax_en.get_yticklabels(), rotation=0, fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salva\n",
    "    out_en_png = OUT_EXPL / 'likert_correlazioni_heatmap_en.png'\n",
    "    fig_en.savefig(out_en_png, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\n✓ Salvato: {out_en_png}\")\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close(fig_en)\n",
    "    \n",
    "    print(\"\\n✓ Heatmap completate\")\n",
    "    \n",
    "    # Salva anche la matrice di correlazione completa\n",
    "    csv_corr = OUT_EXPL / 'likert_correlazioni_matrix.csv'\n",
    "    corr_matrix_labeled.to_csv(csv_corr)\n",
    "    print(f\"✓ Matrice completa salvata: {csv_corr}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n⚠️ Nessuna domanda Likert trovata!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027fb1fa",
   "metadata": {},
   "source": [
    "---\n",
    "### 📊 Interpretazione Matrice di Correlazione\n",
    "\n",
    "#### 🔍 **Correlazioni Forti Trovate** (|ρ| > 0.5)\n",
    "\n",
    "La matrice di correlazione di Spearman mostra **6 coppie di domande** con correlazioni forti (ρ > 0.5):\n",
    "\n",
    "1. **Competenza pratica ↔ Competenza teorica** (ρ = 0.72)\n",
    "   - Le due competenze (uso pratico e conoscenza teorica) sono fortemente correlate\n",
    "   - Chi si sente competente nell'uso pratico tende anche a sentirsi preparato teoricamente\n",
    "\n",
    "2. **Cambierà didattica ↔ Cambierà studio** (ρ = 0.66)\n",
    "   - Le percezioni di cambiamento per insegnamento e studio sono correlate\n",
    "   - Indica una visione coerente dell'impatto dell'IA sull'educazione\n",
    "\n",
    "3. **Fiducia integrazione ↔ Adeguatezza formazione** (ρ = 0.63)\n",
    "   - Chi ritiene adeguata la formazione ricevuta è più fiducioso nell'integrazione dell'IA\n",
    "   - Suggerisce che la preparazione aumenta la fiducia\n",
    "\n",
    "4. **Cambierà didattica ↔ Fiducia integrazione** (ρ = 0.62)\n",
    "   - Chi è fiducioso nell'integrazione percepisce maggiore potenziale di cambiamento\n",
    "   - Attitudine positiva correlata con aspettative di trasformazione\n",
    "\n",
    "5. **Competenza pratica ↔ Competenza teorica** (seconda coppia, ρ = 0.57)\n",
    "   - Conferma ulteriore della forte relazione tra le due dimensioni di competenza\n",
    "\n",
    "6. **Preoccupazione generale ↔ Preoccupazione specifica** (ρ = 0.51)\n",
    "   - Le preoccupazioni generali e specifiche sono moderate ma positivamente correlate\n",
    "   - Pattern di risposta coerente\n",
    "\n",
    "#### 💡 **Pattern Identificati**\n",
    "\n",
    "1. **Dimensione COMPETENZA**: Pratica e teorica vanno insieme (ρ = 0.72)\n",
    "   - Le due facce della stessa medaglia\n",
    "   - Auto-valutazione coerente delle proprie capacità\n",
    "\n",
    "2. **Dimensione FIDUCIA/OTTIMISMO**: Formazione → Fiducia → Percezione cambiamento\n",
    "   - Chi ha ricevuto formazione → più fiducioso → percepisce maggiore impatto\n",
    "   - Catena causale implicita\n",
    "\n",
    "3. **Dimensione PREOCCUPAZIONE**: Correlazioni moderate\n",
    "   - Le preoccupazioni sono relativamente indipendenti dalle competenze\n",
    "   - Pattern più complesso e sfumato\n",
    "\n",
    "4. **ASSENZA di correlazioni negative forti**:\n",
    "   - Sorprendentemente, competenza e preoccupazione NON sono negativamente correlate\n",
    "   - Essere competenti NON riduce necessariamente le preoccupazioni\n",
    "   - Suggerisce che le preoccupazioni possono essere razionali e consapevoli\n",
    "\n",
    "#### 🎯 **Implicazioni**\n",
    "\n",
    "- **Formazione come leva**: Migliorare la formazione potrebbe aumentare sia competenza che fiducia\n",
    "- **Competenze integrate**: Necessario sviluppare sia skills pratiche che conoscenze teoriche\n",
    "- **Preoccupazioni legittime**: Anche chi è competente può avere preoccupazioni (non sono semplicemente dovute a ignoranza)\n",
    "- **Visione sistemica**: Le percezioni dell'impatto dell'IA sono coerenti tra contesti didattici e di studio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e1bf9c",
   "metadata": {},
   "source": [
    "## 📊 Grafici Demografici per l'Articolo\n",
    "\n",
    "Ri-generiamo i 4 grafici demografici con titoli semplificati (senza \"across 4 groups\"):\n",
    "1. Age distribution — box\n",
    "2. Age distribution — violin  \n",
    "3. Gender distribution\n",
    "4. Disciplinary area distribution (STEM/Humanities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8521f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === GRAFICI DEMOGRAFIA PER ARTICOLO (titoli semplificati) ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup style\n",
    "plt.style.use(['science', 'no-latex', 'grid'])\n",
    "mpl.rcParams.update({\n",
    "    'text.usetex': False,\n",
    "    'mathtext.fontset': 'dejavusans',\n",
    "    'font.family': 'DejaVu Sans',\n",
    "    'figure.dpi': 150,\n",
    "    'savefig.dpi': 300,\n",
    "    'font.size': 12,\n",
    "    'axes.labelsize': 12,\n",
    "    'axes.titlesize': 13,\n",
    "})\n",
    "\n",
    "# Palette coerente\n",
    "order = [\n",
    "    'studenti - secondaria',\n",
    "    'studenti - universitari',\n",
    "    'insegnanti - non in servizio',\n",
    "    'insegnanti - in servizio',\n",
    "]\n",
    "\n",
    "palette = {\n",
    "    'studenti - secondaria': 'red',\n",
    "    'studenti - universitari': 'forestgreen',\n",
    "    'insegnanti - in servizio': 'royalblue',\n",
    "    'insegnanti - non in servizio': 'gold',\n",
    "}\n",
    "\n",
    "# Path output\n",
    "OUT = (Path.cwd()/'../analysis/exports/latest').resolve()\n",
    "ASSETS = (Path.cwd()/'../assets/figures').resolve()\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "ASSETS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CREAZIONE GRAFICI DEMOGRAFICI PER ARTICOLO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. AGE DISTRIBUTION - BOX\n",
    "print(\"\\n1. Age distribution — box\")\n",
    "fig, ax = plt.subplots(figsize=(7.2, 5.0))\n",
    "\n",
    "# Calcola soglie outlier\n",
    "stats = (\n",
    "    df_age.groupby('GruppoDettaglio', observed=False)['Eta']\n",
    "          .agg(q1=lambda s: s.quantile(0.25), q3=lambda s: s.quantile(0.75))\n",
    ")\n",
    "stats['iqr'] = stats['q3'] - stats['q1']\n",
    "stats['lower'] = stats['q1'] - 1.5 * stats['iqr']\n",
    "stats['upper'] = stats['q3'] + 1.5 * stats['iqr']\n",
    "thr = stats.reset_index()\n",
    "merged = df_age.merge(thr, on='GruppoDettaglio', how='left')\n",
    "outliers = merged[(merged['Eta'] < merged['lower']) | (merged['Eta'] > merged['upper'])][['GruppoDettaglio','Eta']]\n",
    "\n",
    "# Box senza outlier interni + overlay outlier colorati\n",
    "sns.boxplot(\n",
    "    data=df_age, x='GruppoDettaglio', y='Eta', hue='GruppoDettaglio', dodge=False,\n",
    "    showfliers=False, palette=palette, order=order, ax=ax\n",
    ")\n",
    "sns.stripplot(\n",
    "    data=outliers, x='GruppoDettaglio', y='Eta', hue='GruppoDettaglio', dodge=False,\n",
    "    order=order, hue_order=order, palette=palette, jitter=0.08, size=2.6, marker='o', alpha=0.7, linewidth=0, ax=ax\n",
    ")\n",
    "ax.set_xlabel('Gruppo')\n",
    "ax.set_ylabel('Età (anni)')\n",
    "ax.set_title('Age distribution — box')\n",
    "leg = ax.get_legend()\n",
    "if leg is not None:\n",
    "    leg.remove()\n",
    "ax.grid(True, axis='y', alpha=0.25)\n",
    "ax.set_axisbelow(True)\n",
    "plt.xticks(rotation=10, ha='right')\n",
    "sns.despine(ax=ax)\n",
    "plt.tight_layout()\n",
    "\n",
    "p_box_png = ASSETS / 'age_distribution_box.png'\n",
    "p_box_svg = ASSETS / 'age_distribution_box.svg'\n",
    "fig.savefig(p_box_png); fig.savefig(p_box_svg)\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "print(f\"   ✓ Salvato: {p_box_png}\")\n",
    "\n",
    "# 2. AGE DISTRIBUTION - VIOLIN\n",
    "print(\"\\n2. Age distribution — violin\")\n",
    "fig, ax = plt.subplots(figsize=(7.2, 5.0))\n",
    "sns.violinplot(\n",
    "    data=df_age, x='GruppoDettaglio', y='Eta', hue='GruppoDettaglio', dodge=False,\n",
    "    inner='quartile', cut=0, density_norm='width', palette=palette, order=order, ax=ax\n",
    ")\n",
    "ax.set_xlabel('Gruppo')\n",
    "ax.set_ylabel('Età (anni)')\n",
    "ax.set_title('Age distribution — violin')\n",
    "leg = ax.get_legend()\n",
    "if leg is not None:\n",
    "    leg.remove()\n",
    "ax.grid(True, axis='y', alpha=0.25)\n",
    "ax.set_axisbelow(True)\n",
    "plt.xticks(rotation=10, ha='right')\n",
    "sns.despine(ax=ax)\n",
    "plt.tight_layout()\n",
    "\n",
    "p_violin_png = ASSETS / 'age_distribution_violin.png'\n",
    "p_violin_svg = ASSETS / 'age_distribution_violin.svg'\n",
    "fig.savefig(p_violin_png); fig.savefig(p_violin_svg)\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "print(f\"   ✓ Salvato: {p_violin_png}\")\n",
    "\n",
    "print(\"\\n✓ Grafici età completati!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6cc993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. GENDER DISTRIBUTION\n",
    "print(\"\\n3. Gender distribution\")\n",
    "\n",
    "# Leggi i conteggi salvati in precedenza\n",
    "counts_gender = pd.read_csv(OUT / 'counts_genere_per_gruppo.csv', index_col=0)\n",
    "\n",
    "# Crea stacked bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Colori per genere (neutri)\n",
    "colors_gender = {'Maschio': '#4575b4', 'Femmina': '#d73027', 'Non risponde': '#cccccc'}\n",
    "\n",
    "# Prepara dati per plotting\n",
    "x_pos = np.arange(len(order))\n",
    "width = 0.6\n",
    "\n",
    "# Bottom tracker per stacking\n",
    "bottom = np.zeros(len(order))\n",
    "\n",
    "for gen in ['Maschio', 'Femmina', 'Non risponde']:\n",
    "    if gen in counts_gender.columns:\n",
    "        values = [counts_gender.loc[g, gen] if g in counts_gender.index else 0 for g in order]\n",
    "        ax.bar(x_pos, values, width, label=gen, bottom=bottom, color=colors_gender.get(gen, '#999'))\n",
    "        bottom += values\n",
    "\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(order, rotation=15, ha='right')\n",
    "ax.set_xlabel('Gruppo')\n",
    "ax.set_ylabel('Conteggio')\n",
    "ax.set_title('Gender distribution')\n",
    "ax.legend(loc='upper right', frameon=False)\n",
    "ax.grid(True, axis='y', alpha=0.25)\n",
    "ax.set_axisbelow(True)\n",
    "sns.despine(ax=ax)\n",
    "plt.tight_layout()\n",
    "\n",
    "p_gender_png = ASSETS / 'gender_distribution.png'\n",
    "p_gender_svg = ASSETS / 'gender_distribution.svg'\n",
    "fig.savefig(p_gender_png); fig.savefig(p_gender_svg)\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "print(f\"   ✓ Salvato: {p_gender_png}\")\n",
    "\n",
    "# 4. DISCIPLINARY AREA DISTRIBUTION  \n",
    "print(\"\\n4. Disciplinary area distribution (STEM/Humanities)\")\n",
    "\n",
    "# Leggi i conteggi salvati in precedenza\n",
    "counts_area = pd.read_csv(OUT / 'counts_area_per_gruppo.csv', index_col=0)\n",
    "\n",
    "# Crea stacked bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Colori per area (coerenti con tema)\n",
    "colors_area = {'STEM': '#2ca02c', 'Umanistiche': '#ff7f0e', 'Non risponde': '#cccccc'}\n",
    "\n",
    "# Prepara dati per plotting\n",
    "bottom = np.zeros(len(order))\n",
    "\n",
    "for area in ['STEM', 'Umanistiche', 'Non risponde']:\n",
    "    if area in counts_area.columns:\n",
    "        values = [counts_area.loc[g, area] if g in counts_area.index else 0 for g in order]\n",
    "        ax.bar(x_pos, values, width, label=area, bottom=bottom, color=colors_area.get(area, '#999'))\n",
    "        bottom += values\n",
    "\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(order, rotation=15, ha='right')\n",
    "ax.set_xlabel('Gruppo')\n",
    "ax.set_ylabel('Conteggio')\n",
    "ax.set_title('Disciplinary area distribution (STEM/Humanities)')\n",
    "ax.legend(loc='upper right', frameon=False)\n",
    "ax.grid(True, axis='y', alpha=0.25)\n",
    "ax.set_axisbelow(True)\n",
    "sns.despine(ax=ax)\n",
    "plt.tight_layout()\n",
    "\n",
    "p_area_png = ASSETS / 'area_distribution.png'\n",
    "p_area_svg = ASSETS / 'area_distribution.svg'\n",
    "fig.savefig(p_area_png); fig.savefig(p_area_svg)\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "print(f\"   ✓ Salvato: {p_area_png}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ TUTTI I 4 GRAFICI DEMOGRAFICI CREATI!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nFile salvati in: {ASSETS}\")\n",
    "print(\"  1. age_distribution_box.png/.svg\")\n",
    "print(\"  2. age_distribution_violin.png/.svg\")\n",
    "print(\"  3. gender_distribution.png/.svg\")\n",
    "print(\"  4. area_distribution.png/.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6956440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import edge_tts\n",
    "from pathlib import Path\n",
    "\n",
    "# Testo dell'introduzione italiana\n",
    "introduzione_text = \"\"\"\n",
    "L'intelligenza artificiale generativa (GenAI) sta entrando nelle scuole e università italiane spontaneamente, senza una pianificazione pedagogica strutturata. A differenza di precedenti strumenti digitali che recuperano o visualizzano contenuti esistenti (motori di ricerca, database, sistemi di gestione dell'apprendimento), la GenAI ricostruisce attivamente la conoscenza a ogni interazione. Quando ad esempio uno studente interroga ChatGPT sulla Rivoluzione Francese, non riceve un documento o una fonte (in alcuni casi la riceve dopo), ma una narrazione appena sintetizzata—una che fonde molteplici fonti, seleziona certe cornici interpretative rispetto ad altre, e si presenta con una voce autorevole.\n",
    "\n",
    "Questo processo è genuinamente creativo, nel senso espresso da Bruno Munari. Infatti, nella sua opera \"Fantasia\", definisce la creatività come ricombinazione di elementi esistenti in nuove configurazioni—un processo di selezione, connessione e sintesi piuttosto che invenzione ex nihilo. La GenAI opera precisamente attraverso tali processi ricombinatori. \n",
    "\n",
    "Questa capacità creativa—che nei modelli è più propriamente associata al termine \"generativa\"—consente a questi strumenti di svolgere molti compiti cognitivi e intellettuali di alto livello che fino a ieri erano prerogativa esclusiva dell'essere umano: la scrittura di saggi, la sintesi di documenti complessi, la traduzione tra lingue, la produzione di codice software, la selezione e gerarchizzazione di notizie, l'elaborazione di strategie argomentative. Tutte attività che richiedevano giudizio umano, esperienza consolidata e capacità di discernimento. Quando uno studente chiede a ChatGPT di riassumere un capitolo di filosofia o di proporre una struttura per un tema, il sistema esegue istantaneamente operazioni di selezione delle informazioni rilevanti, gerarchizzazione dei concetti e costruzione di nessi logici, producendo un testo strutturato e coerente.\n",
    "\n",
    "Ma è proprio questa capacità a generare preoccupazioni profonde. Alcuni critici avvertono che la GenAI potrebbe essere semplicemente un \"pappagallo stocastico\"—un pattern-matcher senza genuina comprensione che riproduce schemi statistici dei dati di addestramento. Questi sistemi incorporano bias sistematici che riflettono e amplificano le disuguaglianze presenti nei dati—bias di genere che associano determinate professioni a specifici sessi, bias razziali che perpetuano stereotipi su culture e gruppi etnici, bias socioeconomici che privilegiano prospettive dominanti marginalizzando visioni alternative. Quando uno studente chiede a un'IA di descrivere \"un ingegnere\" o \"un'infermiera\", le risposte riflettono sistematicamente questi pregiudizi, naturalizzandoli come verità neutre e poco trasparenti.\n",
    "\n",
    "Accanto a questo, il problema della trasparenza si lega a quello della accountability. Nei media tradizionali—libri, film, televisione, giornali—il lavoro di cura della conoscenza era svolto da autori, editori, curatori e gatekeeper giornalistici che facevano scelte deliberate e ne portavano la responsabilità. I gatekeeper, in particolare, svolgevano un ruolo cruciale di filtro e validazione: decidevano quali notizie meritassero attenzione, quale rilevanza attribuire agli eventi, quali fonti fossero affidabili. Questo processo, pur non immune da bias, era trasparente nelle sue responsabilità—si poteva identificare chi aveva preso le decisioni editoriali e chiamarlo a rispondere delle sue scelte. Con la GenAI, questo compito fondamentalmente umano di cura della conoscenza è delegato a meccanismi computazionali che operano secondo pattern statistici, senza intento autoriale, accountability o criteri di selezione trasparenti.\n",
    "\n",
    "Un'altra questione riguarda la dimensione epistemologica, legata al modo in cui conosciamo il mondo. Questi sistemi non si limitano a impacchettare informazioni e darcele in maniera che sembra neutra: modificano attivamente il nostro modo di percepire la realtà, ci fanno vedere le cose diversamente, ci spingono verso ragionamenti che non avremmo sviluppato autonomamente. Quando uno studente chiede a ChatGPT di spiegare un concetto complesso, non riceve solo dati—riceve una particolare interpretazione, una specifica cornice cognitiva, un modo di pensare che diventa invisibilmente parte del suo processo di apprendimento. Il rischio è che la delega sistematica dei processi cognitivi possa atrofizzare le nostre capacità di pensiero critico, di analisi autonoma, di sintesi originale—trasformandoci da pensatori attivi in consumatori passivi di elaborazioni algoritmiche.\n",
    "\n",
    "Strettamente connesso a questa trasformazione epistemologica è il problema della velocità e dell'efficienza come valori dominanti. Se la delega cognitiva modifica cosa pensiamo, l'accelerazione radicale elimina il tempo necessario per pensare. In una società sempre più competitiva e orientata alla produttività immediata—dove non solo gli studenti ma anche professionisti, ricercatori e lavoratori di ogni settore sono sottoposti a pressioni crescenti per \"fare di più in meno tempo\"—la GenAI amplifica la spinta verso tempi di risposta sempre più ridotti. Uno studente che un tempo avrebbe impiegato ore o giorni per elaborare una tesina—leggendo fonti, prendendo appunti, riorganizzando le idee, scrivendo bozze successive—può ora ottenere un testo completo in pochi secondi. Un professionista che dedicava settimane ad analizzare dati e preparare report può ora delegare l'intero processo a un sistema automatico. Questa accelerazione radicale elimina quello che gli educatori chiamano \"tempo di incubazione\": quel periodo apparentemente improduttivo ma cognitivamente cruciale in cui le idee sedimentano, si connettono, maturano. La riflessione profonda richiede lentezza; richiede momenti di sospensione, di dubbio, di ritorno critico sul proprio ragionamento—pause che nel contesto lavorativo contemporaneo vengono sempre più percepite come lussi ingiustificabili. La GenAI, offrendo soluzioni istantanee, rischia di far percepire questa lentezza riflessiva non come una risorsa cognitiva essenziale ma come un'inefficienza da eliminare. Il messaggio implicito è chiaro: perché impiegare tre giorni quando puoi ottenere lo stesso risultato in tre minuti? Ma il risultato è davvero lo stesso? Il processo conta, non solo il prodotto—e un processo che salta la fase della rielaborazione personale produce apprendimenti superficiali, privi di quella sedimentazione che trasforma l'informazione in conoscenza autentica.\n",
    "\n",
    "Si aggiunge a queste preoccupazioni la prospettiva della sostituzione dell'insegnante. Alcuni visionari tecnologici immaginano che l'IA possa non solo automatizzare compiti intellettuali, ma sostituire completamente la figura del docente. Bill Gates, all'evento ASU+GSV di San Diego, ha prospettato che entro un anno e mezzo chatbot come ChatGPT potranno insegnare a leggere e scrivere ai bambini con l'efficacia di un tutor umano. Questa visione trova eco anche nella fiction, come nella serie Star Wars: Skeleton Crew, dove bambini interagiscono con droidi educatori in contesti di apprendimento completamente automatizzati. Al di là delle questioni tecniche—se questi sistemi possano svolgere adeguatamente compiti che una volta erano di competenza umana—emerge una domanda pedagogica fondamentale: quando una macchina si sostituisce alla relazione educativa, che effetti ha questo processo sulla formazione intellettuale e umana?\n",
    "\n",
    "Questo crea una situazione paradossale. La GenAI democratizza l'accesso a capacità digitali avanzate—studenti ed educatori possono ora creare siti web dinamici, dashboard interattive, simulazioni di valutazione ed esperienze di apprendimento personalizzate (come interazioni basate su avatar con figure storiche o letterarie) che prima richiedevano competenze tecniche specializzate. Tuttavia questa rapida diffusione avviene in un contesto dove la comprensione critica rimane limitata: gli utenti interagiscono intensivamente con sistemi i cui processi decisionali e limiti rimangono in gran parte oscuri.\n",
    "\n",
    "Vista la complessità del fenomeno—che Morin definirebbe irriducibile a semplificazioni—è comprensibile che le posizioni oscillino tra \"integrati\" e \"apocalittici\", spesso nella stessa persona: chi vede nell'IA una rivoluzione pedagogica democratizzante può al contempo temere l'erosione del pensiero critico; chi riconosce i rischi per il rapporto educativo umano può contemporaneamente apprezzarne le potenzialità. È in questo clima di incertezza e ambivalenza—dove entusiasmo e preoccupazione coesistono senza sintesi definitiva—che studenti, docenti e istituzioni navigano quotidianamente l'integrazione della GenAI.\n",
    "\"\"\"\n",
    "\n",
    "# Configurazione output\n",
    "output_dir = Path(\"../output/audio\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "output_file = output_dir / \"introduzione_italiana.mp3\"\n",
    "\n",
    "# Voce italiana (scegliamo una voce naturale)\n",
    "VOICE = \"it-IT-ElsaNeural\"  # Voce femminile italiana di alta qualità\n",
    "\n",
    "print(f\"Generazione audio dell'introduzione...\")\n",
    "print(f\"Voce: {VOICE}\")\n",
    "print(f\"Output: {output_file}\")\n",
    "print(f\"Lunghezza testo: {len(introduzione_text)} caratteri\")\n",
    "print(f\"Parole: circa {len(introduzione_text.split())} parole\")\n",
    "print(f\"Durata stimata: circa {len(introduzione_text.split()) / 150:.1f} minuti (a 150 parole/minuto)\")\n",
    "\n",
    "# Funzione asincrona per generare l'audio\n",
    "async def generate_audio():\n",
    "    communicate = edge_tts.Communicate(introduzione_text, VOICE)\n",
    "    await communicate.save(str(output_file))\n",
    "\n",
    "# Esegui la generazione\n",
    "await generate_audio()\n",
    "\n",
    "print(f\"\\n✓ Audio generato con successo!\")\n",
    "print(f\"File salvato in: {output_file}\")\n",
    "print(f\"Dimensione file: {output_file.stat().st_size / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46f3dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: ispeziona colonne DF per identificare età e gruppo\n",
    "cols = list(DF.columns)\n",
    "print('Numero colonne DF:', len(cols))\n",
    "for i, c in enumerate(cols[:80], 1):\n",
    "    print(f\"{i:3d}. {c}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb2a4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: trova possibili colonne per età e gruppo\n",
    "import re, unicodedata\n",
    "\n",
    "def norm(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFKD', s) if not unicodedata.combining(c)).lower()\n",
    "\n",
    "age_candidates = []\n",
    "grp_candidates = []\n",
    "for c in DF.columns:\n",
    "    n = norm(str(c))\n",
    "    if any(k in n for k in ['eta', 'età', 'age']):\n",
    "        age_candidates.append(c)\n",
    "    if any(k in n for k in ['gruppo', 'group', 'dettaglio', 'detail']):\n",
    "        grp_candidates.append(c)\n",
    "print('Age candidates:', age_candidates)\n",
    "print('Group candidates:', grp_candidates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ddd1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: individua colonne numeriche candidate per età per percentuale di valori numerici\n",
    "import pandas as pd\n",
    "candidates = []\n",
    "for c in DF.columns:\n",
    "    s = pd.to_numeric(DF[c], errors='coerce')\n",
    "    valid = s.between(10, 100).sum()\n",
    "    total = s.notna().sum()\n",
    "    if valid >= 10:  # almeno 10 valori plausibili\n",
    "        candidates.append((c, int(valid), int(total)))\n",
    "\n",
    "candidates = sorted(candidates, key=lambda x: (-x[1], -x[2]))\n",
    "print('Colonne plausibili per età (validi tra 10 e 100):')\n",
    "for c, v, t in candidates[:10]:\n",
    "    print(f\" - {c} -> validi:{v} su nonNa:{t}\")\n",
    "    sample = pd.to_numeric(DF[c], errors='coerce').dropna().astype(int).drop_duplicates().sort_values().tolist()[:10]\n",
    "    print('   esempi:', sample)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}